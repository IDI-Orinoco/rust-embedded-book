<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>El Libro de Rust Embebido</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = null;
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="intro/index.html"><strong aria-hidden="true">1.</strong> Introducción</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="intro/hardware.html"><strong aria-hidden="true">1.1.</strong> Hardware</a></li><li class="chapter-item expanded "><a href="intro/no-std.html"><strong aria-hidden="true">1.2.</strong> no_std</a></li><li class="chapter-item expanded "><a href="intro/tooling.html"><strong aria-hidden="true">1.3.</strong> Herramientas</a></li><li class="chapter-item expanded "><a href="intro/install.html"><strong aria-hidden="true">1.4.</strong> Instalación</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="intro/install/linux.html"><strong aria-hidden="true">1.4.1.</strong> Linux</a></li><li class="chapter-item expanded "><a href="intro/install/macos.html"><strong aria-hidden="true">1.4.2.</strong> MacOS</a></li><li class="chapter-item expanded "><a href="intro/install/windows.html"><strong aria-hidden="true">1.4.3.</strong> Windows</a></li><li class="chapter-item expanded "><a href="intro/install/verify.html"><strong aria-hidden="true">1.4.4.</strong> Verificar Instalación</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="start/index.html"><strong aria-hidden="true">2.</strong> Cómo empezar</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="start/qemu.html"><strong aria-hidden="true">2.1.</strong> QEMU</a></li><li class="chapter-item expanded "><a href="start/hardware.html"><strong aria-hidden="true">2.2.</strong> Hardware</a></li><li class="chapter-item expanded "><a href="start/registers.html"><strong aria-hidden="true">2.3.</strong> Registros mapeados en memoria</a></li><li class="chapter-item expanded "><a href="start/semihosting.html"><strong aria-hidden="true">2.4.</strong> Semihosting</a></li><li class="chapter-item expanded "><a href="start/panicking.html"><strong aria-hidden="true">2.5.</strong> Pánico</a></li><li class="chapter-item expanded "><a href="start/exceptions.html"><strong aria-hidden="true">2.6.</strong> Excepciones</a></li><li class="chapter-item expanded "><a href="start/interrupts.html"><strong aria-hidden="true">2.7.</strong> Interrupciones</a></li><li class="chapter-item expanded "><a href="start/io.html"><strong aria-hidden="true">2.8.</strong> E/S</a></li></ol></li><li class="chapter-item expanded "><a href="peripherals/index.html"><strong aria-hidden="true">3.</strong> Periféricos</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="peripherals/a-first-attempt.html"><strong aria-hidden="true">3.1.</strong> Un primer intento en Rust</a></li><li class="chapter-item expanded "><a href="peripherals/borrowck.html"><strong aria-hidden="true">3.2.</strong> El comprobador de préstamos</a></li><li class="chapter-item expanded "><a href="peripherals/singletons.html"><strong aria-hidden="true">3.3.</strong> Singletons</a></li></ol></li><li class="chapter-item expanded "><a href="static-guarantees/index.html"><strong aria-hidden="true">4.</strong> Garantías estáticas</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="static-guarantees/typestate-programming.html"><strong aria-hidden="true">4.1.</strong> Programación por Typestate</a></li><li class="chapter-item expanded "><a href="static-guarantees/state-machines.html"><strong aria-hidden="true">4.2.</strong> Periféricos como máquinas de estado</a></li><li class="chapter-item expanded "><a href="static-guarantees/design-contracts.html"><strong aria-hidden="true">4.3.</strong> Contratos de diseño</a></li><li class="chapter-item expanded "><a href="static-guarantees/zero-cost-abstractions.html"><strong aria-hidden="true">4.4.</strong> Abstracciones de costo cero</a></li></ol></li><li class="chapter-item expanded "><a href="portability/index.html"><strong aria-hidden="true">5.</strong> Portabilidad</a></li><li class="chapter-item expanded "><a href="concurrency/index.html"><strong aria-hidden="true">6.</strong> Concurrencia</a></li><li class="chapter-item expanded "><a href="collections/index.html"><strong aria-hidden="true">7.</strong> Colecciones</a></li><li class="chapter-item expanded "><a href="design-patterns/index.html"><strong aria-hidden="true">8.</strong> Design Patterns</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="design-patterns/hal/index.html"><strong aria-hidden="true">8.1.</strong> HALs</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="design-patterns/hal/checklist.html"><strong aria-hidden="true">8.1.1.</strong> Lista de chequeo</a></li><li class="chapter-item expanded "><a href="design-patterns/hal/naming.html"><strong aria-hidden="true">8.1.2.</strong> Nomenclatura</a></li><li class="chapter-item expanded "><a href="design-patterns/hal/interoperability.html"><strong aria-hidden="true">8.1.3.</strong> Interoperabilidad</a></li><li class="chapter-item expanded "><a href="design-patterns/hal/predictability.html"><strong aria-hidden="true">8.1.4.</strong> Previsibilidad</a></li><li class="chapter-item expanded "><a href="design-patterns/hal/gpio.html"><strong aria-hidden="true">8.1.5.</strong> GPIO</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="c-tips/index.html"><strong aria-hidden="true">9.</strong> Consejos para desarrolladores de C embebido</a></li><li class="chapter-item expanded "><a href="interoperability/index.html"><strong aria-hidden="true">10.</strong> Interoperabilidad</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="interoperability/c-with-rust.html"><strong aria-hidden="true">10.1.</strong> Un poco de C con tu Rust</a></li><li class="chapter-item expanded "><a href="interoperability/rust-with-c.html"><strong aria-hidden="true">10.2.</strong> Un poco de Rust con tu C</a></li></ol></li><li class="chapter-item expanded "><a href="unsorted/index.html"><strong aria-hidden="true">11.</strong> Temas sin clasificar</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="unsorted/speed-vs-size.html"><strong aria-hidden="true">11.1.</strong> Optimizaciones: El equilibrio entre velocidad y tamaño</a></li><li class="chapter-item expanded "><a href="unsorted/math.html"><strong aria-hidden="true">11.2.</strong> Realización de funciones matemáticas</a></li><li class="spacer"></li></ol></li><li class="chapter-item expanded "><a href="appendix/glossary.html">Apéndice A: Glosario</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">El Libro de Rust Embebido</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/idio/rust-embedded-book" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introducción"><a class="header" href="#introducción">Introducción</a></h1>
<p>Bienvenido al Libro de Rust Embebido: Un libro introductorio sobre el uso del lenguaje de programación Rust en sistemas embebidos &quot;Bare Metal&quot;, como los microcontroladores.</p>
<h2 id="a-quién-va-dirigido-rust-embebido"><a class="header" href="#a-quién-va-dirigido-rust-embebido">A quién va dirigido Rust Embebido</a></h2>
<p>Rust Embebido es para todos aquellos que quieran hacer programación embebida aprovechando los conceptos de alto nivel y las garantías de seguridad que ofrece el lenguaje Rust.
(Ver también <a href="https://doc.rust-lang.org/book/ch00-00-introduction.html">Para quién es Rust</a>)</p>
<h2 id="alcance"><a class="header" href="#alcance">Alcance</a></h2>
<p>Los objetivos de este libro son:</p>
<ul>
<li>
<p>Poner a los desarrolladores al día con el desarrollo de Rust embebido, es decir, cómo configurar un entorno de desarrollo.</p>
</li>
<li>
<p>Compartir las mejores prácticas <em>actuales</em> sobre el uso de Rust para el desarrollo embebido, es decir, cómo utilizar mejor las características del lenguaje Rust para escribir un software embebido más correcto.</p>
</li>
<li>
<p>Servir como un recetario en algunos casos. Por ejemplo, ¿Cómo puedo mezclar C y Rust en un solo proyecto?</p>
</li>
</ul>
<p>Este libro intenta ser lo más general posible, pero para facilitar las cosas tanto a los lectores como a los escritores, utiliza la arquitectura ARM Cortex-M en todos sus ejemplos. Sin embargo, el libro no asume que el lector esté familiarizado con esta arquitectura en particular y explica detalles particulares de esta arquitectura cuando es necesario.</p>
<h2 id="a-quién-va-dirigido-este-libro"><a class="header" href="#a-quién-va-dirigido-este-libro">A quién va dirigido este libro</a></h2>
<p>Este libro está dirigido a personas con algún tipo de experiencia en sistemas embebidos o con algún tipo de experiencia en Rust, sin embargo creemos que todos los curiosos de la programación en Rust embebido pueden obtener algo de este libro. Para aquellos que no tengan ningún conocimiento previo, les sugerimos que lean la sección &quot;Supuestos y Prerrequisitos&quot; y se pongan al día con los conocimientos que les faltan para sacar más provecho del libro y mejorar su experiencia de lectura. Puedes consultar la sección &quot;Otros recursos&quot; para encontrar recursos sobre temas en los que quieras ponerte al día.</p>
<h3 id="supuestos-y-prerrequisitos"><a class="header" href="#supuestos-y-prerrequisitos">Supuestos y prerrequisitos</a></h3>
<ul>
<li>Te sientes cómodo usando el lenguaje de programación Rust, y has escrito, ejecutado y depurado aplicaciones Rust en un entorno de escritorio. También debes estar familiarizado con los modismos de la <a href="https://doc.rust-lang.org/edition-guide/">edición 2018</a>, ya que este libro está dirigido a Rust 2018.</li>
</ul>
<ul>
<li>Te sientes cómodo desarrollando y depurando sistemas embebidos en otro lenguaje como C, C++ o Ada, y estás familiarizado con conceptos como:
<ul>
<li>Compilación cruzada</li>
<li>Periféricos mapeados en memoria</li>
<li>Interrupciones</li>
<li>Interfaces comunes como I2C, SPI, Serial, etc.</li>
</ul>
</li>
</ul>
<h3 id="otros-recursos"><a class="header" href="#otros-recursos">Otros recursos</a></h3>
<p>Si no estás familiarizado con nada de lo mencionado anteriormente o si quieres más información sobre un tema específico mencionado en este libro, puede que algunos de estos recursos te resulten útiles.</p>
<div class="table-wrapper"><table><thead><tr><th>Tema</th><th>Recurso</th><th>Descripción</th></tr></thead><tbody>
<tr><td>Rust</td><td><a href="intro/(https://doc.rust-lang.org/book/)">Rust Book</a></td><td>Si aún no te sientes cómodo con Rust, te sugerimos que leas este libro.</td></tr>
<tr><td>Rust, Embebido</td><td><a href="intro/(https://docs.rust-embedded.org/discovery/)">Discovery Book</a></td><td>Si nunca has hecho nada de programación embebida, este libro podría ser un mejor comienzo.</td></tr>
<tr><td>Rust, Embebido</td><td><a href="intro/(https://docs.rust-embedded.org)">Embedded Rust Bookshelf</a></td><td>Aquí puedes encontrar otros recursos proporcionados por el Grupo de Trabajo de Rust Embebido.</td></tr>
<tr><td>Rust, Embebido</td><td><a href="intro/(https://docs.rust-embedded.org/embedonomicon/)">Embedonomicon</a></td><td>Los detalles más importantes de la programación embebida en Rust.</td></tr>
<tr><td>Rust, Embebido</td><td><a href="intro/(https://docs.rust-embedded.org/faq.html)">embedded FAQ</a></td><td>Preguntas frecuentes sobre Rust en un contexto embebido.</td></tr>
<tr><td>Interrupciones</td><td><a href="intro/(https://en.wikipedia.org/wiki/Interrupt)">Interrupt</a></td><td>-</td></tr>
<tr><td>IO/Periféricos mapeados en memoria</td><td><a href="intro/(https://en.wikipedia.org/wiki/Memory-mapped_I/O)">Memory-mapped I/O</a></td><td>-</td></tr>
<tr><td>SPI, UART, RS232, USB, I2C, TTL</td><td><a href="intro/(https://electronics.stackexchange.com/questions/37814/usart-uart-rs232-usb-spi-i2c-ttl-etc-what-are-all-of-these-and-how-do-th)">Stack Exchange about SPI, UART, and other interfaces</a></td><td>-</td></tr>
</tbody></table>
</div>
<h3 id="traducciones"><a class="header" href="#traducciones">Traducciones</a></h3>
<p>Este libro ha sido traducido por generosos voluntarios. Si quieres que tu traducción aparezca aquí, por favor abre una PR para añadirla.</p>
<ul>
<li>
<p><a href="https://tomoyuki-nakabayashi.github.io/book/">Japonés</a>
(<a href="https://github.com/tomoyuki-nakabayashi/book">repositorio</a>)</p>
</li>
<li>
<p><a href="https://xxchang.github.io/book/">Chino</a>
(<a href="https://github.com/XxChang/book">repositorio</a>)</p>
</li>
</ul>
<h2 id="cómo-utilizar-este-libro"><a class="header" href="#cómo-utilizar-este-libro">Cómo utilizar este libro</a></h2>
<p>En general, este libro supone que se lee de principio a fin. Los capítulos posteriores se basan en los conceptos de los capítulos anteriores, y es posible que los capítulos anteriores no profundicen en los detalles de un tema, sino que vuelvan a tratar el tema en un capítulo posterior.</p>
<p>Este libro utilizará la tarjeta de desarrollo <a href="http://www.st.com/en/evaluation-tools/stm32f3discovery.html">STM32F3DISCOVERY</a> de STMicroelectronics para la mayoría de los ejemplos que contiene. Esta tarjeta está basada en la arquitectura ARM Cortex-M, y aunque la funcionalidad básica es la misma en la mayoría de las CPUs basadas en esta arquitectura, los periféricos y otros detalles de implementación de los microcontroladores son diferentes entre los distintos proveedores, y a menudo incluso diferentes entre las familias de microcontroladores del mismo proveedor.</p>
<p>Por esta razón, sugerimos adquirir la tarjeta de desarrollo <a href="http://www.st.com/en/evaluation-tools/stm32f3discovery.html">STM32F3DISCOVERY</a> para seguir los ejemplos de este libro.</p>
<h2 id="contribución-a-este-libro"><a class="header" href="#contribución-a-este-libro">Contribución a este libro</a></h2>
<p>El trabajo de este libro está coordinado en <a href="https://github.com/rust-embedded/book">este repositorio</a> y es desarrollado principalmente por el <a href="https://github.com/rust-embedded/wg#the-resources-team">equipo de recursos</a>.</p>
<p>Si tienes problemas para seguir las instrucciones de este libro o encuentras que alguna sección del libro no es lo suficientemente clara o difícil de seguir, entonces eso es un error y debe ser reportado en el <a href="https://github.com/rust-embedded/book/issues/">rastreador de problemas</a> de este libro.</p>
<p>Las PR para corregir errores tipográficos y añadir nuevos contenidos son muy bienvenidas.</p>
<h2 id="reutilización-de-este-material"><a class="header" href="#reutilización-de-este-material">Reutilización de este material</a></h2>
<p>Este libro se distribuye bajo las siguientes licencias:</p>
<ul>
<li>Los ejemplos de código y los proyectos independientes de Cargo contenidos en este libro están licenciados bajo los términos de la <a href="https://opensource.org/licenses/MIT">Licencia MIT</a> y la <a href="http://www.apache.org/licenses/LICENSE-2.0">Licencia Apache v2.0</a>.</li>
<li>La prosa escrita, las imágenes y los diagramas contenidos en este libro están bajo los términos de la licencia Creative Commons <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC-BY-SA v4.0</a>.</li>
</ul>
<p>TL;DR: Si quieres utilizar nuestro texto o imágenes en tu trabajo, tienes que:</p>
<ul>
<li>Dar el crédito apropiado (es decir, mencionar este libro en su diapositiva, y proporcionar un enlace a la página correspondiente)</li>
<li>Proporcionar un enlace a la licencia <a href="https://creativecommons.org/licenses/by-sa/4.0/legalcode">CC-BY-SA v4.0</a></li>
<li>Indicar si ha modificado el material de alguna manera, y hacer que cualquier cambio en nuestro material esté disponible bajo la misma licencia</li>
</ul>
<p>Además, por favor, haznos saber si este libro te resulta útil.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="conoce-tu-hardware"><a class="header" href="#conoce-tu-hardware">Conoce tu hardware</a></h1>
<p>Vamos a familiarizarnos con el hardware con el que vamos a trabajar.</p>
<h2 id="stm32f3discovery-el-f3"><a class="header" href="#stm32f3discovery-el-f3">STM32F3DISCOVERY (El &quot;F3&quot;)</a></h2>
<p align="center">
<img title="F3" src="intro/../assets/f3.jpg">
</p>
<p>¿Qué contiene esta tarjeta?</p>
<ul>
<li>
<p>Un microcontrolador <a href="https://www.st.com/en/microcontrollers/stm32f303vc.html">STM32F303VCT6</a>. Este microcontrolador tiene</p>
<ul>
<li>
<p>Un procesador ARM Cortex-M4F de un solo núcleo con soporte de hardware para operaciones de punto flotante de precisión única y una frecuencia de reloj máxima de 72 MHz.</p>
</li>
<li>
<p>256 KiB de memoria &quot;Flash&quot;. (1 KiB = 10<strong>24</strong> bytes)</p>
</li>
<li>
<p>48 KiB de memoria RAM.</p>
</li>
<li>
<p>Una variedad de periféricos integrados como temporizadores, I2C, SPI y USART.</p>
</li>
<li>
<p>Entradas y salidas de propósito general (GPIO) y otros tipos de pines accesibles a través de las dos filas de cabeceras a lo largo de la tarjeta.</p>
</li>
<li>
<p>Una interfaz USB accesible a través del puerto USB etiquetado como &quot;USB USER&quot;.</p>
</li>
</ul>
</li>
<li>
<p>Un <a href="https://es.wikipedia.org/wiki/Aceler%C3%B3metro">acelerómetro</a> como parte del chip <a href="https://www.st.com/en/mems-and-sensors/lsm303dlhc.html">LSM303DLHC</a>.</p>
</li>
<li>
<p>Un <a href="https://es.wikipedia.org/wiki/Magnet%C3%B3metro">magnetómetro</a> como parte del chip <a href="https://www.st.com/en/mems-and-sensors/lsm303dlhc.html">LSM303DLHC</a>.</p>
</li>
<li>
<p>Un <a href="https://es.wikipedia.org/wiki/Gir%C3%B3scopo">giroscopio</a> como parte del chip <a href="https://www.pololu.com/file/0J563/L3GD20.pdf">L3GD20</a>.</p>
</li>
<li>
<p>8 LEDs de usuario dispuestos en forma de brújula.</p>
</li>
<li>
<p>Un segundo microcontrolador: un <a href="https://www.st.com/en/microcontrollers/stm32f103cb.html">STM32F103</a>. Este microcontrolador es en realidad parte de un programador / depurador a bordo y está conectado al puerto USB llamado &quot;USB ST-LINK&quot;.</p>
</li>
</ul>
<p>Para obtener una lista más detallada de las características y otras especificaciones de la tarjeta, consulta el sitio web de <a href="https://www.st.com/en/evaluation-tools/stm32f3discovery.html">STMicroelectronics</a>.</p>
<p>Una advertencia: ten cuidado si quieres aplicar señales externas a la tarjeta. Los pines del microcontrolador STM32F303VCT6 reciben una tensión nominal de 3,3 voltios. Para más información, consulta la sección <a href="https://www.st.com/resource/en/datasheet/stm32f303vc.pdf">6.2 Valores máximos absolutos del manual</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="un-entorno-rust-no_std"><a class="header" href="#un-entorno-rust-no_std">Un entorno Rust <code>no_std</code></a></h1>
<p>El término Programación Embebida se utiliza para una amplia gama de diferentes clases de programación. Va desde la programación de MCUs de 8 bits (como el <a href="https://www.st.com/resource/en/datasheet/st72325j6.pdf">ST72325xx</a>) con sólo unos pocos KB de RAM y ROM, hasta sistemas como la Raspberry Pi (<a href="https://en.wikipedia.org/wiki/Raspberry_Pi#Specifications">Modelo B 3+</a>) que tiene un Cortex-A53 de 4 núcleos de 32/64 bits a 1,4 GHz y 1GB de RAM. Se aplicarán diferentes restricciones/limitaciones cuando estes escribiendo el código dependiendo del tipo de objetivo y del caso de uso que tengas.</p>
<p>Hay dos clasificaciones generales de programación embebida:</p>
<h2 id="entornos-alojados"><a class="header" href="#entornos-alojados">Entornos alojados</a></h2>
<p>Este tipo de entornos se asemeja a un entorno de PC normal. Esto significa que se le proporciona una interfaz de sistema, por ejemplo <a href="https://en.wikipedia.org/wiki/POSIX">POSIX</a>, que te proporcionan primitivas para interactuar con varios sistemas, como sistemas de archivos, redes, gestión de memoria, hilos, etc. Las bibliotecas estándar, a su vez, suelen depender de estas primitivas para implementar su funcionalidad. También puede tener algún tipo de sysroot y restricciones en el uso de RAM/ROM, y quizás algunos HW o I/Os especiales. En general, se siente como codificar en un entorno de PC de propósito especial.</p>
<h2 id="entornos-bare-metal"><a class="header" href="#entornos-bare-metal">Entornos Bare Metal</a></h2>
<p>En un entorno bare metal no se ha cargado ningún código antes del programa. Sin el software proporcionado por un SO no podemos cargar la biblioteca estándar. En su lugar, el programa, junto con las crates que utiliza, sólo puede utilizar el hardware (bare metal) para ejecutarse. Para evitar que rust cargue la biblioteca estándar utilice <code>no_std</code>. Las partes agnósticas a la plataforma de la biblioteca estándar están disponibles a través de <a href="https://doc.rust-lang.org/core/">libcore</a>. libcore también excluye cosas que no siempre son deseables en un entorno embebido. Una de estas cosas es un asignador de memoria para la asignación de memoria dinámica. Si necesitas esta u otras funcionalidades, a menudo hay crates que las proporcionan.</p>
<h3 id="el-ejecutable-de-libstd"><a class="header" href="#el-ejecutable-de-libstd">El ejecutable de libstd</a></h3>
<p>Como se mencionó antes, el uso de <a href="https://doc.rust-lang.org/std/">libstd</a> requiere algún tipo de integración del sistema, pero esto no es sólo porque <a href="https://doc.rust-lang.org/std/">libstd</a> está proporcionando una forma común de acceder a las abstracciones del sistema operativo, sino que también proporciona un ejecutable. Este ejecutable, entre otras cosas, se encarga de configurar la protección contra el desbordamiento de pila, procesar los argumentos de la línea de comandos y generar el hilo principal antes de que se invoque la función principal de un programa. Este tiempo de ejecución tampoco estará disponible en un entorno <code>no_std</code>.</p>
<h2 id="resumen"><a class="header" href="#resumen">Resumen</a></h2>
<p><code>#![no_std]</code> es un atributo a nivel de <em>crate</em> que indica que la <em>crate</em> se enlazará con la core-crate en lugar de con el std-crate. La <em>crate</em> <a href="https://doc.rust-lang.org/core/">libcore</a> es a su vez un subconjunto agnóstico de plataforma de la <em>crate</em> std que no hace suposiciones sobre el sistema en el que se ejecutará el programa. Como tal, proporciona APIs para primitivas del lenguaje como floats, strings y slices, así como APIs que exponen características del procesador como operaciones atómicas e instrucciones SIMD. Sin embargo, carece de APIs para cualquier cosa que implique la integración de la plataforma. Debido a estas propiedades, el código de no_std y <a href="https://doc.rust-lang.org/core/">libcore</a> se puede utilizar para cualquier tipo de código de arranque (fase 0) como bootloaders, firmware o kernels.</p>
<h3 id="resumen-1"><a class="header" href="#resumen-1">Resumen</a></h3>
<div class="table-wrapper"><table><thead><tr><th>característica</th><th>no_std</th><th>std</th></tr></thead><tbody>
<tr><td>heap (dynamic memory)</td><td>*</td><td>✓</td></tr>
<tr><td>collections (Vec, BTreeMap, etc)</td><td>**</td><td>✓</td></tr>
<tr><td>stack overflow protection</td><td>✘</td><td>✓</td></tr>
<tr><td>runs init code before main</td><td>✘</td><td>✓</td></tr>
<tr><td>libstd available</td><td>✘</td><td>✓</td></tr>
<tr><td>libcore available</td><td>✓</td><td>✓</td></tr>
<tr><td>writing firmware, kernel, or bootloader code</td><td>✓</td><td>✘</td></tr>
</tbody></table>
</div>
<p>* Sólo si usas la <em>crate</em> <code>alloc</code> y utilizas un asignador adecuado como [alloc-cortex-m].</p>
<p>** Sólo si usas la <em>crate</em> <code>collections</code>  y utilizas un asignador global default allocator.</p>
<p>** HashMap y HashSet no están disponibles debido a la falta de un generador de números aleatorios seguro.
[alloc-cortex-m]: https://github.com/rust-embedded/alloc-cortex-m</p>
<h2 id="ver-también"><a class="header" href="#ver-también">Ver también</a></h2>
<ul>
<li><a href="https://github.com/rust-lang/rfcs/blob/master/text/1184-stabilize-no_std.md">RFC-1184</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="herramientas"><a class="header" href="#herramientas">Herramientas</a></h1>
<p>Tratar con microcontroladores implica el uso de varias herramientas diferentes ya que estaremos con una arquitectura diferente a la de tu portátil y tendremos que ejecutar y depurar programas en un dispositivo <em>remoto</em>.</p>
<p>Utilizaremos todas las herramientas listadas a continuación. Cualquier versión reciente debería funcionar no se especifica una versión mínima, pero hemos enumerado las versiones que hemos probado.</p>
<ul>
<li>Rust 1.31, 1.31-beta, o un toolchain más reciente MÁS soporte de compilación ARM Cortex-M. soporte.</li>
<li><a href="https://github.com/rust-embedded/cargo-binutils"><code>cargo-binutils</code></a> ~0.1.4</li>
<li><a href="https://www.qemu.org/"><code>qemu-system-arm</code></a>. Versiones probadas: 3.0.0</li>
<li>OpenOCD &gt;=0.8. Versiones probadas: v0.9.0 y v0.10.0</li>
<li>GDB con soporte ARM. Versión 7.12 o más reciente muy recomendable. Versiones probadas de probadas: 7.10, 7.11, 7.12 y 8.1</li>
<li><a href="https://github.com/ashleygwilliams/cargo-generate"><code>cargo-generate</code></a> o <code>git</code>. Estas herramientas son opcionales pero facilitarán el seguimiento del libro.</li>
</ul>
<p>El siguiente texto explica por qué utilizamos estas herramientas. Las instrucciones de instalación se encuentran en la página siguiente.</p>
<h2 id="cargo-generate-o-git"><a class="header" href="#cargo-generate-o-git"><code>cargo-generate</code> O <code>git</code></a></h2>
<p>Los programas &quot;bare metal&quot; son programas Rust no estándar (<code>no_std</code>) que requieren algunos ajustes en el proceso de enlazado para poder obtener la disposición de memoria del programa. Esto requiere algunos archivos (como scripts del enlazador) y ajustes (como las banderas del enlazador) adicionales. Los hemos empaquetado en una plantilla para que sólo tengas que rellenar la información que falta (como el nombre del proyecto y las características de tu hardware de destino).</p>
<p>Nuestra plantilla es compatible con <code>cargo-generate</code>: un subcomando de Cargo para crear nuevos proyectos Cargo a partir de plantillas. También puedes descargarla usando <code>git</code>, <code>curl</code>, <code>wget</code>, o tu navegador web.</p>
<h2 id="cargo-binutils"><a class="header" href="#cargo-binutils"><code>cargo-binutils</code></a></h2>
<p><code>cargo-binutils</code> es una colección de subcomandos de Cargo que facilitan el uso de las herramientas LLVM que vienen con la cadena de herramientas de Rust. Estas herramientas incluyen las versiones LLVM de <code>objdump</code>, <code>nm</code> y <code>size</code> y se utilizan para inspeccionar binarios.</p>
<p>La ventaja de usar estas herramientas sobre las GNU binutils es que (a) instalar las herramientas de LLVM es la misma instalación con un solo comando (<code>rustup component add llvm-tools-preview</code>) independientemente de tu sistema operativo y (b) herramientas como <code>objdump</code> soportan todas las arquitecturas que <code>rustc</code> soporta -- desde ARM hasta x86_64 -- porque ambas comparten el mismo LLVM backend.</p>
<h2 id="qemu-system-arm"><a class="header" href="#qemu-system-arm"><code>qemu-system-arm</code></a></h2>
<p>QEMU es un emulador. En este caso usamos la variante que puede emular completamente sistemas ARM. Usamos QEMU para ejecutar programas embebidos en el host. Gracias a esto puedes ¡puedes seguir algunas partes de este libro incluso si no tienes ningún hardware contigo!</p>
<h2 id="gdb"><a class="header" href="#gdb">GDB</a></h2>
<p>Un depurador es un componente muy importante del desarrollo embebido, ya que no siempre puedes permitirte el lujo de registrar cosas en la consola del host. En algunos casos, ¡puede que ni siquiera tengas LEDs parpadeando en tu hardware!</p>
<p>En general, LLDB funciona tan bien como GDB cuando se trata de depuración, pero no hemos encontrado una contraparte de LLDB al comando <code>load</code> de GDB, que carga el programa en el hardware de destino, por lo que actualmente recomendamos que utilices GDB.</p>
<h2 id="openocd"><a class="header" href="#openocd">OpenOCD</a></h2>
<p>GDB no es capaz de comunicarse directamente con el hardware de depuración ST-Link en tu tarjeta de desarrollo STM32F3DISCOVERY. Necesita un traductor y el Open On-Chip Debugger, OpenOCD, es ese traductor. OpenOCD es un programa que se ejecuta en tu laptop/PC y traduce entre el protocolo de depuración remota basado en TCP/IP de GDB y el protocolo USB de ST-Link. de GDB y el protocolo basado en USB de ST-Link.</p>
<p>OpenOCD también realiza otros trabajos importantes como parte de la traducción para la depuración del microcontrolador ARM Cortex-M basado en la tarjeta de desarrollo STM32F3DISCOVERY:</p>
<ul>
<li>Sabe cómo interactuar con los registros mapeados en memoria utilizados por el periférico de depuración ARM CoreSight. Son estos registros CoreSight los que permiten:
<ul>
<li>Manipulación de Breakpoint/Watchpoint</li>
<li>Lectura y escritura de los registros de la CPU</li>
<li>Detectar cuando la CPU ha sido detenida por un evento de depuración</li>
<li>Continuar la ejecución de la CPU después de un evento de depuración</li>
<li>etc.</li>
</ul>
</li>
<li>También sabe cómo borrar y escribir en la FLASH del microcontrolador.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="instalación-de-las-herramientas"><a class="header" href="#instalación-de-las-herramientas">Instalación de las herramientas</a></h1>
<p>Esta página contiene instrucciones de instalación independientes del sistema operativo para algunas de las herramientas:</p>
<h3 id="rust-toolchain"><a class="header" href="#rust-toolchain">Rust Toolchain</a></h3>
<p>Instala rustup siguiendo las instrucciones en <a href="https://rustup.rs">https://rustup.rs</a>.</p>
<p><strong>NOTA</strong> Asegúrate de que tienes una versión del compilador igual o más reciente que <code>1.31</code>. <code>rustc -V</code> debería devolver una fecha más reciente que la que se muestra a continuación.</p>
<pre><code class="language-text">$ rustc -V
rustc 1.31.1 (b6c32da9b 2018-12-18)
</code></pre>
<p>Por cuestiones de ancho de banda y uso de disco, la instalación por defecto sólo soporta compilación nativa. Para añadir soporte de compilación cruzada para las arquitecturas ARM Cortex-M elija uno de los siguientes objetivos de compilación. Para la tarjeta STM32F3DISCOVERY utilizada para los ejemplos de este libro, utilice el objetivo <code>thumbv7em-none-eabihf</code>.</p>
<p>Cortex-M0, M0+ y M1 (arquitectura ARMv6-M):</p>
<pre><code class="language-console">rustup target add thumbv6m-none-eabi
</code></pre>
<p>Cortex-M3 (arquitectura ARMv7-M):</p>
<pre><code class="language-console">rustup target add thumbv7m-none-eabi
</code></pre>
<p>Cortex-M4 y M7 sin punto flotante por hardware (arquitectura ARMv7E-M):</p>
<pre><code class="language-console">rustup target add thumbv7em-none-eabi
</code></pre>
<p>Cortex-M4F y M7F con punto flotante por hardware (arquitectura ARMv7E-M):</p>
<pre><code class="language-console">rustup target add thumbv7em-none-eabihf
</code></pre>
<p>Cortex-M23 (arquitectura ARMv8-M):</p>
<pre><code class="language-console">rustup target add thumbv8m.base-none-eabi
</code></pre>
<p>Cortex-M33 y M35P (arquitectura ARMv8-M):</p>
<pre><code class="language-console">rustup target add thumbv8m.main-none-eabi
</code></pre>
<p>Cortex-M33F y M35PF con punto flotante por hardware (arquitectura ARMv8-M):</p>
<pre><code class="language-console">rustup target add thumbv8m.main-none-eabihf
</code></pre>
<h3 id="cargo-binutils-1"><a class="header" href="#cargo-binutils-1"><code>cargo-binutils</code></a></h3>
<pre><code class="language-text">cargo install cargo-binutils

rustup component add llvm-tools-preview
</code></pre>
<p>WINDOWS: prerrequisito tener instalado C++ Build Tools para Visual Studio 2019. https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=BuildTools&amp;rel=16</p>
<h3 id="cargo-generate"><a class="header" href="#cargo-generate"><code>cargo-generate</code></a></h3>
<p>Lo usaremos más adelante para generar un proyecto a partir de una plantilla.</p>
<pre><code class="language-console">cargo install cargo-generate
</code></pre>
<p>Nota: en algunas distribuciones Linux (p.e. Ubuntu) puede que necesites instalar los paquetes <code>libssl-dev</code> y <code>pkg-config</code> antes de instalar cargo-generate.</p>
<h3 id="instrucciones-específicas-por-sistema-operativo"><a class="header" href="#instrucciones-específicas-por-sistema-operativo">Instrucciones específicas por sistema operativo</a></h3>
<p>Ahora sigue las instrucciones específicas para el SO que estés usando:</p>
<ul>
<li><a href="intro/install/linux.html">Linux</a></li>
<li><a href="intro/install/windows.html">Windows</a></li>
<li><a href="intro/install/macos.html">macOS</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="linux"><a class="header" href="#linux">Linux</a></h1>
<p>Aquí están los comandos de instalación para algunas distribuciones de Linux.</p>
<h2 id="paquetes"><a class="header" href="#paquetes">Paquetes</a></h2>
<ul>
<li>Ubuntu 18.04 o más reciente / Debian stretch o más reciente</li>
</ul>
<blockquote>
<p><strong>NOTA</strong> <code>gdb-multiarch</code> es el comando GDB que usarás para depurar tus programas ARM Cortex-M</p>
</blockquote>
<!-- Debian stretch -->
<!-- GDB 7.12 -->
<!-- OpenOCD 0.9.0 -->
<!-- QEMU 2.8.1 -->
<!-- Ubuntu 18.04 -->
<!-- GDB 8.1 -->
<!-- OpenOCD 0.10.0 -->
<!-- QEMU 2.11.1 -->
<pre><code class="language-console">sudo apt install gdb-multiarch openocd qemu-system-arm
</code></pre>
<ul>
<li>Ubuntu 14.04 y 16.04</li>
</ul>
<blockquote>
<p><strong>NOTA</strong> <code>arm-none-eabi-gdb</code> es el comando GDB que usarás para depurar tus programas ARM Cortex-M</p>
</blockquote>
<!-- Ubuntu 14.04 -->
<!-- GDB 7.6 (!) -->
<!-- OpenOCD 0.7.0 (?) -->
<!-- QEMU 2.0.0 (?) -->
<pre><code class="language-console">sudo apt install gdb-arm-none-eabi openocd qemu-system-arm
</code></pre>
<ul>
<li>Fedora 27 o más reciente</li>
</ul>
<!-- Fedora 27 -->
<!-- GDB 7.6 (!) -->
<!-- OpenOCD 0.10.0 -->
<!-- QEMU 2.10.2 -->
<pre><code class="language-console">sudo dnf install gdb openocd qemu-system-arm
</code></pre>
<ul>
<li>Arch Linux</li>
</ul>
<blockquote>
<p><strong>NOTA</strong> <code>arm-none-eabi-gdb</code> es el comando GDB que usarás para depurar programas ARM Cortex-M</p>
</blockquote>
<pre><code class="language-console">sudo pacman -S arm-none-eabi-gdb qemu-arch-extra openocd
</code></pre>
<h2 id="reglas-udev"><a class="header" href="#reglas-udev">reglas udev</a></h2>
<p>Esta regla te permite utilizar OpenOCD con la tarjeta Discovery sin privilegios de root.</p>
<p>Cree el archivo <code>/etc/udev/rules.d/70-st-link.rules</code> con el contenido que se muestra a continuación.</p>
<pre><code class="language-text"># STM32F3DISCOVERY rev A/B - ST-LINK/V2
ATTRS{idVendor}==&quot;0483&quot;, ATTRS{idProduct}==&quot;3748&quot;, TAG+=&quot;uaccess&quot;

# STM32F3DISCOVERY rev C+ - ST-LINK/V2-1
ATTRS{idVendor}==&quot;0483&quot;, ATTRS{idProduct}==&quot;374b&quot;, TAG+=&quot;uaccess&quot;
</code></pre>
<p>Y luego, recargar todas las reglas udev con:</p>
<pre><code class="language-console">sudo udevadm control --reload-rules
</code></pre>
<p>Si tenías la tarjeta conectada al portátil, desconéctala y vuelve a conectarla.</p>
<p>Puedes comprobar los permisos ejecutando este comando:</p>
<pre><code class="language-console">lsusb
</code></pre>
<p>Que debería mostrar algo como</p>
<pre><code class="language-text">(..)
Bus 001 Device 018: ID 0483:374b STMicroelectronics ST-LINK/V2.1
(..)
</code></pre>
<p>Toma nota de los números de bus y dispositivo. Use esos números para crear una ruta como <code>/dev/bus/usb/&lt;bus&gt;/&lt;device&gt;</code>. Luego usa esta ruta así:</p>
<pre><code class="language-console">ls -l /dev/bus/usb/001/018
</code></pre>
<pre><code class="language-text">crw-------+ 1 root root 189, 17 Sep 13 12:34 /dev/bus/usb/001/018
</code></pre>
<pre><code class="language-console">getfacl /dev/bus/usb/001/018 | grep user
</code></pre>
<pre><code class="language-text">user::rw-
user:you:rw-
</code></pre>
<p>El signo <code>+</code> añadido a los permisos indica la existencia de un permiso ampliado. El comando <code>getfacl</code> le dice al usuario <code>you</code> que puede hacer uso de este dispositivo.</p>
<p>Ahora, ve a la <a href="intro/install/verify.html">siguiente sección</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="macos"><a class="header" href="#macos">macOS</a></h1>
<p>Todas las herramientas pueden ser instaladas usando <a href="http://brew.sh/">Homebrew</a> o <a href="https://www.macports.org/">MacPorts</a>:</p>
<h2 id="instala-las-herramientas-con-homebrew"><a class="header" href="#instala-las-herramientas-con-homebrew">Instala las herramientas con <a href="http://brew.sh/">Homebrew</a></a></h2>
<pre><code class="language-text">$ # GDB
$ brew install armmbed/formulae/arm-none-eabi-gcc

$ # OpenOCD
$ brew install openocd

$ # QEMU
$ brew install qemu
</code></pre>
<blockquote>
<p><strong>NOTA</strong> Si OpenOCD se cae puede que necesites instalar la última versión usando:</p>
</blockquote>
<pre><code class="language-text">$ brew install --HEAD openocd
</code></pre>
<h2 id="instala-las-herramientas-con-macports"><a class="header" href="#instala-las-herramientas-con-macports">Instala las herramientas con <a href="https://www.macports.org/">MacPorts</a></a></h2>
<pre><code class="language-text">$ # GDB
$ sudo port install arm-none-eabi-gcc

$ # OpenOCD
$ sudo port install openocd

$ # QEMU
$ sudo port install qemu
</code></pre>
<p>¡Eso es todo! anda a la <a href="intro/install/verify.html">siguiente sección</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="windows"><a class="header" href="#windows">Windows</a></h1>
<h2 id="arm-none-eabi-gdb"><a class="header" href="#arm-none-eabi-gdb"><code>arm-none-eabi-gdb</code></a></h2>
<p>ARM proporciona instaladores <code>.exe</code> para Windows. Toma uno de <a href="https://developer.arm.com/open-source/gnu-toolchain/gnu-rm/downloads">aquí</a>, y sigue las instrucciones. Justo antes de que termine el proceso de instalación, marca/selecciona la opción &quot;Add path to environment variable&quot;. Luego verifica que las herramientas están en tu <code>%PATH%</code>:</p>
<pre><code class="language-text">$ arm-none-eabi-gdb -v
GNU gdb (GNU Tools for Arm Embedded Processors 7-2018-q2-update) 8.1.0.20180315-git
(..)
</code></pre>
<h2 id="openocd-1"><a class="header" href="#openocd-1">OpenOCD</a></h2>
<p>No hay una versión binaria oficial de OpenOCD para Windows, pero si no estás de humor para compilarla tú mismo, el proyecto xPack proporciona una distribución binaria, <a href="https://xpack.github.io/openocd/">aquí</a>. Sigue las instrucciones de instalación proporcionadas. A continuación, actualiza tu variable de entorno <code>%PATH%</code> para incluir la ruta donde se instalaron los binarios. (<code>C:\Users\USERNAME\AppData\Roaming\xPacks\@xpack-dev-tools\openocd\0.10.0-13.1\.content\bin\</code>, si usaste la instalación fácil)</p>
<p>Comprueba que OpenOCD está en tu <code>%PATH%</code> con:</p>
<pre><code class="language-text">$ openocd -v
Open On-Chip Debugger 0.10.0
(..)
</code></pre>
<h2 id="qemu"><a class="header" href="#qemu">QEMU</a></h2>
<p>Baja QEMU desde <a href="https://www.qemu.org/download/#windows">el sitio web oficial</a>.</p>
<h2 id="controlador-usb-st-link"><a class="header" href="#controlador-usb-st-link">Controlador USB ST-LINK</a></h2>
<p>También necesitarás instalar <a href="http://www.st.com/en/embedded-software/stsw-link009.html">este controlador USB</a> o OpenOCD no funcionará. Sigue las instrucciones del instalador y asegúrate de instalar la versión correcta (32-bit o 64-bit) del controlador.</p>
<p>¡Eso es todo! anda a la <a href="intro/install/verify.html">siguiente sección</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="verificar-la-instalación"><a class="header" href="#verificar-la-instalación">Verificar la instalación</a></h1>
<p>En esta sección comprobamos que algunas de las herramientas / controladores necesarios se han instalado y configurado correctamente.</p>
<p>Conecta tu computador portátil / PC a la tarjeta discovery mediante un cable micro USB. La placa tiene dos conectores USB; utilice el etiquetado &quot;USB ST-LINK&quot; que se encuentra en el centro del borde de la placa.</p>
<p>Comprueba también que el cabezal ST-LINK está lleno. Ve la imagen siguiente; el cabezal ST-LINK está resaltado.</p>
<p align="center">
<img title="Connected discovery board" src="intro/install/../../assets/verify.jpeg">
</p>
<p>Ahora ejecuta el siguiente comando:</p>
<pre><code class="language-console">openocd -f interface/stlink.cfg -f target/stm32f3x.cfg
</code></pre>
<blockquote>
<p><strong>NOTA</strong>: Las versiones antiguas de openocd, incluida la versión 0.10.0 de 2017, no contienen el nuevo (y preferible) archivo <code>interface/stlink.cfg</code>; en su lugar, es posible que tenga que utilizar <code>interface/stlink-v2.cfg</code> o <code>interface/stlink-v2-1.cfg</code>..</p>
</blockquote>
<p>Debería obtener la siguiente salida y el programa debería bloquear la consola:</p>
<pre><code class="language-text">Open On-Chip Debugger 0.10.0
Licensed under GNU GPL v2
For bug reports, read
        http://openocd.org/doc/doxygen/bugs.html
Info : auto-selecting first available session transport &quot;hla_swd&quot;. To override use 'transport select &lt;transport&gt;'.
adapter speed: 1000 kHz
adapter_nsrst_delay: 100
Info : The selected transport took over low-level target control. The results might differ compared to plain JTAG/SWD
none separate
Info : Unable to match requested speed 1000 kHz, using 950 kHz
Info : Unable to match requested speed 1000 kHz, using 950 kHz
Info : clock speed 950 kHz
Info : STLINK v2 JTAG v27 API v2 SWIM v15 VID 0x0483 PID 0x374B
Info : using stlink api v2
Info : Target voltage: 2.919881
Info : stm32f3x.cpu: hardware has 6 breakpoints, 4 watchpoints
</code></pre>
<p>Puede que el contenido no coincida exactamente, pero deberías obtener la última línea acerca de los <em>breakpoints</em> y <em>watchpoints</em>. Si lo obtienes, finaliza el proceso OpenOCD y pasa a la <a href="intro/install/../../start/index.html">siguiente sección</a>.</p>
<p>Si no obtienes la línea &quot;breakpoints&quot; entonces intenta uno de los siguientes comandos.</p>
<pre><code class="language-console">openocd -f interface/stlink-v2.cfg -f target/stm32f3x.cfg
</code></pre>
<pre><code class="language-console">openocd -f interface/stlink-v2-1.cfg -f target/stm32f3x.cfg
</code></pre>
<p>Si uno de esos comandos funciona, significa que tienes una revisión de hardware antigua de la tarjeta discovery. Esto no será un problema, pero recuerda este hecho ya que necesitarás configurar las cosas de manera diferente más adelante. Puedes pasar a la <a href="intro/install/../../start/index.html">siguiente sección</a>.</p>
<p>Si ninguno de los comandos funciona como usuario normal, intenta ejecutarlos con permisos de root (por ejemplo, <code>sudo openocd ..</code>). Si los comandos funcionan con permisos de root, comprueba que las <a href="intro/install/linux.html#udev-rules">reglas udev</a> se han configurado correctamente.</p>
<p>Si has llegado a este punto y OpenOCD no funciona, abre <a href="https://github.com/rust-embedded/book/issues">una incidencia</a> y te ayudaremos.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="primeros-pasos"><a class="header" href="#primeros-pasos">Primeros pasos</a></h1>
<p>En esta sección te guiaremos a través del proceso de escribir, construir, flashear y depurar programas embebidos. Podrás probar la mayoría de los ejemplos sin ningún hardware especial ya que te mostraremos lo básico usando QEMU, un popular emulador de hardware de código abierto. La única sección donde se requiere hardware es, naturalmente, la sección <a href="start/./hardware.html">Hardware</a>, donde usamos OpenOCD para programar un <a href="http://www.st.com/en/evaluation-tools/stm32f3discovery.html">STM32F3DISCOVERY</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="qemu-1"><a class="header" href="#qemu-1">QEMU</a></h1>
<p>Empezaremos escribiendo un programa para el <a href="http://www.ti.com/product/LM3S6965">LM3S6965</a>, un microcontrolador Cortex-M3. Hemos elegido este como nuestro objetivo inicial porque <a href="https://wiki.qemu.org/Documentation/Platforms/ARM#Supported_in_qemu-system-arm">puede ser emulado</a> usando QEMU por lo que no es necesario juguetear con el hardware en esta sección y podemos centrarnos en las herramientas y el proceso de desarrollo.</p>
<p><strong>IMPORTANTE</strong>
Usaremos el nombre &quot;app&quot; para el nombre del proyecto en este tutorial. Siempre que veas la palabra &quot;app&quot; debes sustituirla por el nombre que hayas seleccionado para tu proyecto. O, también podrías nombrar tu proyecto &quot;app&quot; y evitar las sustituciones.</p>
<h2 id="creando-un-programa-rust-no-estándar"><a class="header" href="#creando-un-programa-rust-no-estándar">Creando un programa Rust no estándar</a></h2>
<p>Usaremos la plantilla de proyecto <a href="https://github.com/rust-embedded/cortex-m-quickstart"><code>cortex-m-quickstart</code></a> para generar un nuevo proyecto a partir de ella. El proyecto creado contendrá una aplicación barebone: un buen punto de partida para una nueva aplicación Rust embebida. Además, el proyecto contendrá un directorio <code>examples</code>, con varias aplicaciones separadas, destacando algunas de las funcionalidades clave de rust embebido.</p>
<h3 id="usando-cargo-generate"><a class="header" href="#usando-cargo-generate">Usando <code>cargo-generate</code></a></h3>
<p>Primero instala cargo-generate</p>
<pre><code class="language-console">cargo install cargo-generate
</code></pre>
<p>Luego genera un nuevo proyecto</p>
<pre><code class="language-console">cargo generate --git https://github.com/rust-embedded/cortex-m-quickstart
</code></pre>
<pre><code class="language-text"> Project Name: app
 Creating project called `app`...
 Done! New project created /tmp/app
</code></pre>
<pre><code class="language-console">cd app
</code></pre>
<h3 id="usando-git"><a class="header" href="#usando-git">Usando <code>git</code></a></h3>
<p>Clonar el repositorio</p>
<pre><code class="language-console">git clone https://github.com/rust-embedded/cortex-m-quickstart app
cd app
</code></pre>
<p>Y luego rellena los marcadores de posición en el archivo <code>Cargo.toml</code>.</p>
<pre><code class="language-toml">[package]
authors = [&quot;{{authors}}&quot;] # &quot;{{authors}}&quot; -&gt; &quot;John Smith&quot;
edition = &quot;2018&quot;
name = &quot;{{project-name}}&quot; # &quot;{{project-name}}&quot; -&gt; &quot;app&quot;
version = &quot;0.1.0&quot;

# ..

[[bin]]
name = &quot;{{project-name}}&quot; # &quot;{{project-name}}&quot; -&gt; &quot;app&quot;
test = false
bench = false
</code></pre>
<h3 id="sin-usar-herramientas"><a class="header" href="#sin-usar-herramientas">Sin usar herramientas</a></h3>
<p>Toma la última instantánea de la plantilla <code>cortex-m-quickstart</code> y extráela.</p>
<pre><code class="language-console">curl -LO https://github.com/rust-embedded/cortex-m-quickstart/archive/master.zip
unzip master.zip
mv cortex-m-quickstart-master app
cd app
</code></pre>
<p>O puedes navegar hasta <a href="https://github.com/rust-embedded/cortex-m-quickstart"><code>cortex-m-quickstart</code></a>, hacer clic en el botón verde &quot;Clonar o descargar&quot; y luego en &quot;Descargar ZIP&quot;.</p>
<p>A continuación, rellena los marcadores de posición en el archivo <code>Cargo.toml</code> como se hace en la segunda parte de la versión &quot;Usando <code>git</code>&quot;.</p>
<h2 id="resumen-del-programa"><a class="header" href="#resumen-del-programa">Resumen del Programa</a></h2>
<p>Por conveniencia aquí están las partes más importantes del código fuente en <code>src/main.rs</code>:</p>
<pre><code class="language-rust ignore">#![no_std]
#![no_main]

use panic_halt as _;

use cortex_m_rt::entry;

#[entry]
fn main() -&gt; ! {
    loop {
        // your code goes here
    }
}</code></pre>
<p>Este programa es un poco diferente de un programa estándar de Rust, así que echemos un vistazo más de cerca.</p>
<p><code>#![no_std]</code> indica que este programa <em>no</em> se enlazará a la <em>crate</em> estándar, <code>std</code>. En su lugar, se enlazará a su subconjunto: la <code>core</code> <em>crate</em>.</p>
<p><code>#![no_main]</code> indica que este programa no usará la interfaz estándar <code>main</code> que usan la mayoría de los programas Rust. La principal razón para usar <code>no_main</code> es que usar la interfaz <code>main</code> en el contexto <code>no_std</code> requiere nightly.</p>
<p><code>use panic_halt as _;</code>. Esta <em>crate</em> proporciona un <code>panic_handler</code> que define el comportamiento de pánico del programa. Cubriremos esto con más detalle en el capítulo <a href="start/panicking.html">Panicking</a> del libro.</p>
<p><a href="https://docs.rs/cortex-m-rt-macros/latest/cortex_m_rt_macros/attr.entry.html"><code>#[entry]</code></a> es un atributo proporcionado por la <em>crate</em> <a href="https://crates.io/crates/cortex-m-rt"><code>cortex-m-rt</code></a> que se utiliza para marcar el punto de entrada del programa. Como no estamos usando la interfaz estándar <code>main</code> necesitamos otra forma de indicar el punto de entrada del programa y esa sería <code>#[entry]</code>.</p>
<p><code>fn main() -&gt; !</code>. Nuestro programa será el <em>único</em> proceso ejecutándose en el hardware de destino, ¡así que no queremos que termine! Usamos una <a href="https://doc.rust-lang.org/rust-by-example/fn/diverging.html">función divergente</a> (el bit <code>-&gt; !</code> en la firma de la función) para asegurar en tiempo de compilación que ese será el caso.</p>
<h2 id="compilación-cruzada"><a class="header" href="#compilación-cruzada">Compilación cruzada</a></h2>
<p>El siguiente paso es <em>compilar</em> el programa para la arquitectura Cortex-M3. Esto es tan sencillo como ejecutar <code>cargo build --target $TRIPLE</code> si tienes claro cuál debe ser el objetivo de compilación (<code>$TRIPLE</code>). Por suerte, el archivo <code>.cargo/config.toml</code> de la plantilla tiene la respuesta:</p>
<pre><code class="language-console">tail -n6 .cargo/config.toml
</code></pre>
<pre><code class="language-toml">[build]
# Pick ONE of these compilation targets
# target = &quot;thumbv6m-none-eabi&quot;    # Cortex-M0 and Cortex-M0+
target = &quot;thumbv7m-none-eabi&quot;    # Cortex-M3
# target = &quot;thumbv7em-none-eabi&quot;   # Cortex-M4 and Cortex-M7 (no FPU)
# target = &quot;thumbv7em-none-eabihf&quot; # Cortex-M4F and Cortex-M7F (with FPU)
</code></pre>
<p>Para realizar la compilación cruzada para la arquitectura Cortex-M3 tenemos que utilizar <code>thumbv7m-none-eabi</code>. Ese <em>target</em> no se instala automáticamente al instalar el toolchain de Rust, ahora sería un buen momento para añadir ese <em>target</em> al toolchain, si aún no lo has hecho:</p>
<pre><code class="language-console">rustup target add thumbv7m-none-eabi
</code></pre>
<p>Dado que el objetivo de compilación <code>thumbv7m-none-eabi</code> ha sido establecido por defecto en tu archivo <code>.cargo/config.toml</code>, los dos comandos siguientes hacen lo mismo:</p>
<pre><code class="language-console">cargo build --target thumbv7m-none-eabi
cargo build
</code></pre>
<h2 id="inspeccionando"><a class="header" href="#inspeccionando">Inspeccionando</a></h2>
<p>Ahora tenemos un binario ELF no nativo en <code>target/thumbv7m-none-eabi/debug/app</code>. Podemos inspeccionarlo usando <code>cargo-binutils</code>.</p>
<p>Con <code>cargo-readobj</code> podemos imprimir las cabeceras ELF para confirmar que se trata de un binario ARM.</p>
<pre><code class="language-console">cargo readobj --bin app -- --file-headers
</code></pre>
<p>Ten en cuenta que:</p>
<ul>
<li><code>--bin app</code> es azúcar para inspeccionar el binario en <code>target/$TRIPLE/debug/app</code>.</li>
<li><code>--bin app</code> también (re)compilará el binario, si es necesario</li>
</ul>
<pre><code class="language-text">ELF Header:
  Magic:   7f 45 4c 46 01 01 01 00 00 00 00 00 00 00 00 00
  Class:                             ELF32
  Data:                              2's complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0x0
  Type:                              EXEC (Executable file)
  Machine:                           ARM
  Version:                           0x1
  Entry point address:               0x405
  Start of program headers:          52 (bytes into file)
  Start of section headers:          153204 (bytes into file)
  Flags:                             0x5000200
  Size of this header:               52 (bytes)
  Size of program headers:           32 (bytes)
  Number of program headers:         2
  Size of section headers:           40 (bytes)
  Number of section headers:         19
  Section header string table index: 18
</code></pre>
<p><code>cargo-size</code> puede imprimir el tamaño de las secciones de enlace del binario.</p>
<pre><code class="language-console">cargo size --bin app --release -- -A
</code></pre>
<p>usamos <code>--release</code> para inspeccionar la versión optimizada</p>
<pre><code class="language-text">app  :
section             size        addr
.vector_table       1024         0x0
.text                 92       0x400
.rodata                0       0x45c
.data                  0  0x20000000
.bss                   0  0x20000000
.debug_str          2958         0x0
.debug_loc            19         0x0
.debug_abbrev        567         0x0
.debug_info         4929         0x0
.debug_ranges         40         0x0
.debug_macinfo         1         0x0
.debug_pubnames     2035         0x0
.debug_pubtypes     1892         0x0
.ARM.attributes       46         0x0
.debug_frame         100         0x0
.debug_line          867         0x0
Total              14570
</code></pre>
<blockquote>
<p>Un repaso a las secciones del enlazador ELF</p>
<ul>
<li><code>.text</code> contiene las instrucciones del programa</li>
<li><code>.rodata</code> contiene valores constantes como cadenas</li>
<li><code>.data</code> contiene variables asignadas estáticamente cuyos valores iniciales son <em>no</em> cero</li>
<li><code>.bss</code> también contiene variables asignadas estáticamente cuyos valores iniciales <em>son</em> cero</li>
<li><code>.vector_table</code> es una sección <em>no</em> estándar que utilizamos para almacenar la tabla de vectores (interrupciones)</li>
<li>Las secciones <code>.ARM.attributes</code> y <code>.debug_*</code> contienen metadatos y <em>no</em> se cargarán en el objetivo al flashear el binario.</li>
</ul>
</blockquote>
<p><strong>IMPORTANTE</strong>: Los archivos ELF contienen metadatos como información de depuración, por lo que su <em>tamaño en disco</em> <em>no</em> refleja con exactitud el espacio que ocupará el programa al ser flasheado en un dispositivo. <em>Usa</em> siempre <code>cargo-size</code> para comprobar el tamaño real de un binario.</p>
<p>Se puede usar <code>cargo-objdump</code> para desensamblar el binario.</p>
<pre><code class="language-console">cargo objdump --bin app --release -- --disassemble --no-show-raw-insn --print-imm-hex
</code></pre>
<blockquote>
<p><strong>NOTA</strong> si el comando anterior se queja de <code>Unknown command line argument</code> mira el siguiente informe de error: https://github.com/rust-embedded/book/issues/269</p>
</blockquote>
<blockquote>
<p><strong>NOTA</strong> esta salida puede diferir en su sistema. Nuevas versiones de rustc, LLVM y bibliotecas pueden generar diferentes ensamblados. Hemos truncado algunas de las instrucciones para mantener el fragmento pequeño.</p>
</blockquote>
<pre><code class="language-text">app:  file format ELF32-arm-little

Disassembly of section .text:
main:
     400: bl  #0x256
     404: b #-0x4 &lt;main+0x4&gt;

Reset:
     406: bl  #0x24e
     40a: movw  r0, #0x0
     &lt; .. truncated any more instructions .. &gt;

DefaultHandler_:
     656: b #-0x4 &lt;DefaultHandler_&gt;

UsageFault:
     657: strb  r7, [r4, #0x3]

DefaultPreInit:
     658: bx  lr

__pre_init:
     659: strb  r7, [r0, #0x1]

__nop:
     65a: bx  lr

HardFaultTrampoline:
     65c: mrs r0, msp
     660: b #-0x2 &lt;HardFault_&gt;

HardFault_:
     662: b #-0x4 &lt;HardFault_&gt;

HardFault:
     663: &lt;unknown&gt;
</code></pre>
<h2 id="ejecutando"><a class="header" href="#ejecutando">Ejecutando</a></h2>
<p>A continuación, ¡vamos a ver cómo ejecutar un programa embebido en QEMU! Esta vez usaremos el ejemplo <code>hello</code> que realmente hace algo.</p>
<p>Por conveniencia aquí está el código fuente de <code>examples/hello.rs</code>:</p>
<pre><code class="language-rust ignore">//! Escribe &quot;Hola, mundo!&quot;en la consola del anfitrión usando semihosting

#![no_main]
#![no_std]

use panic_halt as _;

use cortex_m_rt::entry;
use cortex_m_semihosting::{debug, hprintln};

#[entry]
fn main() -&gt; ! {
    hprintln!(&quot;Hola, mundo!&quot;).unwrap();

    // salir de QEMU
    // NOTA no ejecute esto en el hardware; puede corromper el estado del OpenOCD
    debug::exit(debug::EXIT_SUCCESS);

    loop {}
}</code></pre>
<p>Este programa usa algo llamado semihosting para imprimir texto en la consola <em>host</em>. Cuando se usa hardware real esto requiere una sesión de depuración pero cuando se usa QEMU esto simplemente funciona.</p>
<p>Empecemos compilando el ejemplo:</p>
<pre><code class="language-console">cargo build --example hello
</code></pre>
<p>El binario de salida estará localizado en <code>target/thumbv7m-none-eabi/debug/examples/hello</code>.</p>
<p>Para ejecutar este binario en QEMU ejecute el siguiente comando:</p>
<pre><code class="language-console">qemu-system-arm \
  -cpu cortex-m3 \
  -machine lm3s6965evb \
  -nographic \
  -semihosting-config enable=on,target=native \
  -kernel target/thumbv7m-none-eabi/debug/examples/hello
</code></pre>
<pre><code class="language-text">Hello, world!
</code></pre>
<p>El comando debería salir con éxito (código de salida = 0) después de imprimir el texto. En *nix puedes comprobarlo con el siguiente comando:</p>
<pre><code class="language-console">echo $?
</code></pre>
<pre><code class="language-text">0
</code></pre>
<p>Vamos a desglosar ese comando QEMU:</p>
<ul>
<li>
<p><code>qemu-system-arm</code>. Este es el emulador QEMU. Hay algunas variantes de estos binarios QEMU; éste hace una emulación completa del <em>sistema</em> de máquinas <em>ARM</em>, de ahí el nombre.</p>
</li>
<li>
<p><code>-cpu cortex-m3</code>. Esto le dice a QEMU que emule una CPU Cortex-M3. Especificar el modelo de CPU nos permite detectar algunos errores de compilación: por ejemplo, ejecutar un programa compilado para Cortex-M4F, que tiene una FPU por hardware, hará que QEMU se equivoque durante su ejecución.</p>
</li>
<li>
<p><code>-machine lm3s6965evb</code>. Esto le dice a QEMU que emule el LM3S6965EVB, una tarjeta de evaluación que contiene un microcontrolador LM3S6965.</p>
</li>
<li>
<p><code>-nographic</code>. Esto le dice a QEMU que no lance su GUI.</p>
</li>
<li>
<p><code>-semihosting-config (..)</code>. Esto le dice a QEMU que habilite semihosting. Semihosting permite al dispositivo emulado, entre otras cosas, utilizar el stdout, stderr y stdin del host y crear archivos en el host.</p>
</li>
<li>
<p><code>-kernel $file</code>. Esto le dice a QEMU qué binario cargar y ejecutar en la máquina emulada.</p>
</li>
</ul>
<p>¡Escribir ese largo comando QEMU es demasiado trabajo! Podemos configurar un <em>runner</em> personalizado para simplificar el proceso. El archivo <code>.cargo/config.toml</code> tiene un <em>runner</em> comentado que invoca a QEMU; vamos a descomentarlo:</p>
<pre><code class="language-console">head -n3 .cargo/config.toml
</code></pre>
<pre><code class="language-toml">[target.thumbv7m-none-eabi]
# uncomment this to make `cargo run` execute programs on QEMU
runner = &quot;qemu-system-arm -cpu cortex-m3 -machine lm3s6965evb -nographic -semihosting-config enable=on,target=native -kernel&quot;
</code></pre>
<p>Este <em>runner</em> sólo se aplica al objetivo <code>thumbv7m-none-eabi</code>, que es nuestro objetivo de compilación por defecto. Ahora <code>cargo run</code> compilará el programa y lo ejecutará en QEMU:</p>
<pre><code class="language-console">cargo run --example hello --release
</code></pre>
<pre><code class="language-text">   Compiling app v0.1.0 (file:///tmp/app)
    Finished release [optimized + debuginfo] target(s) in 0.26s
     Running `qemu-system-arm -cpu cortex-m3 -machine lm3s6965evb -nographic -semihosting-config enable=on,target=native -kernel target/thumbv7m-none-eabi/release/examples/hello`
Hello, world!
</code></pre>
<h2 id="depuración"><a class="header" href="#depuración">Depuración</a></h2>
<p>La depuración es crítica para el desarrollo embebido. Veamos cómo se hace.</p>
<p>Depurar un dispositivo embebido implica depuración <em>remota</em> ya que el programa que queremos depurar no se estará ejecutando en la máquina que está ejecutando el programa depurador (GDB o LLDB).</p>
<p>La depuración remota implica un cliente y un servidor. En una configuración QEMU, el cliente será un proceso GDB (o LLDB) y el servidor será el proceso QEMU que también está ejecutando el programa embebido.</p>
<p>En esta sección usaremos el ejemplo <code>hello</code> que ya hemos compilado.</p>
<p>El primer paso para depurar es lanzar QEMU en modo depuración:</p>
<pre><code class="language-console">qemu-system-arm \
  -cpu cortex-m3 \
  -machine lm3s6965evb \
  -nographic \
  -semihosting-config enable=on,target=native \
  -gdb tcp::3333 \
  -S \
  -kernel target/thumbv7m-none-eabi/debug/examples/hello
</code></pre>
<p>Este comando no imprimirá nada en la consola y bloqueará el terminal. Esta vez hemos pasado dos banderas extra</p>
<ul>
<li>
<p><code>-gdb tcp::3333</code>. Esto le dice a QEMU que espere una conexión GDB en el puerto TCP 3333.</p>
</li>
<li>
<p><code>-S</code>. Esto le dice a QEMU que congele la máquina en el arranque. Sin esto el programa habría llegado al final de main ¡antes de que tuviéramos la oportunidad de lanzar el depurador!</p>
</li>
</ul>
<p>A continuación lanzamos GDB en otro terminal y le decimos que cargue los símbolos de depuración del ejemplo:</p>
<pre><code class="language-console">gdb-multiarch -q target/thumbv7m-none-eabi/debug/examples/hello
</code></pre>
<p><strong>NOTA</strong>: puede que necesite otra versión de gdb en lugar de <code>gdb-multiarch</code> dependiendo de la que haya instalado en el capítulo de instalación. También podría ser <code>arm-none-eabi-gdb</code> o simplemente <code>gdb</code>.</p>
<p>A continuación, dentro de la shell GDB nos conectamos a QEMU, usando el comando <code>target</code>, que está esperando una conexión en el puerto TCP 3333.</p>
<pre><code class="language-console">target remote :3333
</code></pre>
<pre><code class="language-text">Remote debugging using :3333
Reset () at $REGISTRY/cortex-m-rt-0.6.1/src/lib.rs:473
473     pub unsafe extern &quot;C&quot; fn Reset() -&gt; ! {
</code></pre>
<p>Verás que el proceso se detiene y que el contador del programa apunta a una función llamada <code>Reset</code>. Este es el manejador de reset: lo que los núcleos Cortex-M ejecutan al arrancar.</p>
<blockquote>
<p>Ten en cuenta que en algunas configuraciones, en lugar de mostrar la línea <code>Reset () at $REGISTRY/cortex-m-rt-0.6.1/src/lib.rs:473</code> como se muestra arriba, gdb puede imprimir algunas advertencias como:</p>
<p><code>core::num::bignum::Big32x40::mul_small () at src/libcore/num/bignum.rs:254</code> 
<code>    src/libcore/num/bignum.rs: No such file or directory.</code></p>
<p>Es un fallo conocido. Puedes ignorar con seguridad esas advertencias, lo más probable es que estés en Reset().</p>
</blockquote>
<p>Este manejador de reset eventualmente llamará a nuestra función principal. Saltemos todo el camino hasta allí usando un <em>breakpoint</em> y el comando <code>continue</code>. Para establecer el punto de ruptura, primero echemos un vistazo a dónde nos gustaría hacer el <em>break</em> en nuestro código, con el comando <code>list</code>.</p>
<pre><code class="language-console">list main
</code></pre>
<p>Esto mostrará el código fuente, del archivo examples/hello.rs.</p>
<pre><code class="language-text">6       use panic_halt as _;
7
8       use cortex_m_rt::entry;
9       use cortex_m_semihosting::{debug, hprintln};
10
11      #[entry]
12      fn main() -&gt; ! {
13          hprintln!(&quot;Hello, world!&quot;).unwrap();
14
15          // exit QEMU
</code></pre>
<p>Nos gustaría añadir un <em>breakpoint</em> justo antes del &quot;¡Hola, mundo!&quot;, que está en la línea 13. Lo hacemos con el comando <code>break</code>:</p>
<pre><code class="language-console">break 13
</code></pre>
<p>Ahora podemos ordenar a gdb que ejecute hasta nuestra función principal, con el comando <code>continue</code>:</p>
<pre><code class="language-console">continue
</code></pre>
<pre><code class="language-text">Continuing.

Breakpoint 1, hello::__cortex_m_rt_main () at examples\hello.rs:13
13          hprintln!(&quot;Hello, world!&quot;).unwrap();
</code></pre>
<p>Ya estamos cerca del código que imprime &quot;Hello, world!&quot;. Avancemos usando el comando <code>next</code>.</p>
<pre><code class="language-console">next
</code></pre>
<pre><code class="language-text">16          debug::exit(debug::EXIT_SUCCESS);
</code></pre>
<p>En este punto deberías ver &quot;Hello, world!&quot; impreso en el terminal que está ejecutando <code>qemu-system-arm</code>.</p>
<pre><code class="language-text">$ qemu-system-arm (..)
Hello, world!
</code></pre>
<p>Llamando de nuevo a <code>next</code> terminará el proceso QEMU.</p>
<pre><code class="language-console">next
</code></pre>
<pre><code class="language-text">[Inferior 1 (Remote target) exited normally]
</code></pre>
<p>Ahora puedes salir de la sesión GDB.</p>
<pre><code class="language-console">quit
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hardware"><a class="header" href="#hardware">Hardware</a></h1>
<p>A estas alturas ya deberías estar familiarizado con las herramientas y el proceso de desarrollo. En esta sección cambiaremos a hardware real; el proceso seguirá siendo en gran medida el mismo. Empecemos.</p>
<h2 id="conoce-tu-hardware-1"><a class="header" href="#conoce-tu-hardware-1">Conoce tu hardware</a></h2>
<p>Antes de empezar es necesario identificar algunas características del dispositivo de destino, ya que se utilizarán para configurar el proyecto:</p>
<ul>
<li>
<p>El núcleo ARM. Por ejemplo, Cortex-M3.</p>
</li>
<li>
<p>¿Incluye el núcleo ARM una FPU? Los núcleos Cortex-M4<strong>F</strong> y Cortex-M7<strong>F</strong> sí.</p>
</li>
<li>
<p>¿Cuánta memoria Flash y RAM tiene el dispositivo de destino? Por ejemplo, 256 KiB de Flash y 32 KiB de RAM.</p>
</li>
<li>
<p>¿Dónde están mapeadas la memoria Flash y la RAM en el espacio de direcciones? Por ejemplo, la RAM se encuentra normalmente en la dirección <code>0x2000_0000</code>.</p>
</li>
</ul>
<p>Puedes encontrar esta información en la hoja de datos o en el manual de referencia de tu dispositivo.</p>
<p>En esta sección utilizaremos nuestro hardware de referencia, la STM32F3DISCOVERY. Esta tarjeta contiene un microcontrolador STM32F303VCT6. Este microcontrolador tiene:</p>
<ul>
<li>
<p>Un núcleo Cortex-M4F que incluye una FPU de precisión simple</p>
</li>
<li>
<p>256 KiB de Flash localizados en la dirección 0x0800_0000.</p>
</li>
<li>
<p>40 KiB de RAM localizados en la dirección 0x2000_0000. (Hay otra región de RAM pero por simplicidad la ignoraremos).</p>
</li>
</ul>
<h2 id="configuración"><a class="header" href="#configuración">Configuración</a></h2>
<p>Empezaremos desde cero con una instancia de plantilla nueva. Consulta la <a href="start/qemu.html">sección anterior sobre QEMU</a> para refrescar cómo hacer esto sin <code>cargo-generate</code>.</p>
<pre><code class="language-text">$ cargo generate --git https://github.com/rust-embedded/cortex-m-quickstart
 Project Name: app
 Creating project called `app`...
 Done! New project created /tmp/app

$ cd app
</code></pre>
<p>El paso número uno es establecer un objetivo de compilación por defecto en <code>.cargo/config.toml</code>.</p>
<pre><code class="language-console">tail -n5 .cargo/config.toml
</code></pre>
<pre><code class="language-toml"># Pick ONE of these compilation targets
# target = &quot;thumbv6m-none-eabi&quot;    # Cortex-M0 and Cortex-M0+
# target = &quot;thumbv7m-none-eabi&quot;    # Cortex-M3
# target = &quot;thumbv7em-none-eabi&quot;   # Cortex-M4 and Cortex-M7 (no FPU)
target = &quot;thumbv7em-none-eabihf&quot; # Cortex-M4F and Cortex-M7F (with FPU)
</code></pre>
<p>Usaremos <code>thumbv7em-none-eabihf</code> ya que cubre el núcleo Cortex-M4F.</p>
<p>El segundo paso es introducir la información de la región de memoria en el archivo <code>memory.x</code>.</p>
<pre><code class="language-text">$ cat memory.x
/* Linker script for the STM32F303VCT6 */
MEMORY
{
  /* NOTE 1 K = 1 KiBi = 1024 bytes */
  FLASH : ORIGIN = 0x08000000, LENGTH = 256K
  RAM : ORIGIN = 0x20000000, LENGTH = 40K
}
</code></pre>
<blockquote>
<p><strong>NOTA</strong>: Si por alguna razón ha cambiado el archivo <code>memory.x</code> después de haber hecho
la primera compilación de un objetivo de compilación específico, entonces haz <code>cargo clean</code> antes de
de <code>cargo build</code>, porque <code>cargo build</code> puede no seguir las actualizaciones de <code>memory.x</code>.</p>
</blockquote>
<p>Empezaremos con el ejemplo hello de nuevo, pero primero tenemos que hacer un pequeño cambio.</p>
<p>En <code>examples/hello.rs</code>, asegúrate de que la llamada <code>debug::exit()</code> está comentada o eliminada. Se utiliza sólo para ejecutar en QEMU.</p>
<pre><code class="language-rust ignore">#[entry]
fn main() -&gt; ! {
    hprintln!(&quot;Hello, world!&quot;).unwrap();

    // exit QEMU
    // NOTE do not run this on hardware; it can corrupt OpenOCD state
    // debug::exit(debug::EXIT_SUCCESS);

    loop {}
}</code></pre>
<p>Ahora puedes compilar programas usando <code>cargo build</code> e inspeccionar los binarios usando <code>cargo-binutils</code> como hacías antes. La <em>crate</em> <code>cortex-m-rt</code> se encarga de toda la magia necesaria para que tu chip funcione, ya que prácticamente todas las CPUs Cortex-M arrancan de la misma manera.</p>
<pre><code class="language-console">cargo build --example hello
</code></pre>
<h2 id="depuración-1"><a class="header" href="#depuración-1">Depuración</a></h2>
<p>La depuración será un poco diferente. De hecho, los primeros pasos pueden parecer diferentes dependiendo del dispositivo de destino. En esta sección mostraremos los pasos necesarios para depurar un programa que se ejecuta en el STM32F3DISCOVERY. Esto debe servir como referencia; para información específica del dispositivo sobre depuración consulte el <a href="https://github.com/rust-embedded/debugonomicon">Debugonomicon</a>.</p>
<p>Como antes haremos depuración remota y el cliente será un proceso GDB. Esta vez, sin embargo, el servidor será OpenOCD.</p>
<p>Como se hizo durante la sección <a href="start/../intro/install/verify.html">verificar</a> conecte la tarjeta discovery a su portátil / PC y compruebe que la cabecera ST-LINK está poblada.</p>
<p>En un terminal, ejecute <code>openocd</code> para conectarse al ST-LINK de la tarjeta discovery. Ejecute este comando desde la raíz de la plantilla; <code>openocd</code> leerá el archivo <code>openocd.cfg</code> que indica qué archivo de interfaz y archivo de destino utilizar.</p>
<pre><code class="language-console">cat openocd.cfg
</code></pre>
<pre><code class="language-text"># Sample OpenOCD configuration for the STM32F3DISCOVERY development board

# Depending on the hardware revision you got you'll have to pick ONE of these
# interfaces. At any time only one interface should be commented out.

# Revision C (newer revision)
source [find interface/stlink.cfg]

# Revision A and B (older revisions)
# source [find interface/stlink-v2.cfg]

source [find target/stm32f3x.cfg]
</code></pre>
<blockquote>
<p><strong>NOTA</strong> Si descubriste que tienes una revisión anterior de la tarjeta discovery
durante la sección <a href="start/../intro/install/verify.html">verificar</a> entonces debe modificar el archivo <code>openocd.cfg</code>
en este punto para usar <code>interface/stlink-v2.cfg</code>.</p>
</blockquote>
<pre><code class="language-text">$ openocd
Open On-Chip Debugger 0.10.0
Licensed under GNU GPL v2
For bug reports, read
        http://openocd.org/doc/doxygen/bugs.html
Info : auto-selecting first available session transport &quot;hla_swd&quot;. To override use 'transport select &lt;transport&gt;'.
adapter speed: 1000 kHz
adapter_nsrst_delay: 100
Info : The selected transport took over low-level target control. The results might differ compared to plain JTAG/SWD
none separate
Info : Unable to match requested speed 1000 kHz, using 950 kHz
Info : Unable to match requested speed 1000 kHz, using 950 kHz
Info : clock speed 950 kHz
Info : STLINK v2 JTAG v27 API v2 SWIM v15 VID 0x0483 PID 0x374B
Info : using stlink api v2
Info : Target voltage: 2.913879
Info : stm32f3x.cpu: hardware has 6 breakpoints, 4 watchpoints
</code></pre>
<p>En otro terminal ejecute GDB, también desde la raíz de la plantilla.</p>
<pre><code class="language-text">gdb-multiarch -q target/thumbv7em-none-eabihf/debug/examples/hello
</code></pre>
<p><strong>NOTA</strong>: como antes, puede que necesites otra versión de gdb en lugar de <code>gdb-multiarch</code> dependiendo de la que haya instalado en el capítulo de instalación. También puede ser <code>arm-none-eabi-gdb</code> o simplemente <code>gdb</code>.</p>
<p>A continuación conecte GDB a OpenOCD, que está esperando una conexión TCP en el puerto 3333 utilizando el comando <code>target</code>.</p>
<pre><code class="language-console">(gdb) target remote :3333
Remote debugging using :3333
0x00000000 in ?? ()
</code></pre>
<p>Ahora proceda a <em>flashear</em> (cargar) el programa en el microcontrolador utilizando el comando <code>load</code>.</p>
<pre><code class="language-console">(gdb) load
Loading section .vector_table, size 0x400 lma 0x8000000
Loading section .text, size 0x1518 lma 0x8000400
Loading section .rodata, size 0x414 lma 0x8001918
Start address 0x08000400, load size 7468
Transfer rate: 13 KB/sec, 2489 bytes/write.
</code></pre>
<p>El programa ya está cargado. Este programa usa semihosting así que antes de hacer cualquier llamada a semihosting tenemos que decirle a OpenOCD que habilite semihosting. Puedes enviar comandos a OpenOCD usando el comando <code>monitor</code>.</p>
<pre><code class="language-console">(gdb) monitor arm semihosting enable
semihosting is enabled
</code></pre>
<blockquote>
<p>Puedes ver todos los comandos de OpenOCD invocando el comando <code>monitor help</code>.</p>
</blockquote>
<p>Como antes podemos saltar hasta <code>main</code> usando un <em>breakpoint</em> y el comando <code>continue</code>.</p>
<pre><code class="language-console">(gdb) break main
Breakpoint 1 at 0x8000490: file examples/hello.rs, line 11.
Note: automatically using hardware breakpoints for read-only addresses.

(gdb) continue
Continuing.

Breakpoint 1, hello::__cortex_m_rt_main_trampoline () at examples/hello.rs:11
11      #[entry]
</code></pre>
<blockquote>
<p><strong>NOTA</strong> Si GDB bloquea el terminal en lugar de parar en el <em>breakpoint</em> después de
ejecutar el comando <code>continue</code> anterior, es posible que quieras volver a comprobar que
la información de la región de memoria en el archivo <code>memory.x</code> está configurada correctamente.
para tu dispositivo (tanto los inicios como las longitudes).</p>
</blockquote>
<p>Entra en la función principal con <code>step</code>.</p>
<pre><code class="language-console">(gdb) step
halted: PC: 0x08000496
hello::__cortex_m_rt_main () at examples/hello.rs:13
13          hprintln!(&quot;Hello, world!&quot;).unwrap();
</code></pre>
<p>Después de hacer avanzar el programa con <code>next</code> deberías ver &quot;Hello, world!&quot; impreso en la consola de OpenOCD, entre otras cosas.</p>
<pre><code class="language-console">$ openocd
(..)
Info : halted: PC: 0x08000502
Hello, world!
Info : halted: PC: 0x080004ac
Info : halted: PC: 0x080004ae
Info : halted: PC: 0x080004b0
Info : halted: PC: 0x080004b4
Info : halted: PC: 0x080004b8
Info : halted: PC: 0x080004bc
</code></pre>
<p>El mensaje sólo se muestra una vez cuando el programa está a punto de entrar en el bucle infinito definido en la línea 19: <code>loop {}</code>.</p>
<p>Ahora puedes salir de GDB usando el comando <code>quit</code>.</p>
<pre><code class="language-console">(gdb) quit
A debugging session is active.

        Inferior 1 [Remote target] will be detached.

Quit anyway? (y or n)
</code></pre>
<p>La depuración ahora requiere algunos pasos más, así que hemos empaquetado todos esos pasos en un único script GDB llamado <code>openocd.gdb</code>. El archivo fue creado durante el paso <code>cargo generate</code>, y debería funcionar sin modificaciones. Echemos un vistazo:</p>
<pre><code class="language-console">cat openocd.gdb
</code></pre>
<pre><code class="language-text">target extended-remote :3333

# print demangled symbols
set print asm-demangle on

# detect unhandled exceptions, hard faults and panics
break DefaultHandler
break HardFault
break rust_begin_unwind

monitor arm semihosting enable

load

# start the process but immediately halt the processor
stepi
</code></pre>
<p>Ahora ejecutando <code>&lt;gdb&gt; -x openocd.gdb target/thumbv7em-none-eabihf/debug/examples/hello</code> conectará inmediatamente GDB a OpenOCD, habilitará el semihosting, cargará el programa e iniciará el proceso.</p>
<p>Alternativamente, puedes convertir <code>&lt;gdb&gt; -x openocd.gdb</code> en un runner personalizado para hacer que <code>cargo run</code> construya un programa <em>y</em> comience una sesión GDB. Este runner está incluido en <code>.cargo/config.toml</code> pero está comentado.</p>
<pre><code class="language-console">head -n10 .cargo/config.toml
</code></pre>
<pre><code class="language-toml">[target.thumbv7m-none-eabi]
# uncomment this to make `cargo run` execute programs on QEMU
# runner = &quot;qemu-system-arm -cpu cortex-m3 -machine lm3s6965evb -nographic -semihosting-config enable=on,target=native -kernel&quot;

[target.'cfg(all(target_arch = &quot;arm&quot;, target_os = &quot;none&quot;))']
# uncomment ONE of these three option to make `cargo run` start a GDB session
# which option to pick depends on your system
runner = &quot;arm-none-eabi-gdb -x openocd.gdb&quot;
# runner = &quot;gdb-multiarch -x openocd.gdb&quot;
# runner = &quot;gdb -x openocd.gdb&quot;
</code></pre>
<pre><code class="language-text">$ cargo run --example hello
(..)
Loading section .vector_table, size 0x400 lma 0x8000000
Loading section .text, size 0x1e70 lma 0x8000400
Loading section .rodata, size 0x61c lma 0x8002270
Start address 0x800144e, load size 10380
Transfer rate: 17 KB/sec, 3460 bytes/write.
(gdb)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="registros-mapeados-en-memoria"><a class="header" href="#registros-mapeados-en-memoria">Registros Mapeados en Memoria</a></h1>
<p>Los sistemas embebidos sólo pueden llegar hasta cierto punto ejecutando código Rust normal y moviendo datos en la RAM. Si queremos obtener cualquier información dentro o fuera de nuestro sistema (ya sea parpadeando un LED, detectando la pulsación de un botón o comunicándonos con un periférico fuera del chip en algún tipo de bus) vamos a tener que sumergirnos en el mundo de los periféricos y sus 'registros mapeados en memoria'.</p>
<p>Es muy posible que el código que necesitas para acceder a los periféricos de tu microcontrolador ya esté escrito, en alguno de los siguientes niveles:</p>
<p align="center">
<img title="Common crates" src="start/../assets/crates.png">
</p>
<ul>
<li><em>Crate</em> de Micro-arquitectura - Este tipo de <em>crate</em> maneja cualquier rutina útil común al núcleo del procesador que tu microcontrolador está utilizando, así como cualquier periférico que sea común a todos los microcontroladores que utilizan ese tipo particular de núcleo de procesador. Por ejemplo, la <em>crate</em> <a href="https://crates.io/crates/cortex-m">cortex-m</a> le proporciona funciones para activar y desactivar interrupciones, que son las mismas para todos los microcontroladores basados en Cortex-M. También le da acceso al periférico 'SysTick' incluido con todos los microcontroladores basados en Cortex-M.</li>
<li><em>Crate</em> de Acceso a Periféricos (PAC) - Este tipo de <em>crate</em> es una fina envoltura sobre los diversos registros de memoria definidos para el número de parte del micro-controlador que está utilizando. Por ejemplo, <a href="https://crates.io/crates/tm4c123x">tm4c123x</a> para la serie Texas Instruments Tiva-C TM4C123, o <a href="https://crates.io/crates/stm32f30x">stm32f30x</a> para la serie ST-Micro STM32F30x. Aquí, interactuarás con los registros directamente, siguiendo las instrucciones de funcionamiento de cada periférico dadas en el Manual de Referencia Técnica de tu micro-controlador.</li>
<li><em>Crate</em> de HAL - Estas <em>crates</em> ofrecen una API más amigable para tu procesador en particular, a menudo implementando algunos <em>traits</em> comunes definidos en <a href="https://crates.io/crates/embedded-hal">embedded-hal</a>. Por ejemplo, esta <em>crate</em> podría ofrecer una estructura <code>Serial</code>, con un constructor que toma un conjunto apropiado de pines GPIO y una tasa de baudios, y ofrece algún tipo de función <code>write_byte</code> para enviar datos. Ver el capítulo sobre [Portabilidad] para más información sobre <a href="https://crates.io/crates/embedded-hal">embedded-hal</a>.</li>
<li><em>Crate</em> de Tarjeta - Estas <em>crates</em> van un paso más allá que una HAL <em>Crate</em> preconfigurando varios periféricos y pines GPIO para adaptarse al kit de desarrollo específico o tarjeta que esté utilizando, como <a href="https://crates.io/crates/stm32f3-discovery">stm32f3-discovery</a> para la tarjeta STM32F3DISCOVERY.</li>
</ul>
<h2 id="crate-de-tarjeta"><a class="header" href="#crate-de-tarjeta"><em>Crate</em> de Tarjeta</a></h2>
<p>Una <em>board crate</em> o <em>crate</em> de tarjeta es el punto de partida perfecto, si eres nuevo en Rust embebido. Abstraen muy bien los detalles de HW que pueden ser abrumadores cuando se empieza a estudiar este tema, y hace que las tareas estándar sean fáciles, como encender o apagar un LED. La funcionalidad que expone varía mucho entre tarjetas. Dado que este libro tiene como objetivo permanecer agnóstico al hardware, las <em>board crates</em> no serán cubiertos por este libro.</p>
<p>Si quieres experimentar con la tarjeta STM32F3DISCOVERY, es muy recomendable echar un vistazo a la <em>crate</em> de la tarjeta <a href="https://crates.io/crates/stm32f3-discovery">stm32f3-discovery</a>, que proporciona funcionalidad para hacer parpadear los LEDs de la tarjeta, acceder a su brújula, bluetooth y mucho más. El libro <a href="https://rust-embedded.github.io/discovery/">Discovery</a> ofrece una gran introducción al uso de una board <em>crate</em>.</p>
<p>Pero si estás trabajando en un sistema que todavía no tiene una board <em>crate</em> dedicado, o necesitas una funcionalidad que no proporcionan las <em>crates</em> existentes, sigue leyendo mientras empezamos desde abajo, con las <em>crates</em> de micro-arquitectura.</p>
<h2 id="crate-de-micro-arquitectura"><a class="header" href="#crate-de-micro-arquitectura"><em>Crate</em> de Micro-arquitectura</a></h2>
<p>Veamos el periférico SysTick que es común a todos los microcontroladores basados en Cortex-M. Podemos encontrar una API de muy bajo nivel en la <a href="https://crates.io/crates/cortex-m">cortex-m</a> <em>crate</em>, y podemos usarlo así:</p>
<pre><code class="language-rust ignore">#![no_std]
#![no_main]
use cortex_m::peripheral::{syst, Peripherals};
use cortex_m_rt::entry;
use panic_halt as _;

#[entry]
fn main() -&gt; ! {
    let peripherals = Peripherals::take().unwrap();
    let mut systick = peripherals.SYST;
    systick.set_clock_source(syst::SystClkSource::Core);
    systick.set_reload(1_000);
    systick.clear_current();
    systick.enable_counter();
    while !systick.has_wrapped() {
        // Loop
    }

    loop {}
}</code></pre>
<p>Las funciones de la estructura <code>SYST</code> se asemejan bastante a la funcionalidad definida en el Manual de Referencia Técnica de ARM para este periférico. No hay nada en esta API sobre 'retrasar X milisegundos' - tenemos que implementarlo nosotros mismos usando un bucle <code>while</code>. Ten en cuenta que no podemos acceder a nuestra estructura <code>SYST</code> hasta que hayamos llamado a <code>Peripherals::take()</code> - esta es una rutina especial que garantiza que sólo hay una estructura <code>SYST</code> en todo nuestro programa. Para más información, consulta la sección <a href="start/../peripherals/index.html">Periféricos</a>.</p>
<h2 id="usando-una-peripheral-access-crate-pac-o-una-crate-de-acceso-a-periféricos"><a class="header" href="#usando-una-peripheral-access-crate-pac-o-una-crate-de-acceso-a-periféricos">Usando una <em>Peripheral Access Crate</em> (PAC) o una <em>Crate</em> de Acceso a Periféricos</a></h2>
<p>No llegaremos muy lejos con nuestro desarrollo de software embebido si nos limitamos sólo a los periféricos básicos incluidos con cada Cortex-M. En algún momento, vamos a necesitar escribir algún código que sea específico para el micro-controlador en particular que estamos utilizando. En este ejemplo, vamos a suponer que tenemos un Texas Instruments TM4C123 - un Cortex-M4 medio de 80MHz con 256 KiB de Flash. Vamos a utilizar la <em>crate</em> <a href="https://crates.io/crates/tm4c123x">tm4c123x</a> para hacer uso de este chip.</p>
<pre><code class="language-rust ignore">#![no_std]
#![no_main]

use panic_halt as _; // panic handler

use cortex_m_rt::entry;
use tm4c123x;

#[entry]
pub fn init() -&gt; (Delay, Leds) {
    let cp = cortex_m::Peripherals::take().unwrap();
    let p = tm4c123x::Peripherals::take().unwrap();

    let pwm = p.PWM0;
    pwm.ctl.write(|w| w.globalsync0().clear_bit());
    // Mode = 1 =&gt; Count up/down mode
    pwm._2_ctl.write(|w| w.enable().set_bit().mode().set_bit());
    pwm._2_gena.write(|w| w.actcmpau().zero().actcmpad().one());
    // 528 cycles (264 up and down) = 4 loops per video line (2112 cycles)
    pwm._2_load.write(|w| unsafe { w.load().bits(263) });
    pwm._2_cmpa.write(|w| unsafe { w.compa().bits(64) });
    pwm.enable.write(|w| w.pwm4en().set_bit());
}
</code></pre>
<p>Hemos accedido al periférico <code>PWM0</code> exactamente de la misma forma que antes accedimos al periférico <code>SYST</code>, excepto que hemos llamado a <code>tm4c123x::Peripherals::take()</code>. Como esta <em>crate</em> fue auto-generada usando <a href="https://crates.io/crates/svd2rust">svd2rust</a>, las funciones de acceso para nuestros campos de registro toman una <em>closure</em>, en lugar de un argumento numérico. Aunque esto parece un montón de código, el compilador de Rust puede utilizarlo para realizar un montón de comprobaciones por nosotros, ¡pero luego genera código máquina que es bastante parecido al ensamblador escrito a mano! Cuando el código autogenerado no es capaz de determinar que todos los posibles argumentos de una función accesoria en particular son válidos (por ejemplo, si el SVD define el registro como de 32 bits, pero no dice si algunos de esos valores de 32 bits tienen un significado especial), entonces la función se marca como <code>unsafe</code>. Podemos ver esto en el ejemplo anterior cuando se establecen los subcampos <code>load</code> y <code>compa</code> usando la función <code>bits()</code>.</p>
<h3 id="lectura"><a class="header" href="#lectura">Lectura</a></h3>
<p>La función <code>read()</code> devuelve un objeto que da acceso de sólo lectura a los distintos subcampos dentro de este registro, tal y como se define en el archivo SVD del fabricante para este chip. Puede encontrar todas las funciones disponibles en el tipo de retorno especial <code>R</code> para este registro en particular, en este periférico en particular, en este chip en particular, en la <a href="https://docs.rs/tm4c123x/0.7.0/tm4c123x/pwm0/ctl/struct.R.html">documentación tm4c123x</a>.</p>
<pre><code class="language-rust ignore">if pwm.ctl.read().globalsync0().is_set() {
    // Do a thing
}</code></pre>
<h3 id="escritura"><a class="header" href="#escritura">Escritura</a></h3>
<p>La función <code>write()</code> toma una <em>closure</em> con un único argumento. Típicamente lo llamamos <code>w</code>. Este argumento da acceso de lectura-escritura a varios subcampos dentro de este registro, como se define en el archivo SVD del fabricante para este chip. De nuevo, puedes encontrar todas las funciones disponibles en <code>w</code> para este registro en particular, en este periférico en particular, en este chip en particular, en la <a href="https://docs.rs/tm4c123x/0.7.0/tm4c123x/pwm0/ctl/struct.W.html">documentación tm4c123x</a>. Tenga en cuenta que todos los subcampos que no establezcamos se establecerán a un valor por defecto para nosotros - cualquier contenido existente en el registro se perderá.</p>
<pre><code class="language-rust ignore">pwm.ctl.write(|w| w.globalsync0().clear_bit());</code></pre>
<h3 id="modificación"><a class="header" href="#modificación">Modificación</a></h3>
<p>Si deseamos cambiar sólo un subcampo concreto de este registro y dejar los demás subcampos sin cambios, podemos utilizar la función <code>modify</code>. Esta función toma un cierre con dos argumentos - uno para lectura y otro para escritura. Normalmente los llamamos <code>r</code> y <code>w</code> respectivamente. El argumento <code>r</code> se puede utilizar para inspeccionar el contenido actual del registro, y el argumento <code>w</code> se puede utilizar para modificar el contenido del registro.</p>
<pre><code class="language-rust ignore">pwm.ctl.modify(|r, w| w.globalsync0().clear_bit());</code></pre>
<p>La función <code>modify</code> muestra realmente el poder de las <em>closures</em>. En C, tendríamos que leer un valor temporal, modificar los bits correctos y volver a escribir el valor. Esto significa que hay un margen de error considerable:</p>
<pre><code class="language-C">uint32_t temp = pwm0.ctl.read();
temp |= PWM0_CTL_GLOBALSYNC0;
pwm0.ctl.write(temp);
uint32_t temp2 = pwm0.enable.read();
temp2 |= PWM0_ENABLE_PWM4EN;
pwm0.enable.write(temp); // Oh oh! Variable equivocada!
</code></pre>
<h2 id="usando-una-crate-hal"><a class="header" href="#usando-una-crate-hal">Usando una <em>crate</em> HAL</a></h2>
<p>La <em>crate</em> HAL para un chip funciona típicamente implementando un <em>Trait</em> personalizado para las estructuras crudas expuestas por la PAC. A menudo este <em>trait</em> definirá una función llamada <code>constrain()</code> para periféricos simples o <code>split()</code> para cosas como puertos GPIO con múltiples pines. Esta función consumirá la estructura subyacente del periférico y devolverá un nuevo objeto con una API de alto nivel. Esta API también puede hacer cosas como que la función <code>new</code> del puerto serie requiera un préstamo en alguna estructura <code>Clock</code>, que sólo puede ser generada llamando a la función que configura los PLLs y establece todas las frecuencias de reloj. De esta forma, es estáticamente imposible crear un objeto puerto serie sin haber configurado antes las frecuencias de reloj, o que el objeto puerto serie convierta erróneamente la velocidad de transmisión en ticks de reloj. Algunas crates incluso definen rasgos especiales para los estados en los que puede estar cada pin GPIO, requiriendo que el usuario ponga un pin en el estado correcto (digamos, seleccionando el Modo de Función Alternativo apropiado) antes de pasar el pin a Periférico. Todo ello sin costo alguno en tiempo de ejecución.</p>
<p>Veamos un ejemplo:</p>
<pre><code class="language-rust ignore">#![no_std]
#![no_main]

use panic_halt as _; // panic handler

use cortex_m_rt::entry;
use tm4c123x_hal as hal;
use tm4c123x_hal::prelude::*;
use tm4c123x_hal::serial::{NewlineMode, Serial};
use tm4c123x_hal::sysctl;

#[entry]
fn main() -&gt; ! {
    let p = hal::Peripherals::take().unwrap();
    let cp = hal::CorePeripherals::take().unwrap();

    // Wrap up the SYSCTL struct into an object with a higher-layer API
    let mut sc = p.SYSCTL.constrain();
    // Pick our oscillation settings
    sc.clock_setup.oscillator = sysctl::Oscillator::Main(
        sysctl::CrystalFrequency::_16mhz,
        sysctl::SystemClock::UsePll(sysctl::PllOutputFrequency::_80_00mhz),
    );
    // Configure the PLL with those settings
    let clocks = sc.clock_setup.freeze();

    // Wrap up the GPIO_PORTA struct into an object with a higher-layer API.
    // Note it needs to borrow `sc.power_control` so it can power up the GPIO
    // peripheral automatically.
    let mut porta = p.GPIO_PORTA.split(&amp;sc.power_control);

    // Activate the UART.
    let uart = Serial::uart0(
        p.UART0,
        // The transmit pin
        porta
            .pa1
            .into_af_push_pull::&lt;hal::gpio::AF1&gt;(&amp;mut porta.control),
        // The receive pin
        porta
            .pa0
            .into_af_push_pull::&lt;hal::gpio::AF1&gt;(&amp;mut porta.control),
        // No RTS or CTS required
        (),
        (),
        // The baud rate
        115200_u32.bps(),
        // Output handling
        NewlineMode::SwapLFtoCRLF,
        // We need the clock rates to calculate the baud rate divisors
        &amp;clocks,
        // We need this to power up the UART peripheral
        &amp;sc.power_control,
    );

    loop {
        writeln!(uart, &quot;Hello, World!\r\n&quot;).unwrap();
    }
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="semihosting"><a class="header" href="#semihosting">Semihosting</a></h1>
<p>Semihosting es un mecanismo que permite a los dispositivos embebidos realizar E/S en el anfitrión y se utiliza principalmente para registrar mensajes en la consola del anfitrión. Semihosting requiere una sesión de depuración y prácticamente nada más (¡sin cables adicionales!) por lo que es muy conveniente de usar. La desventaja es que es super lento: cada operación de escritura puede tardar varios milisegundos dependiendo del depurador de hardware (por ejemplo, ST-Link) que utilices.</p>
<p>La <em>crate</em> <a href="https://crates.io/crates/cortex-m-semihosting"><code>cortex-m-semihosting</code></a> proporciona una API para realizar operaciones semihosting en dispositivos Cortex-M. El programa de abajo es la versión semihosting de &quot;Hello, world!&quot;:</p>
<pre><code class="language-rust ignore">#![no_main]
#![no_std]

use panic_halt as _;

use cortex_m_rt::entry;
use cortex_m_semihosting::hprintln;

#[entry]
fn main() -&gt; ! {
    hprintln!(&quot;Hello, world!&quot;).unwrap();

    loop {}
}</code></pre>
<p>Si ejecutas este programa en hardware verás el mensaje &quot;Hello, world!&quot; dentro de los logs de OpenOCD.</p>
<pre><code class="language-text">$ openocd
(..)
Hello, world!
(..)
</code></pre>
<p>Es necesario activar primero el semihosting en OpenOCD desde GDB:</p>
<pre><code class="language-console">(gdb) monitor arm semihosting enable
semihosting is enabled
</code></pre>
<p>QEMU entiende las operaciones de semihosting por lo que el programa anterior también funcionará con <code>qemu-system-arm</code> sin tener que iniciar una sesión de depuración. Ten en cuenta que tendrás que pasar la bandera <code>-semihosting-config</code> a QEMU para habilitar el soporte de semihosting; estas banderas ya están incluidas en el archivo <code>.cargo/config.toml</code> de la plantilla.</p>
<pre><code class="language-text">$ # this program will block the terminal
$ cargo run
     Running `qemu-system-arm (..)
Hello, world!
</code></pre>
<p>También hay una operación de semi-hosting <code>exit</code> que se puede utilizar para terminar el proceso QEMU. Importante: <strong>no</strong> uses <code>debug::exit</code> en hardware; esta función puede corromper tu sesión de OpenOCD y no podrás depurar más programas hasta que la reinicies.</p>
<pre><code class="language-rust ignore">#![no_main]
#![no_std]

use panic_halt as _;

use cortex_m_rt::entry;
use cortex_m_semihosting::debug;

#[entry]
fn main() -&gt; ! {
    let roses = &quot;blue&quot;;

    if roses == &quot;red&quot; {
        debug::exit(debug::EXIT_SUCCESS);
    } else {
        debug::exit(debug::EXIT_FAILURE);
    }

    loop {}
}</code></pre>
<pre><code class="language-text">$ cargo run
     Running `qemu-system-arm (..)

$ echo $?
1
</code></pre>
<p>Un último consejo: puedes configurar el comportamiento de pánico a <code>exit(EXIT_FAILURE)</code>. Esto te permitirá escribir pruebas ejecutar-pasar <code>no_std</code> que puedes ejecutar en QEMU.</p>
<p>Para mayor comodidad, la <em>crate</em> <code>panic-semihosting</code> tiene una función &quot;exit&quot; que cuando está activada invoca <code>exit(EXIT_FAILURE)</code> después de registrar el mensaje de pánico en la stderr del host.</p>
<pre><code class="language-rust ignore">#![no_main]
#![no_std]

use panic_semihosting as _; // features = [&quot;exit&quot;]

use cortex_m_rt::entry;
use cortex_m_semihosting::debug;

#[entry]
fn main() -&gt; ! {
    let roses = &quot;blue&quot;;

    assert_eq!(roses, &quot;red&quot;);

    loop {}
}</code></pre>
<pre><code class="language-text">$ cargo run
     Running `qemu-system-arm (..)
panicked at 'assertion failed: `(left == right)`
  left: `&quot;blue&quot;`,
 right: `&quot;red&quot;`', examples/hello.rs:15:5

$ echo $?
1
</code></pre>
<p><strong>NOTA</strong>: Para habilitar esta prestación en <code>panic-semihosting</code>, edite su sección de dependencias <code>Cargo.toml</code> donde se especifica <code>panic-semihosting</code> con:</p>
<pre><code class="language-toml">panic-semihosting = { version = &quot;VERSION&quot;, features = [&quot;exit&quot;] }
</code></pre>
<p>donde <code>VERSION</code> es la versión deseada. Para más información sobre las prestaciones de las dependencias, consulta la sección <a href="https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html"><code>specifying dependencies</code></a> del libro de Cargo.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pánico"><a class="header" href="#pánico">Pánico</a></h1>
<p>El pánico es una parte esencial del lenguaje Rust. Las operaciones integradas, como la indexación, se comprueban en tiempo de ejecución para garantizar la seguridad de la memoria. Cuando se intenta indexar fuera de los límites, se produce un pánico.</p>
<p>En la biblioteca estándar el pánico tiene un comportamiento definido: despliega la pila del hilo en pánico, a menos que el usuario haya optado por abortar el programa en caso de pánico.</p>
<p>En programas sin biblioteca estándar, sin embargo, el comportamiento de pánico se deja indefinido. Se puede elegir un comportamiento declarando una función <code>#[panic_handler]</code>. Esta función debe existir exactamente <em>una vez</em> en el grafo de dependencias de un programa, y debe tener la siguiente firma: <code>fn(&amp;PanicInfo) -&gt; !</code>, donde <a href="https://doc.rust-lang.org/core/panic/struct.PanicInfo.html"><code>PanicInfo</code></a> es una estructura que contiene información sobre la localización del pánico.</p>
<p>Dado que los sistemas embebidos van desde los orientados al usuario hasta los de seguridad crítica (que no pueden colapsar), no hay un comportamiento de pánico talla única, pero hay un montón de comportamientos comúnmente utilizados. Estos comportamientos comunes han sido empaquetados en <em>crates</em> que definen la función <code>#[panic_handler]</code>. Algunos ejemplos incluyen:</p>
<ul>
<li><a href="https://crates.io/crates/panic-abort"><code>panic-abort</code></a>. Un pánico provoca la ejecución de la instrucción abort.</li>
<li><a href="https://crates.io/crates/panic-halt"><code>panic-halt</code></a>. Un pánico hace que el programa, o el hilo actual, se detenga entrando en un bucle infinito.</li>
<li><a href="https://crates.io/crates/panic-itm"><code>panic-itm</code></a>. El mensaje de pánico se registra utilizando el ITM, un periférico específico de ARM Cortex-M.</li>
<li><a href="https://crates.io/crates/panic-semihosting"><code>panic-semihosting</code></a>. El mensaje de pánico se registra en el host utilizando la técnica semihosting.</li>
</ul>
<p>Puedes encontrar más <em>crates</em> buscando la palabra clave <a href="https://crates.io/keywords/panic-handler"><code>panic-handler</code></a> en crates.io.</p>
<p>Un programa puede elegir uno de estos comportamientos simplemente enlazando con la <em>crate</em> correspondiente. El hecho de que el comportamiento de pánico se exprese en el código fuente de una aplicación como una única línea de código no sólo es útil como documentación, sino que también puede utilizarse para cambiar el comportamiento de pánico en función del perfil de compilación. Por ejemplo:</p>
<pre><code class="language-rust ignore">#![no_main]
#![no_std]

// dev profile: easier to debug panics; can put a breakpoint on `rust_begin_unwind`
#[cfg(debug_assertions)]
use panic_halt as _;

// release profile: minimize the binary size of the application
#[cfg(not(debug_assertions))]
use panic_abort as _;

// ..</code></pre>
<p>En este ejemplo la <em>crate</em> enlaza con la <em>crate</em> <code>panic-halt</code> cuando se construye con el perfil dev (<code>cargo build</code>), pero enlaza con la <em>crate</em> <code>panic-abort</code> cuando se construye con el perfil release (<code>cargo build --release</code>).</p>
<blockquote>
<p>La forma <code>use panic_abort as _;</code> de la sentencia <code>use</code> se usa para asegurar que el manejador de pánico <code>panic_abort</code>
se incluye en nuestro ejecutable final, dejando claro al compilador que no usaremos explícitamente nada
de la <em>crate</em>. Sin el cambio de nombre <code>as _</code>, el compilador nos avisaría de que tenemos una importación sin usar.
A veces se puede ver <code>extern crate panic_abort</code> en su lugar, que es un estilo más antiguo utilizado antes de la
edición 2018 de Rust, y ahora sólo debería usarse para crates &quot;sysroot&quot; (los que se distribuyen con el propio Rust) tales
como <code>proc_macro</code>, <code>alloc</code>, <code>std</code>, y <code>test</code>.</p>
</blockquote>
<h2 id="un-ejemplo"><a class="header" href="#un-ejemplo">Un ejemplo</a></h2>
<p>He aquí un ejemplo que intenta indexar un array más allá de su longitud. La operación resulta en un pánico.</p>
<pre><code class="language-rust ignore">#![no_main]
#![no_std]

use panic_semihosting as _;

use cortex_m_rt::entry;

#[entry]
fn main() -&gt; ! {
    let xs = [0, 1, 2];
    let i = xs.len() + 1;
    let _y = xs[i]; // out of bounds access

    loop {}
}</code></pre>
<p>Este ejemplo elige el comportamiento <code>panic-semihosting</code> que imprime el mensaje de pánico en la consola del host usando semihosting.</p>
<pre><code class="language-text">$ cargo run
     Running `qemu-system-arm -cpu cortex-m3 -machine lm3s6965evb (..)
panicked at 'index out of bounds: the len is 3 but the index is 4', src/main.rs:12:13
</code></pre>
<p>Puedes probar a cambiar el comportamiento a <code>panic-halt</code> y confirmar que no se imprime ningún mensaje en ese caso.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="excepciones"><a class="header" href="#excepciones">Excepciones</a></h1>
<p>Las excepciones, y las interrupciones, son un mecanismo de hardware mediante el cual el procesador gestiona eventos asíncronos y errores fatales (p.e. la ejecución de una instrucción no válida). Las excepciones implican prioridad e involucran manejadores de excepciones, subrutinas ejecutadas en respuesta a la señal que desencadenó el evento.</p>
<p>La <em>crate</em> <code>cortex-m-rt</code> proporciona un atributo <a href="https://docs.rs/cortex-m-rt-macros/latest/cortex_m_rt_macros/attr.exception.html"><code>exception</code></a> para declarar los manejadores de excepciones.</p>
<pre><code class="language-rust ignore">// Exception handler for the SysTick (System Timer) exception
#[exception]
fn SysTick() {
    // ..
}</code></pre>
<p>Aparte del atributo <code>exception</code> los manejadores de excepciones parecen funciones simples pero hay una diferencia más: Los manejadores de excepciones <em>no</em> pueden ser llamados por software. Siguiendo el ejemplo anterior, la sentencia <code>SysTick();</code> produciría un error de compilación.</p>
<p>Este comportamiento es intencionado y es necesario para proporcionar una característica: las variables <code>static mut</code> declaradas <em>dentro</em> de los manejadores de <code>exception</code> son <em>seguras</em> de usar.</p>
<pre><code class="language-rust ignore">#[exception]
fn SysTick() {
    static mut COUNT: u32 = 0;

    // `COUNT` has transformed to type `&amp;mut u32` and it's safe to use
    *COUNT += 1;
}</code></pre>
<p>Como sabrás, usar variables <code>static mut</code> en una función la convierte en <a href="https://en.wikipedia.org/wiki/Reentrancy_(computing)"><em>non-reentrant</em></a>. Es un comportamiento indefinido llamar a una función no-reentrante, directa o indirectamente, desde más de un manejador de excepciones / interrupciones o desde <code>main</code> y uno o más manejadores de excepciones / interrupciones.</p>
<p>Rust seguro nunca debe dar lugar a un comportamiento indefinido por lo que las funciones no reentrantes deben ser marcadas como <code>unsafe</code>. Sin embargo, me acaban de decir que los manejadores de <code>excepciones</code> pueden usar variables <code>static mut</code> de forma segura. ¿Cómo es esto posible? Esto es posible porque los manejadores de <code>excepción</code> no pueden ser llamados por software, por lo que la reentrada no es posible.</p>
<blockquote>
<p>Tenga en cuenta que el atributo <code>exception</code> transforma las definiciones de variables
estáticas dentro de la función envolviéndolas en bloques &quot;inseguros&quot; y
proporcionándonos con nuevas variables apropiadas de tipo <code>&amp;mut</code> del mismo nombre.
De este modo podemos derefenciar la referencia mediante <code>*</code> para acceder a los valores
de las variables sin necesidad de envolverlas en bloques de tipo <code>unsafe</code>.</p>
</blockquote>
<h2 id="un-ejemplo-completo"><a class="header" href="#un-ejemplo-completo">Un ejemplo completo</a></h2>
<p>Este es un ejemplo que utiliza el temporizador del sistema para lanzar una excepción <code>SysTick</code> aproximadamente cada segundo. El manejador de la excepción <code>SysTick</code> mantiene un registro de cuantas veces ha sido llamado en la variable <code>COUNT</code> y luego imprime el valor de <code>COUNT</code> en la consola del host usando semihosting.</p>
<blockquote>
<p><strong>NOTA</strong>: Puedes ejecutar este ejemplo en cualquier dispositivo Cortex-M;
también puedes ejecutarlo en QEMU</p>
</blockquote>
<pre><code class="language-rust ignore">#![deny(unsafe_code)]
#![no_main]
#![no_std]

use panic_halt as _;

use core::fmt::Write;

use cortex_m::peripheral::syst::SystClkSource;
use cortex_m_rt::{entry, exception};
use cortex_m_semihosting::{
    debug,
    hio::{self, HStdout},
};

#[entry]
fn main() -&gt; ! {
    let p = cortex_m::Peripherals::take().unwrap();
    let mut syst = p.SYST;

    // configures the system timer to trigger a SysTick exception every second
    syst.set_clock_source(SystClkSource::Core);
    // this is configured for the LM3S6965 which has a default CPU clock of 12 MHz
    syst.set_reload(12_000_000);
    syst.clear_current();
    syst.enable_counter();
    syst.enable_interrupt();

    loop {}
}

#[exception]
fn SysTick() {
    static mut COUNT: u32 = 0;
    static mut STDOUT: Option&lt;HStdout&gt; = None;

    *COUNT += 1;

    // Lazy initialization
    if STDOUT.is_none() {
        *STDOUT = hio::hstdout().ok();
    }

    if let Some(hstdout) = STDOUT.as_mut() {
        write!(hstdout, &quot;{}&quot;, *COUNT).ok();
    }

    // IMPORTANT omit this `if` block if running on real hardware or your
    // debugger will end in an inconsistent state
    if *COUNT == 9 {
        // This will terminate the QEMU process
        debug::exit(debug::EXIT_SUCCESS);
    }
}</code></pre>
<pre><code class="language-console">tail -n5 Cargo.toml
</code></pre>
<pre><code class="language-toml">[dependencies]
cortex-m = &quot;0.5.7&quot;
cortex-m-rt = &quot;0.6.3&quot;
panic-halt = &quot;0.2.0&quot;
cortex-m-semihosting = &quot;0.3.1&quot;
</code></pre>
<pre><code class="language-text">$ cargo run --release
     Running `qemu-system-arm -cpu cortex-m3 -machine lm3s6965evb (..)
123456789
</code></pre>
<p>Si ejecutas esto en la tarjeta Discovery verás la salida en la consola OpenOCD. Además, el programa <em>no</em> se detendrá cuando la cuenta llegue a 9.</p>
<h2 id="el-manejador-de-excepciones-por-defecto"><a class="header" href="#el-manejador-de-excepciones-por-defecto">El manejador de excepciones por defecto</a></h2>
<p>Lo que el atributo <code>exception</code> realmente hace es <em>anular</em> el manejador de excepciones por defecto para una excepción específica. Si no anulas el manejador para una excepción en particular, será manejada por la función <code>DefaultHandler</code>, que por defecto es:</p>
<pre><code class="language-rust ignore">fn DefaultHandler() {
    loop {}
}</code></pre>
<p>Esta función es proporcionada por la <em>crate</em> <code>cortex-m-rt</code> y marcada como <code>#[no_mangle]</code> para que puedas poner un breakpoint en &quot;DefaultHandler&quot; y atrapar excepciones <em>sin manejador</em>.</p>
<p>Es posible sobreescribir este <code>DefaultHandler</code> usando el atributo <code>exception</code>:</p>
<pre><code class="language-rust ignore">#[exception]
fn DefaultHandler(irqn: i16) {
    // custom default handler
}</code></pre>
<p>El argumento <code>irqn</code> indica qué excepción se está procesando. Un valor negativo indica que se está sirviendo una excepción Cortex-M; y cero o un valor positivo indican que se está sirviendo una excepción específica del dispositivo, también conocida como interrupción.</p>
<h2 id="el-manejador-de-fallas-graves"><a class="header" href="#el-manejador-de-fallas-graves">El manejador de fallas graves</a></h2>
<p>La excepción <code>HardFault</code> es un poco especial. Esta excepción se dispara cuando el programa entra en un estado inválido por lo que su manejador no puede <em>no</em> retornar ya que podría resultar en un comportamiento indefinido. Además, la <em>crate runtime</em> hace algún trabajo antes de que el manejador <code>HardFault</code> definido por el usuario sea invocado para mejorar la depuración.</p>
<p>El resultado es que el manejador <code>HardFault</code> debe tener la siguiente firma: <code>fn(&amp;ExceptionFrame) -&gt; !</code>. El argumento del manejador es un puntero a los registros que fueron empujados a la pila por la excepción. Estos registros son una instantánea del estado del procesador en el momento en que se produjo la excepción y son útiles para diagnosticar una falla grave.</p>
<p>He aquí un ejemplo que realiza una operación ilegal: una lectura a una posición de memoria inexistente.</p>
<blockquote>
<p><strong>NOTA</strong>: Este programa no funcionará, es decir, no se bloqueará, en QEMU porque
<code>qemu-system-arm -machine lm3s6965evb</code> no comprueba las cargas de memoria y
en lecturas a memoria inválida.</p>
</blockquote>
<pre><code class="language-rust ignore">#![no_main]
#![no_std]

use panic_halt as _;

use core::fmt::Write;
use core::ptr;

use cortex_m_rt::{entry, exception, ExceptionFrame};
use cortex_m_semihosting::hio;

#[entry]
fn main() -&gt; ! {
    // read a nonexistent memory location
    unsafe {
        ptr::read_volatile(0x3FFF_FFFE as *const u32);
    }

    loop {}
}

#[exception]
fn HardFault(ef: &amp;ExceptionFrame) -&gt; ! {
    if let Ok(mut hstdout) = hio::hstdout() {
        writeln!(hstdout, &quot;{:#?}&quot;, ef).ok();
    }

    loop {}
}</code></pre>
<p>El manejador <code>HardFault</code> imprime el valor <code>ExceptionFrame</code>. Si ejecutas esto verás algo como esto en la consola de OpenOCD.</p>
<pre><code class="language-text">$ openocd
(..)
ExceptionFrame {
    r0: 0x3ffffffe,
    r1: 0x00f00000,
    r2: 0x20000000,
    r3: 0x00000000,
    r12: 0x00000000,
    lr: 0x080008f7,
    pc: 0x0800094a,
    xpsr: 0x61000000
}
</code></pre>
<p>El valor <code>pc</code> es el valor del Contador de Programa en el momento de la excepción y apunta a la instrucción que disparó la excepción.</p>
<p>Si miras el desensamblado del programa:</p>
<pre><code class="language-text">$ cargo objdump --bin app --release -- -d --no-show-raw-insn --print-imm-hex
(..)
ResetTrampoline:
 8000942:       movw    r0, #0xfffe
 8000946:       movt    r0, #0x3fff
 800094a:       ldr     r0, [r0]
 800094c:       b       #-0x4 &lt;ResetTrampoline+0xa&gt;
</code></pre>
<p>Puedes consultar el valor del contador de programa <code>0x0800094a</code> en el desensamblado. Verás que una operación de carga (<code>ldr r0, [r0]</code> ) causó la excepción. El campo <code>r0</code> de <code>ExceptionFrame</code> te dirá que el valor del registro <code>r0</code> era <code>0x3fff_fffe</code> en ese momento.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="interrupciones"><a class="header" href="#interrupciones">Interrupciones</a></h1>
<p>Las interrupciones difieren de las excepciones en varios aspectos, pero su funcionamiento y uso es muy similar y también son manejadas por el mismo controlador de interrupciones. Mientras que las excepciones están definidas por la arquitectura Cortex-M, las interrupciones son siempre implementaciones específicas del proveedor (y a menudo incluso del chip), tanto en nombre como en funcionalidad.</p>
<p>Las interrupciones permiten una gran flexibilidad que debe tenerse en cuenta cuando se intenta utilizarlas de forma avanzada. No cubriremos esos usos en este libro, sin embargo es una buena idea tener en mente lo siguiente:</p>
<ul>
<li>Las interrupciones tienen prioridades programables que determinan el orden de ejecución de sus manejadores.</li>
<li>Las interrupciones pueden anidarse y priorizarse, es decir, la ejecución de un manejador de interrupción puede ser interrumpida por otra interrupción de mayor prioridad.</li>
<li>En general, el motivo por el que se produce la interrupción debe borrarse para evitar que re-entre en el manejador de interrupciones indefinidamente.</li>
</ul>
<p>Los pasos generales de inicialización en tiempo de ejecución son siempre los mismos:</p>
<ul>
<li>Configurar el(los) periférico(s) para generar peticiones de interrupción en las ocasiones deseadas</li>
<li>Establecer la prioridad deseada del manejador de interrupciones en el controlador de interrupciones</li>
<li>Habilitar el manejador de interrupciones en el controlador de interrupciones</li>
</ul>
<p>De forma similar a las excepciones, la <em>crate</em> <code>cortex-m-rt</code> proporciona un atributo <a href="https://docs.rs/cortex-m-rt-macros/0.1.5/cortex_m_rt_macros/attr.interrupt.html"><code>interrupt</code></a> para declarar los manejadores de interrupciones. Las interrupciones disponibles (y su posición en la tabla de manejadores de interrupción) se generan automáticamente a través de <code>svd2rust</code> a partir de una descripción SVD.</p>
<pre><code class="language-rust ignore">// Interrupt handler for the Timer2 interrupt
#[interrupt]
fn TIM2() {
    // ..
    // Clear reason for the generated interrupt request
}</code></pre>
<p>Los manejadores de interrupciones parecen funciones simples (excepto por la falta de argumentos) similares a los manejadores de excepciones. Sin embargo, no pueden ser llamados directamente por otras partes del firmware debido a las convenciones especiales de llamada. Sin embargo, es posible generar peticiones de interrupción en el software para desencadenar un desvío al manejador de interrupciones.</p>
<p>De forma similar a los manejadores de excepciones, también es posible declarar variables <code>static mut</code> dentro de los manejadores de interrupciones para mantener el estado <em>safe</em>.</p>
<pre><code class="language-rust ignore">#[interrupt]
fn TIM2() {
    static mut COUNT: u32 = 0;

    // `COUNT` has type `&amp;mut u32` and it's safe to use
    *COUNT += 1;
}</code></pre>
<p>Para una descripción más detallada sobre los mecanismos demostrados aquí, por favor ve a la <a href="start/./exceptions.html">sección de excepciones</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="es"><a class="header" href="#es">E/S</a></h1>
<blockquote>
<p><strong>TODO</strong> Cubrir las E/S mapeadas en la memoria usando registros.</p>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="periféricos"><a class="header" href="#periféricos">Periféricos</a></h1>
<h2 id="qué-son-los-periféricos"><a class="header" href="#qué-son-los-periféricos">¿Qué son los periféricos?</a></h2>
<p>La mayoría de los microcontroladores tienen algo más que una CPU, RAM o memoria Flash: contienen secciones de silicio que se utilizan para interactuar con sistemas externos al microcontrolador, así como para interactuar directa e indirectamente con su entorno en el mundo a través de sensores, controladores de motor o interfaces humanas como una pantalla o un teclado. Estos componentes se conocen colectivamente como periféricos.</p>
<p>Estos periféricos son útiles porque le permiten al desarrollador relegar procesamiento en ellos, evitando tener que gestionar todo en el software. Al igual que un desarrollador en una pc relegaría el procesamiento gráfico a una tarjeta de vídeo, los desarrolladores de sistemas embebidos pueden relegar algunas tareas a los periféricos, lo que permite a la CPU dedicar su tiempo a hacer otra cosa importante, o no hacer nada para ahorrar energía.</p>
<p>Si nos fijamos en la tarjeta principal de un computador doméstico antiguo de los años 70 u 80 (y en realidad, los PC de sobremesa de ayer no están tan alejados de los sistemas embebidos de hoy en día) esperaríamos ver:</p>
<ul>
<li>Un procesador</li>
<li>Un chip de RAM</li>
<li>Un chip de ROM</li>
<li>Un controlador de E/S</li>
</ul>
<p>El chip de RAM, el chip de ROM y el controlador de E/S (el periférico en este sistema) estarían unidos al procesador a través de una serie de pistas paralelas conocidas como 'bus'. Este bus transporta la información de la dirección, que selecciona con qué dispositivo del bus desea comunicarse el procesador, y un bus de datos que transporta los datos propiamente dichos. En nuestros microcontroladores embebidos se aplican los mismos principios, sólo que todo está empaquetado en una única pieza de silicio.</p>
<p>Sin embargo, a diferencia de las tarjetas gráficas, que normalmente tienen una API de software como Vulkan, Metal u OpenGL, los periféricos están expuestos a nuestro microcontrolador con una interfaz de hardware, que se asigna a un área de la memoria.</p>
<h2 id="espacio-de-memoria-lineal-y-real"><a class="header" href="#espacio-de-memoria-lineal-y-real">Espacio de Memoria Lineal y Real</a></h2>
<p>En un microcontrolador, escribir algunos datos en alguna otra dirección arbitraria, como <code>0x4000_0000</code> o <code>0x0000_0000</code>, también puede ser una acción completamente válida.</p>
<p>En un sistema de sobremesa, el acceso a la memoria está estrechamente controlado por la MMU, o Unidad de Gestión de Memoria. Este componente tiene dos responsabilidades principales: hacer cumplir los permisos de acceso a secciones de memoria (impidiendo que un proceso lea o modifique la memoria de otro proceso); y reasignar segmentos de la memoria física a rangos de memoria virtual utilizados en el software. Los microcontroladores no suelen tener una MMU, y en su lugar sólo utilizan direcciones físicas reales en el software.</p>
<p>Aunque los microcontroladores de 32 bits tienen un espacio de direcciones real y lineal desde <code>0x0000_0000</code>, y <code>0xFFFF_FFFF</code>, generalmente sólo utilizan unos pocos cientos de kilobytes de ese rango para la memoria real. Esto deja una cantidad significativa de espacio de direcciones restante. En capítulos anteriores, hablábamos de que la RAM estaba localizada en la dirección <code>0x2000_0000</code>. Si nuestra RAM tuviera 64 KiB de longitud (es decir, con una dirección máxima de 0xFFFF) entonces las direcciones <code>0x2000_0000</code> a <code>0x2000_FFFF</code> corresponderían a nuestra RAM. Cuando escribimos en una variable que esta en la dirección <code>0x2000_1234</code>, lo que ocurre internamente es que alguna lógica detecta la parte superior de la dirección (0x2000 en este ejemplo) y luego activa la RAM para que pueda actuar sobre la parte inferior de la dirección (0x1234 en este caso). En un Cortex-M también tenemos nuestra Flash ROM mapeada en la dirección <code>0x0000_0000</code> hasta, digamos, la dirección <code>0x0007_FFFF</code> (si tenemos una Flash ROM de 512 KiB). En lugar de ignorar todo el espacio restante entre estas dos regiones, los diseñadores de microcontroladores mapearon la interfaz para los periféricos en ciertas posiciones de memoria. Esto termina pareciendo algo como esto</p>
<p><img src="peripherals/../assets/nrf52-memory-map.png" alt="" /></p>
<p><a href="http://infocenter.nordicsemi.com/pdf/nRF52832_PS_v1.1.pdf">Hoja de datos Nordic nRF52832 (pdf)</a></p>
<h2 id="periféricos-mapeados-en-memoria"><a class="header" href="#periféricos-mapeados-en-memoria">Periféricos Mapeados en Memoria</a></h2>
<p>La interacción con estos periféricos es simple a primera vista - escribir los datos correctos en la dirección correcta. Por ejemplo, enviar una palabra de 32 bits a través de un puerto serial podría ser tan directo como escribir esa palabra de 32 bits en una determinada dirección de memoria. El periférico del puerto serial se encargaría entonces de enviar los datos automáticamente.</p>
<p>La configuración de estos periféricos funciona de forma similar. En lugar de llamar a una función para configurar un periférico, se expone un trozo de memoria que sirve como API de hardware. Escribe <code>0x8000_0000</code> en un Registro de Configuración de Frecuencia SPI, y el puerto SPI enviará datos a 8 Megabits por segundo. Escribe <code>0x0200_0000</code> en la misma dirección, y el puerto SPI enviará datos a 125 Kilobits por segundo. Estos registros de configuración se parecen un poco a esto:</p>
<p><img src="peripherals/../assets/nrf52-spi-frequency-register.png" alt="" /></p>
<p><a href="http://infocenter.nordicsemi.com/pdf/nRF52832_PS_v1.1.pdf">Hoja de datos Nordic nRF52832 (pdf)</a></p>
<p>Esta interfaz es la forma en que se realizan las interacciones con el hardware, independientemente del lenguaje que se utilice, ya sea ensamblador, C o Rust.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="un-primer-intento"><a class="header" href="#un-primer-intento">Un Primer Intento</a></h1>
<h2 id="los-registros"><a class="header" href="#los-registros">Los Registros</a></h2>
<p>Echemos un vistazo al periférico 'SysTick' - un simple temporizador que viene con cada núcleo de procesador Cortex-M. Típicamente lo buscarás en la hoja de datos del fabricante del chip o en el <em>Manual de Referencia Técnica</em>, pero este ejemplo es común a todos los núcleos Cortex-M de ARM, miremos en el <a href="http://infocenter.arm.com/help/topic/com.arm.doc.dui0553a/Babieigh.html">manual de referencia de ARM</a>. Vemos que hay cuatro registros:</p>
<div class="table-wrapper"><table><thead><tr><th>Offset</th><th>Nombre</th><th>Descripción</th><th>Ancho</th></tr></thead><tbody>
<tr><td>0x00</td><td>SYST_CSR</td><td>Registro de control y estado</td><td>32 bits</td></tr>
<tr><td>0x04</td><td>SYST_RVR</td><td>Registro de valor de recarga</td><td>32 bits</td></tr>
<tr><td>0x08</td><td>SYST_CVR</td><td>Registro de valor actual</td><td>32 bits</td></tr>
<tr><td>0x0C</td><td>SYST_CALIB</td><td>Registro de Valor de Calibración</td><td>32 bits</td></tr>
</tbody></table>
</div>
<h2 id="el-enfoque-c"><a class="header" href="#el-enfoque-c">El enfoque C</a></h2>
<p>En Rust, podemos representar una colección de registros exactamente de la misma manera que lo hacemos en C - con una <code>struct</code>.</p>
<pre><code class="language-rust ignore">#[repr(C)]
struct SysTick {
    pub csr: u32,
    pub rvr: u32,
    pub cvr: u32,
    pub calib: u32,
}</code></pre>
<p>El calificador <code>#[repr(C)]</code> le dice al compilador de Rust que diseñe esta estructura como lo haría un compilador de C. Eso es muy importante, ya que Rust permite reordenar los campos de estructura, mientras que C no. ¡Puedes imaginar la depuración que tendríamos que hacer si el compilador reorganizara estos campos en silencio! Con este calificador en su lugar, tenemos nuestros cuatro campos de 32 bits que corresponden a la tabla anterior. Pero, por supuesto, esta <code>estructura</code> no sirve por sí sola, necesitamos una variable.</p>
<pre><code class="language-rust ignore">let systick = 0xE000_E010 as *mut SysTick;
let time = unsafe { (*systick).cvr };</code></pre>
<h2 id="accesos-volátiles"><a class="header" href="#accesos-volátiles">Accesos volátiles</a></h2>
<p>Ahora, hay un par de problemas con el enfoque anterior.</p>
<ol>
<li>Tenemos que usar <code>unsafe</code> cada vez que queramos acceder a nuestro Periférico.</li>
<li>No tenemos forma de especificar qué registros son de solo lectura o de lectura y escritura.</li>
<li>Cualquier pieza de código en cualquier parte de tu programa podría acceder al hardware a través de esta estructura.</li>
<li>Aún más importante, esto en realidad no funciona...</li>
</ol>
<p>Ahora, el problema es que los compiladores son inteligentes. Si realiza dos escrituras en la misma pieza de RAM, una tras otra, el compilador puede notarlo y omitir la primera escritura por completo. En C, podemos marcar las variables como &quot;volátiles&quot; para garantizar que cada lectura o escritura ocurra según lo previsto. En Rust, en cambio, marcamos los <em>accesos</em> como volátiles, no como variables.</p>
<pre><code class="language-rust ignore">let systick = unsafe { &amp;mut *(0xE000_E010 as *mut SysTick) };
let time = unsafe { core::ptr::read_volatile(&amp;mut systick.cvr) };</code></pre>
<p>Entonces, hemos solucionado uno de nuestros cuatro problemas, ¡pero ahora tenemos aún más código <code>no seguro</code>! Afortunadamente, hay una <em>crate</em> de terceros que puede ayudar: <a href="https://crates.io/crates/volatile_register"><code>registro_volatil</code></a>.</p>
<pre><code class="language-rust ignore">use volatile_register::{RW, RO};

#[repr(C)]
struct SysTick {
    pub csr: RW&lt;u32&gt;,
    pub rvr: RW&lt;u32&gt;,
    pub cvr: RW&lt;u32&gt;,
    pub calib: RO&lt;u32&gt;,
}

fn get_systick() -&gt; &amp;'static mut SysTick {
    unsafe { &amp;mut *(0xE000_E010 as *mut SysTick) }
}

fn get_time() -&gt; u32 {
    let systick = get_systick();
    systick.cvr.read()
}</code></pre>
<p>Ahora, los accesos volátiles se realizan automáticamente a través de los métodos <code>read</code> y <code>write</code>. Todavía es <code>inseguro</code> realizar escrituras, pero para ser justos, el hardware es un montón de estados mutables y no hay forma de que el compilador sepa si estas escrituras son realmente seguras, por lo que esta es una buena posición inicial.</p>
<h2 id="un-envoltorio-rust-para-systick"><a class="header" href="#un-envoltorio-rust-para-systick">Un envoltorio Rust para SysTick</a></h2>
<p>Necesitamos envolver esta <code>estructura</code> en una API de capa superior que sea segura para que llamen nuestros usuarios. Como autor del controlador, verificamos manualmente que el código inseguro sea correcto y luego presentamos una API segura para nuestros usuarios para que no tengan que preocuparse por eso (¡siempre que confíen en que lo haremos bien!).</p>
<p>Un ejemplo podría ser:</p>
<pre><code class="language-rust ignore">use volatile_register::{RW, RO};

pub struct SystemTimer {
    p: &amp;'static mut RegisterBlock
}

#[repr(C)]
struct RegisterBlock {
    pub csr: RW&lt;u32&gt;,
    pub rvr: RW&lt;u32&gt;,
    pub cvr: RW&lt;u32&gt;,
    pub calib: RO&lt;u32&gt;,
}

impl SystemTimer {
    pub fn new() -&gt; SystemTimer {
        SystemTimer {
            p: unsafe { &amp;mut *(0xE000_E010 as *mut RegisterBlock) }
        }
    }

    pub fn get_time(&amp;self) -&gt; u32 {
        self.p.cvr.read()
    }

    pub fn set_reload(&amp;mut self, reload_value: u32) {
        unsafe { self.p.rvr.write(reload_value) }
    }
}

pub fn example_usage() -&gt; String {
    let mut st = SystemTimer::new();
    st.set_reload(0x00FF_FFFF);
    format!(&quot;Time is now 0x{:08x}&quot;, st.get_time())
}</code></pre>
<p>Ahora, el problema con este enfoque es que el siguiente código es perfectamente aceptable para el compilador:</p>
<pre><code class="language-rust ignore">fn thread1() {
    let mut st = SystemTimer::new();
    st.set_reload(2000);
}

fn thread2() {
    let mut st = SystemTimer::new();
    st.set_reload(1000);
}</code></pre>
<p>Nuestro argumento <code>&amp;mut self</code> para la función <code>set_reload</code> verifica que no haya otras referencias a <em>esa</em> estructura <code>SystemTimer</code> en particular, ¡pero no impiden que el usuario cree un segundo <code>SystemTimer</code> que apunte exactamente al mismo periférico! El código escrito de esta manera funcionará si el autor es lo suficientemente diligente para detectar todas estas instancias de controlador 'duplicadas', pero una vez que el código se distribuye en varios módulos, controladores, desarrolladores y días, se vuelve cada vez más fácil hacer estos tipos de errores.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="estado-global-mutable"><a class="header" href="#estado-global-mutable">Estado Global Mutable</a></h2>
<p>Desafortunadamente, el hardware no es más que un estado global mutable, lo que puede resultar muy aterrador para un desarrollador de Rust. El hardware existe independientemente de las estructuras del código que escribimos y puede ser modificado en cualquier momento por el mundo real.</p>
<h2 id="cuáles-deberían-ser-nuestras-reglas"><a class="header" href="#cuáles-deberían-ser-nuestras-reglas">¿Cuáles deberían ser nuestras reglas?</a></h2>
<p>¿Cómo podemos interactuar de forma fiable con estos periféricos?</p>
<ol>
<li>Utilice siempre métodos <code>volatile</code> para leer o escribir en la memoria periférica, ya que puede cambiar en cualquier momento</li>
<li>En el software, deberíamos poder compartir cualquier número de accesos de solo lectura a estos periféricos</li>
<li>Si algún software debe tener acceso de lectura y escritura a un periférico, debe contener la única referencia a ese periférico</li>
</ol>
<h2 id="el-verificador-de-préstamos-the-borrow-checker"><a class="header" href="#el-verificador-de-préstamos-the-borrow-checker">El Verificador de Préstamos (The Borrow Checker)</a></h2>
<p>¡Las últimas dos de estas reglas suenan sospechosamente similares a lo que ya hace el Borrow Checker!</p>
<p>¿Imagínese si pudiéramos pasar la propiedad de estos periféricos u ofrecerles referencias inmutables o mutables?</p>
<p>Bueno, podemos, pero para el Borrow Checker, necesitamos tener exactamente una instancia de cada periférico, para que Rust pueda manejar esto correctamente. Bueno, afortunadamente en el hardware, solo hay una instancia de cualquier periférico dado, pero ¿cómo podemos exponer eso en la estructura de nuestro código?</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="singletons"><a class="header" href="#singletons">Singletons</a></h1>
<blockquote>
<p>En ingeniería de software, el patrón singleton es un patrón de diseño de software que restringe la instanciación de una clase a un objeto.</p>
<p><em>Wikipedia: <a href="https://en.wikipedia.org/wiki/Singleton_pattern">Singleton Pattern</a>, <a href="peripherals/es">Singleton</a></em></p>
</blockquote>
<h2 id="pero-por-qué-no-podemos-simplemente-usar-variables-globales"><a class="header" href="#pero-por-qué-no-podemos-simplemente-usar-variables-globales">Pero, ¿por qué no podemos simplemente usar variables globales?</a></h2>
<p>Podríamos hacer que todo sea público estático, como esto:</p>
<pre><code class="language-rust ignore">static mut THE_SERIAL_PORT: SerialPort = SerialPort;

fn main() {
    let _ = unsafe {
        THE_SERIAL_PORT.read_speed();
    };
}</code></pre>
<p>Pero esto tiene algunos problemas. Es una variable global mutable, y en Rust, siempre es inseguro interactuar con estas. Estas variables también son visibles en todo su programa, lo que significa que el verificador de préstamos no puede ayudarte a rastrear las referencias y la propiedad de estas variables.</p>
<h2 id="cómo-hacemos-esto-en-rust"><a class="header" href="#cómo-hacemos-esto-en-rust">¿Cómo hacemos esto en Rust?</a></h2>
<p>En lugar de convertir nuestro periférico en una variable global, podríamos decidir crear una estructura, en este caso denominada <code>PERIPHERALS</code>, que contiene una <code>Opción&lt;T&gt;</code> para cada uno de nuestros periféricos.</p>
<pre><code class="language-rust ignore">struct Peripherals {
    serial: Option&lt;SerialPort&gt;,
}
impl Peripherals {
    fn take_serial(&amp;mut self) -&gt; SerialPort {
        let p = replace(&amp;mut self.serial, None);
        p.unwrap()
    }
}
static mut PERIPHERALS: Peripherals = Peripherals {
    serial: Some(SerialPort),
};</code></pre>
<p>Esta estructura nos permite obtener una única instancia de nuestro periférico. Si intentamos llamar a <code>take_serial()</code> más de una vez, ¡nuestro código entrará en pánico!</p>
<pre><code class="language-rust ignore">fn main() {
    let serial_1 = unsafe { PERIPHERALS.take_serial() };
    // This panics!
    // let serial_2 = unsafe { PERIPHERALS.take_serial() };
}</code></pre>
<p>Aunque interactuar con esta estructura es <code>unsafe</code>, una vez que tenemos el <code>SerialPort</code> que contiene, ya no necesitamos usar <code>unsafe</code>, o la estructura <code>PERIPHERALS</code> en absoluto.</p>
<p>Esto tiene una pequeña sobrecarga en la ejecución porque debemos envolver la estructura <code>SerialPort</code> en una opción, y necesitaremos llamar a <code>take_serial()</code> una vez, sin embargo, este pequeño costo inicial nos permite aprovechar el verificador de préstamos en el resto de nuestro programa.</p>
<h2 id="soporte-de-biblioteca-existente"><a class="header" href="#soporte-de-biblioteca-existente">Soporte de biblioteca existente</a></h2>
<p>Aunque creamos nuestra propia estructura <code>Peripherals</code> arriba, no es necesario hacer esto para su código. La <em>crate</em> <code>cortex_m</code> contiene una macro llamada <code>singleton!()</code> que realizará esta acción por ti.</p>
<pre><code class="language-rust ignore">use cortex_m::singleton;

fn main() {
    // OK if `main` is executed only once
    let x: &amp;'static mut bool =
        singleton!(: bool = false).unwrap();
}</code></pre>
<p><a href="https://docs.rs/cortex-m/latest/cortex_m/macro.singleton.html">cortex_m docs</a></p>
<p>Además, si usas <a href="https://github.com/rtic-rs/cortex-m-rtic"><code>cortex-m-rtic</code></a>, todo el proceso de definición y obtención de estos periféricos es abstraído para ti, y tu, en cambio, recibes una estructura <code>Peripherals</code> que contiene una versión que es no-<code>Option&lt;T&gt;</code> de todos los elementos que definas.</p>
<pre><code class="language-rust ignore">// cortex-m-rtic v0.5.x
#[rtic::app(device = lm3s6965, peripherals = true)]
const APP: () = {
    #[init]
    fn init(cx: init::Context) {
        static mut X: u32 = 0;

        // Cortex-M peripherals
        let core: cortex_m::Peripherals = cx.core;

        // Device specific peripherals
        let device: lm3s6965::Peripherals = cx.device;
    }
}</code></pre>
<h2 id="pero-por-qué"><a class="header" href="#pero-por-qué">¿Pero por qué?</a></h2>
<p>Pero, ¿cómo estos Singleton marcan una diferencia notable en el funcionamiento de nuestro código Rust?</p>
<pre><code class="language-rust ignore">impl SerialPort {
    const SER_PORT_SPEED_REG: *mut u32 = 0x4000_1000 as _;

    fn read_speed(
        &amp;self // &lt;------ This is really, really important
    ) -&gt; u32 {
        unsafe {
            ptr::read_volatile(Self::SER_PORT_SPEED_REG)
        }
    }
}</code></pre>
<p>Hay dos factores importantes en juego aquí:</p>
<ul>
<li>Debido a que estamos usando un singleton, solo hay una forma o lugar para obtener una estructura <code>SerialPort</code></li>
<li>Para llamar al método <code>read_speed()</code>, debemos tener propiedad o una referencia a una estructura <code>SerialPort</code></li>
</ul>
<p>Estos dos factores juntos significan que solo es posible acceder al hardware si hemos satisfecho adecuadamente el verificador de préstamos, lo que significa que en ningún momento tenemos múltiples referencias mutables al mismo hardware.</p>
<pre><code class="language-rust ignore">fn main() {
    // missing reference to `self`! Won't work.
    // SerialPort::read_speed();

    let serial_1 = unsafe { PERIPHERALS.take_serial() };

    // you can only read what you have access to
    let _ = serial_1.read_speed();
}</code></pre>
<h2 id="trate-su-hardware-como-si-fueran-datos"><a class="header" href="#trate-su-hardware-como-si-fueran-datos">Trate su hardware como si fueran datos</a></h2>
<p>Además, dado que algunas referencias son mutables y otras inmutables, es posible ver si una función o método podría modificar potencialmente el estado del hardware. Por ejemplo,</p>
<p>Esto está permitido para cambiar la configuración del hardware:</p>
<pre><code class="language-rust ignore">fn setup_spi_port(
    spi: &amp;mut SpiPort,
    cs_pin: &amp;mut GpioPin
) -&gt; Result&lt;()&gt; {
    // ...
}</code></pre>
<p>Esto no está permitido:</p>
<pre><code class="language-rust ignore">fn read_button(gpio: &amp;GpioPin) -&gt; bool {
    // ...
}</code></pre>
<p>Esto nos permite imponer si el código debe o no realizar cambios en el hardware en <strong>tiempo de compilación</strong>, en lugar de en tiempo de ejecución. Como nota, esto generalmente solo funciona en una aplicación, pero para los sistemas completos, nuestro software se compilará en una sola aplicación, por lo que esto no suele ser una restricción.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="garantías-estáticas"><a class="header" href="#garantías-estáticas">Garantías Estáticas</a></h1>
<p>El sistema de tipos de Rust evita carreras de datos en tiempo de compilación (consulte los <em>traits</em> <a href="https://doc.rust-lang.org/core/marker/trait.Send.html"><code>Send</code></a> y <a href="https://doc.rust-lang.org/core/marker/trait.Sync.html"><code>Sync</code></a>). El sistema de tipos también se puede usar para verificar otras propiedades en tiempo de compilación; reduciendo la necesidad de controles de tiempo de ejecución en algunos casos.</p>
<p>Cuando se aplican a programas embebidos, estas <em>comprobaciones estáticas</em> se pueden usar, por ejemplo, para hacer cumplir que la configuración de las interfaces de E/S se realice correctamente. Por ejemplo, se puede diseñar una API donde solo es posible inicializar una interfaz serial configurando primero los pines que utilizará la interfaz.</p>
<p>También se puede verificar estáticamente que las operaciones, como establecer un pin bajo, solo se pueden realizar en periféricos configurados correctamente. Por ejemplo, intentar cambiar el estado de salida de un pin configurado en modo de entrada flotante generaría un error de compilación.</p>
<p>Y, como se vio en el capítulo anterior, el concepto de propiedad se puede aplicar a los periféricos para garantizar que solo ciertas partes de un programa puedan modificar un periférico. Este <em>control de acceso</em> hace que sea más fácil razonar sobre el software en comparación con la alternativa de tratar los periféricos como un estado mutable global.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="programación-de-estado-de-tipos-typestates"><a class="header" href="#programación-de-estado-de-tipos-typestates">Programación de estado de tipos (typestates)</a></h1>
<p>El concepto de <a href="https://en.wikipedia.org/wiki/Typestate_analysis">typestates</a> describe la codificación de información sobre el estado actual de un objeto en el tipo de ese objeto. Aunque esto puede sonar un poco arcano, si ha usado <a href="https://doc.rust-lang.org/1.0.0/style/ownership/builders.html">Patrón Constructor</a> en Rust, ¡ya ha comenzado a usar Typestate Programming!</p>
<pre><pre class="playground"><code class="language-rust">pub mod foo_module {
    #[derive(Debug)]
    pub struct Foo {
        inner: u32,
    }

    pub struct FooBuilder {
        a: u32,
        b: u32,
    }

    impl FooBuilder {
        pub fn new(starter: u32) -&gt; Self {
            Self {
                a: starter,
                b: starter,
            }
        }

        pub fn double_a(self) -&gt; Self {
            Self {
                a: self.a * 2,
                b: self.b,
            }
        }

        pub fn into_foo(self) -&gt; Foo {
            Foo {
                inner: self.a + self.b,
            }
        }
    }
}

fn main() {
    let x = foo_module::FooBuilder::new(10)
        .double_a()
        .into_foo();

    println!(&quot;{:#?}&quot;, x);
}</code></pre></pre>
<p>En este ejemplo, no hay una forma directa de crear un objeto <code>Foo</code>. Debemos crear un <code>FooBuilder</code> e inicializarlo correctamente antes de que podamos obtener el objeto <code>Foo</code> que queremos.</p>
<p>Este ejemplo mínimo codifica dos estados:</p>
<ul>
<li><code>FooBuilder</code>, que representa un estado &quot;desconfigurado&quot; o &quot;configuración en proceso&quot;</li>
<li><code>Foo</code>, que representa un estado &quot;configurado&quot; o &quot;listo para usar&quot;.</li>
</ul>
<h2 id="tipos-fuertes"><a class="header" href="#tipos-fuertes">Tipos Fuertes</a></h2>
<p>Debido a que Rust tiene un <a href="https://en.wikipedia.org/wiki/Strong_and_weak_typing">Sistema de Tipos Fuerte</a>, no hay una manera fácil de crear mágicamente una instancia de <code>Foo</code>, o de convertir un <code>FooBuilder</code> en un <code>Foo</code> sin llamar al método <code>into_foo()</code>. Además, llamar al método <code>into_foo()</code> consume la estructura original de <code>FooBuilder</code>, lo que significa que no se puede reutilizar sin la creación de una nueva instancia.</p>
<p>Esto nos permite representar los estados de nuestro sistema como tipos e incluir las acciones necesarias para las transiciones de estado en los métodos que intercambian un tipo por otro. Al crear un <code>FooBuilder</code> e intercambiarlo por un objeto <code>Foo</code>, hemos recorrido los pasos de una máquina de estado básica.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="periféricos-como-máquinas-de-estado"><a class="header" href="#periféricos-como-máquinas-de-estado">Periféricos como Máquinas de Estado</a></h1>
<p>Los periféricos de un microcontrolador se pueden considerar como un conjunto de máquinas de estado. Por ejemplo, la configuración de un <a href="https://en.wikipedia.org/wiki/General-purpose_input/output">pin GPIO</a> simplificada podría representarse como el siguiente árbol de estados:</p>
<ul>
<li>Desactivado</li>
<li>Activado
<ul>
<li>Configurado como Salida
<ul>
<li>Salida: Alto</li>
<li>Salida: Bajo</li>
</ul>
</li>
<li>Configurado como Entrada
<ul>
<li>Entrada: Alta Impedancia</li>
<li>Entrada: Pull-down</li>
<li>Entrada: Pull-up</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Si el periférico arranca en el modo <code>Deshabilitado</code>, para pasar al modo <code>Entrada: Alta Impedancia</code>, debemos realizar los siguientes pasos:</p>
<ol>
<li>Deshabilitado</li>
<li>Habilitado</li>
<li>Configurado como Entrada</li>
<li>Entrada: Alta Impedancia</li>
</ol>
<p>Si quisiéramos pasar de <code>Entrada: Alta Impedancia</code> a <code>Entrada: Pull-down</code>, debemos realizar los siguientes pasos:</p>
<ol>
<li>Entrada: Alta Impedancia</li>
<li>Entrada: Pull-down</li>
</ol>
<p>De igual forma, si queremos mover un pin GPIO de configurado como <code>Entrada: Pull-down</code> a <code>Salida: Alto</code>, debemos realizar los siguientes pasos:</p>
<ol>
<li>Entrada: Pull-down</li>
<li>Configurado como Entrada</li>
<li>Configurado como Salida</li>
<li>Salida: Alto</li>
</ol>
<h2 id="representación-de-hardware"><a class="header" href="#representación-de-hardware">Representación de hardware</a></h2>
<p>Por lo general, los estados enumerados anteriormente se establecen escribiendo valores en registros asignados a un periférico GPIO. Definamos un registro de configuración GPIO imaginario para ilustrar esto:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: right">Nombre</th><th style="text-align: right">Número(s) de bit</th><th style="text-align: right">Valor</th><th style="text-align: right">Significado</th><th style="text-align: right">Notas</th></tr></thead><tbody>
<tr><td style="text-align: right">enable</td><td style="text-align: right">0</td><td style="text-align: right">0</td><td style="text-align: right">disabled</td><td style="text-align: right">Deshabilita el GPIO</td></tr>
<tr><td style="text-align: right"></td><td style="text-align: right"></td><td style="text-align: right">1</td><td style="text-align: right">enabled</td><td style="text-align: right">Habilita el GPIO</td></tr>
<tr><td style="text-align: right">direction</td><td style="text-align: right">1</td><td style="text-align: right">0</td><td style="text-align: right">input</td><td style="text-align: right">Establece la dirección en Entrada</td></tr>
<tr><td style="text-align: right"></td><td style="text-align: right"></td><td style="text-align: right">1</td><td style="text-align: right">output</td><td style="text-align: right">Establece la dirección en Salida</td></tr>
<tr><td style="text-align: right">input_mode</td><td style="text-align: right">2..3</td><td style="text-align: right">00</td><td style="text-align: right">hi-z</td><td style="text-align: right">Establece la entrada como alta impedancia</td></tr>
<tr><td style="text-align: right"></td><td style="text-align: right"></td><td style="text-align: right">01</td><td style="text-align: right">pull-down</td><td style="text-align: right">El pin de entrada se establece a pull-down</td></tr>
<tr><td style="text-align: right"></td><td style="text-align: right"></td><td style="text-align: right">10</td><td style="text-align: right">pull-up</td><td style="text-align: right">El pin de entrada se establece a pull-up</td></tr>
<tr><td style="text-align: right"></td><td style="text-align: right"></td><td style="text-align: right">11</td><td style="text-align: right">n/a</td><td style="text-align: right">Estado Inválido. No establecer</td></tr>
<tr><td style="text-align: right">output_mode</td><td style="text-align: right">4</td><td style="text-align: right">0</td><td style="text-align: right">set-low</td><td style="text-align: right">El pin de salida se lleva a bajo</td></tr>
<tr><td style="text-align: right"></td><td style="text-align: right"></td><td style="text-align: right">1</td><td style="text-align: right">set-high</td><td style="text-align: right">El pin de salida se lleva a alto</td></tr>
<tr><td style="text-align: right">input_status</td><td style="text-align: right">5</td><td style="text-align: right">x</td><td style="text-align: right">in-val</td><td style="text-align: right">0 si la entrada es &lt; 1.5v, 1 si la entrada es &gt;= 1.5v</td></tr>
</tbody></table>
</div>
<p><em>Podríamos</em> exponer la siguiente estructura en Rust para controlar este GPIO:</p>
<pre><code class="language-rust ignore">/// GPIO interface
struct GpioConfig {
    /// GPIO Configuration structure generated by svd2rust
    periph: GPIO_CONFIG,
}

impl GpioConfig {
    pub fn set_enable(&amp;mut self, is_enabled: bool) {
        self.periph.modify(|_r, w| {
            w.enable().set_bit(is_enabled)
        });
    }

    pub fn set_direction(&amp;mut self, is_output: bool) {
        self.periph.modify(|_r, w| {
            w.direction().set_bit(is_output)
        });
    }

    pub fn set_input_mode(&amp;mut self, variant: InputMode) {
        self.periph.modify(|_r, w| {
            w.input_mode().variant(variant)
        });
    }

    pub fn set_output_mode(&amp;mut self, is_high: bool) {
        self.periph.modify(|_r, w| {
            w.output_mode.set_bit(is_high)
        });
    }

    pub fn get_input_status(&amp;self) -&gt; bool {
        self.periph.read().input_status().bit_is_set()
    }
}</code></pre>
<p>Sin embargo, esto nos permitiría modificar ciertos registros que no tienen sentido. Por ejemplo, ¿qué sucede si configuramos el campo <code>output_mode</code> cuando nuestro GPIO está configurado como entrada?</p>
<p>En general, el uso de esta estructura nos permitiría alcanzar estados no definidos por nuestra máquina de estado anterior: p.e. una salida con un pull-down o una entrada establecida a nivel alto. Para algunos hardware, esto puede no importar. ¡En otro hardware, podría causar un comportamiento inesperado o indefinido!</p>
<p>Aunque esta interfaz es conveniente para escribir, no hace cumplir los contratos de diseño establecidos por nuestra implementación de hardware.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contratos-de-diseño"><a class="header" href="#contratos-de-diseño">Contratos de diseño</a></h1>
<p>En nuestro último capítulo, escribimos una interfaz que <em>no</em> hacía cumplir los contratos de diseño. Echemos otro vistazo a nuestro registro de configuración GPIO imaginario:</p>
<div class="table-wrapper"><table><thead><tr><th style="text-align: right">Nombre</th><th style="text-align: right">Número(s) de bit</th><th style="text-align: right">Valor</th><th style="text-align: right">Significado</th><th style="text-align: right">Notas</th></tr></thead><tbody>
<tr><td style="text-align: right">enable</td><td style="text-align: right">0</td><td style="text-align: right">0</td><td style="text-align: right">disabled</td><td style="text-align: right">Deshabilita el GPIO</td></tr>
<tr><td style="text-align: right"></td><td style="text-align: right"></td><td style="text-align: right">1</td><td style="text-align: right">enabled</td><td style="text-align: right">Habilita el GPIO</td></tr>
<tr><td style="text-align: right">direction</td><td style="text-align: right">1</td><td style="text-align: right">0</td><td style="text-align: right">input</td><td style="text-align: right">Establece la dirección a Entrada</td></tr>
<tr><td style="text-align: right"></td><td style="text-align: right"></td><td style="text-align: right">1</td><td style="text-align: right">output</td><td style="text-align: right">Establece la dirección a Salida</td></tr>
<tr><td style="text-align: right">input_mode</td><td style="text-align: right">2..3</td><td style="text-align: right">00</td><td style="text-align: right">hi-z</td><td style="text-align: right">Establece la entrada como alta impedancia</td></tr>
<tr><td style="text-align: right"></td><td style="text-align: right"></td><td style="text-align: right">01</td><td style="text-align: right">pull-low</td><td style="text-align: right">El pin de entrada es pull-down</td></tr>
<tr><td style="text-align: right"></td><td style="text-align: right"></td><td style="text-align: right">10</td><td style="text-align: right">pull-high</td><td style="text-align: right">El pin de entrada es pull-up</td></tr>
<tr><td style="text-align: right"></td><td style="text-align: right"></td><td style="text-align: right">11</td><td style="text-align: right">n/a</td><td style="text-align: right">Estado Inválido. No establecer</td></tr>
<tr><td style="text-align: right">output_mode</td><td style="text-align: right">4</td><td style="text-align: right">0</td><td style="text-align: right">set-low</td><td style="text-align: right">El pin de salida se lleva a bajo</td></tr>
<tr><td style="text-align: right"></td><td style="text-align: right"></td><td style="text-align: right">1</td><td style="text-align: right">set-high</td><td style="text-align: right">El pin de salida se lleva a alto</td></tr>
<tr><td style="text-align: right">input_status</td><td style="text-align: right">5</td><td style="text-align: right">x</td><td style="text-align: right">in-val</td><td style="text-align: right">0 si la entrada es &lt; 1.5v, 1 si la entrada es &gt;= 1.5v</td></tr>
</tbody></table>
</div>
<p>Si, en cambio, verificamos el estado antes de hacer uso del hardware subyacente, haciendo cumplir nuestros contratos de diseño en tiempo de ejecución, podríamos escribir un código que se vea así:</p>
<pre><code class="language-rust ignore">/// GPIO interface
struct GpioConfig {
    /// GPIO Configuration structure generated by svd2rust
    periph: GPIO_CONFIG,
}

impl GpioConfig {
    pub fn set_enable(&amp;mut self, is_enabled: bool) {
        self.periph.modify(|_r, w| {
            w.enable().set_bit(is_enabled)
        });
    }

    pub fn set_direction(&amp;mut self, is_output: bool) -&gt; Result&lt;(), ()&gt; {
        if self.periph.read().enable().bit_is_clear() {
            // Must be enabled to set direction
            return Err(());
        }

        self.periph.modify(|r, w| {
            w.direction().set_bit(is_output)
        });

        Ok(())
    }

    pub fn set_input_mode(&amp;mut self, variant: InputMode) -&gt; Result&lt;(), ()&gt; {
        if self.periph.read().enable().bit_is_clear() {
            // Must be enabled to set input mode
            return Err(());
        }

        if self.periph.read().direction().bit_is_set() {
            // Direction must be input
            return Err(());
        }

        self.periph.modify(|_r, w| {
            w.input_mode().variant(variant)
        });

        Ok(())
    }

    pub fn set_output_status(&amp;mut self, is_high: bool) -&gt; Result&lt;(), ()&gt; {
        if self.periph.read().enable().bit_is_clear() {
            // Must be enabled to set output status
            return Err(());
        }

        if self.periph.read().direction().bit_is_clear() {
            // Direction must be output
            return Err(());
        }

        self.periph.modify(|_r, w| {
            w.output_mode.set_bit(is_high)
        });

        Ok(())
    }

    pub fn get_input_status(&amp;self) -&gt; Result&lt;bool, ()&gt; {
        if self.periph.read().enable().bit_is_clear() {
            // Must be enabled to get status
            return Err(());
        }

        if self.periph.read().direction().bit_is_set() {
            // Direction must be input
            return Err(());
        }

        Ok(self.periph.read().input_status().bit_is_set())
    }
}</code></pre>
<p>Debido a que necesitamos hacer cumplir las restricciones en el hardware, terminamos haciendo muchas comprobaciones en tiempo de ejecución, lo que desperdicia tiempo y recursos, y este código será mucho menos agradable de usar para el desarrollador.</p>
<h2 id="tipo-de-estados"><a class="header" href="#tipo-de-estados">Tipo de estados</a></h2>
<p>But what if instead, we used Rust's type system to enforce the state transition rules? Take this example:</p>
<pre><code class="language-rust ignore">/// GPIO interface
struct GpioConfig&lt;ENABLED, DIRECTION, MODE&gt; {
    /// GPIO Configuration structure generated by svd2rust
    periph: GPIO_CONFIG,
    enabled: ENABLED,
    direction: DIRECTION,
    mode: MODE,
}

// Type states for MODE in GpioConfig
struct Disabled;
struct Enabled;
struct Output;
struct Input;
struct PulledLow;
struct PulledHigh;
struct HighZ;
struct DontCare;

/// These functions may be used on any GPIO Pin
impl&lt;EN, DIR, IN_MODE&gt; GpioConfig&lt;EN, DIR, IN_MODE&gt; {
    pub fn into_disabled(self) -&gt; GpioConfig&lt;Disabled, DontCare, DontCare&gt; {
        self.periph.modify(|_r, w| w.enable.disabled());
        GpioConfig {
            periph: self.periph,
            enabled: Disabled,
            direction: DontCare,
            mode: DontCare,
        }
    }

    pub fn into_enabled_input(self) -&gt; GpioConfig&lt;Enabled, Input, HighZ&gt; {
        self.periph.modify(|_r, w| {
            w.enable.enabled()
             .direction.input()
             .input_mode.high_z()
        });
        GpioConfig {
            periph: self.periph,
            enabled: Enabled,
            direction: Input,
            mode: HighZ,
        }
    }

    pub fn into_enabled_output(self) -&gt; GpioConfig&lt;Enabled, Output, DontCare&gt; {
        self.periph.modify(|_r, w| {
            w.enable.enabled()
             .direction.output()
             .input_mode.set_high()
        });
        GpioConfig {
            periph: self.periph,
            enabled: Enabled,
            direction: Output,
            mode: DontCare,
        }
    }
}

/// This function may be used on an Output Pin
impl GpioConfig&lt;Enabled, Output, DontCare&gt; {
    pub fn set_bit(&amp;mut self, set_high: bool) {
        self.periph.modify(|_r, w| w.output_mode.set_bit(set_high));
    }
}

/// These methods may be used on any enabled input GPIO
impl&lt;IN_MODE&gt; GpioConfig&lt;Enabled, Input, IN_MODE&gt; {
    pub fn bit_is_set(&amp;self) -&gt; bool {
        self.periph.read().input_status.bit_is_set()
    }

    pub fn into_input_high_z(self) -&gt; GpioConfig&lt;Enabled, Input, HighZ&gt; {
        self.periph.modify(|_r, w| w.input_mode().high_z());
        GpioConfig {
            periph: self.periph,
            enabled: Enabled,
            direction: Input,
            mode: HighZ,
        }
    }

    pub fn into_input_pull_down(self) -&gt; GpioConfig&lt;Enabled, Input, PulledLow&gt; {
        self.periph.modify(|_r, w| w.input_mode().pull_low());
        GpioConfig {
            periph: self.periph,
            enabled: Enabled,
            direction: Input,
            mode: PulledLow,
        }
    }

    pub fn into_input_pull_up(self) -&gt; GpioConfig&lt;Enabled, Input, PulledHigh&gt; {
        self.periph.modify(|_r, w| w.input_mode().pull_high());
        GpioConfig {
            periph: self.periph,
            enabled: Enabled,
            direction: Input,
            mode: PulledHigh,
        }
    }
}</code></pre>
<p>Ahora veamos cómo se vería el código que usa esto:</p>
<pre><code class="language-rust ignore">/*
 * Example 1: Unconfigured to High-Z input
 */
let pin: GpioConfig&lt;Disabled, _, _&gt; = get_gpio();

// Can't do this, pin isn't enabled!
// pin.into_input_pull_down();

// Now turn the pin from unconfigured to a high-z input
let input_pin = pin.into_enabled_input();

// Read from the pin
let pin_state = input_pin.bit_is_set();

// Can't do this, input pins don't have this interface!
// input_pin.set_bit(true);

/*
 * Example 2: High-Z input to Pulled Low input
 */
let pulled_low = input_pin.into_input_pull_down();
let pin_state = pulled_low.bit_is_set();

/*
 * Example 3: Pulled Low input to Output, set high
 */
let output_pin = pulled_low.into_enabled_output();
output_pin.set_bit(true);

// Can't do this, output pins don't have this interface!
// output_pin.into_input_pull_down();</code></pre>
<p>Esta es definitivamente una forma conveniente de almacenar el estado del pin, pero ¿por qué hacerlo de esta manera? ¿Por qué es esto mejor que almacenar el estado como un <code>enum</code> dentro de nuestra estructura <code>GpioConfig</code>?</p>
<h2 id="tiempo-de-compilación-seguridad-funcional"><a class="header" href="#tiempo-de-compilación-seguridad-funcional">Tiempo de compilación Seguridad funcional</a></h2>
<p>Debido a que estamos aplicando nuestras restricciones de diseño por completo en tiempo de compilación, esto no genera costos de tiempo de ejecución. Es imposible establecer un modo de salida cuando tienes un pin en un modo de entrada. En su lugar, debes recorrer los estados convirtiéndolos en un pin de salida y luego configurando el modo de salida. Debido a esto, no hay penalización de tiempo de ejecución por verificar el estado actual antes de ejecutar una función.</p>
<p>Además, debido a que estos estados son impuestos por el sistema de tipos, ya no hay espacio para errores por parte de los consumidores de esta interfaz. Si intentan realizar una transición de estado ilegal, ¡el código no se compilará!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="abstracciones-de-costo-cero"><a class="header" href="#abstracciones-de-costo-cero">Abstracciones de Costo Cero</a></h1>
<p>Los estados de tipo también son un excelente ejemplo de abstracciones de costo cero: la capacidad de mover ciertos comportamientos para compilar el tiempo de ejecución o análisis. Estos estados de tipo no contienen datos reales y, en su lugar, se utilizan como marcadores. Dado que no contienen datos, no tienen una representación real en la memoria en tiempo de ejecución:</p>
<pre><code class="language-rust ignore">use core::mem::size_of;

let _ = size_of::&lt;Enabled&gt;();    // == 0
let _ = size_of::&lt;Input&gt;();      // == 0
let _ = size_of::&lt;PulledHigh&gt;(); // == 0
let _ = size_of::&lt;GpioConfig&lt;Enabled, Input, PulledHigh&gt;&gt;(); // == 0</code></pre>
<h2 id="tipos-de-tamaño-cero"><a class="header" href="#tipos-de-tamaño-cero">Tipos de tamaño cero</a></h2>
<pre><code class="language-rust ignore">struct Enabled;</code></pre>
<p>Las estructuras definidas de esta manera se denominan tipos de tamaño cero, ya que no contienen datos reales. Aunque estos tipos actúan como &quot;reales&quot; en tiempo de compilación, puede copiarlos, moverlos, tomar referencias a ellos, etc., sin embargo, el optimizador los eliminará por completo.</p>
<p>En este fragmento de código:</p>
<pre><code class="language-rust ignore">pub fn into_input_high_z(self) -&gt; GpioConfig&lt;Enabled, Input, HighZ&gt; {
    self.periph.modify(|_r, w| w.input_mode().high_z());
    GpioConfig {
        periph: self.periph,
        enabled: Enabled,
        direction: Input,
        mode: HighZ,
    }
}</code></pre>
<p>El GpioConfig que devolvemos nunca existe en tiempo de ejecución. Llamar a esta función generalmente se reducirá a una sola instrucción de ensamblaje: almacenar un valor de registro constante en una ubicación de registro. Esto significa que la interfaz de estado de tipo que hemos desarrollado es una abstracción de costo cero: no usa más CPU, RAM o espacio de código para rastrear el estado de <code>GpioConfig</code>, y representa el mismo código de máquina como un acceso de registro directo.</p>
<h2 id="anidado"><a class="header" href="#anidado">Anidado</a></h2>
<p>En general, estas abstracciones se pueden anidar tan profundamente como desee. Siempre que todos los componentes utilizados sean tipos de tamaño cero, la estructura completa no existirá en tiempo de ejecución.</p>
<p>Para estructuras complejas o profundamente anidadas, puede ser tedioso definir todas las combinaciones posibles de estado. En estos casos, se pueden utilizar macros para generar todas las implementaciones.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="portabilidad"><a class="header" href="#portabilidad">Portabilidad</a></h1>
<p>En entornos embebidos, la portabilidad es un tema muy importante: Cada proveedor e incluso cada familia de un mismo fabricante ofrece diferentes periféricos y capacidades y, de forma similar, las formas de interactuar con los periféricos variarán.</p>
<p>Una forma común de igualar estas diferencias es a través de una capa llamada capa de Abstracción de Hardware o <strong>HAL</strong>.</p>
<blockquote>
<p>Las abstracciones de hardware son conjuntos de rutinas en software que emulan algunos detalles específicos de la plataforma, dando a los programas acceso directo a los recursos de hardware.</p>
<p>Suelen permitir a los programadores escribir aplicaciones independientes del dispositivo y de alto rendimiento al proporcionar llamadas estándar del sistema operativo (SO) al hardware.</p>
<p><em>Wikipedia: <a href="https://en.wikipedia.org/wiki/Hardware_abstraction">capa de abstracción de hardware</a></em></p>
</blockquote>
<p>Los sistemas embebidos son un poco especiales en este sentido, ya que normalmente no tenemos sistemas operativos y software instalable por el usuario, sino imágenes de firmware que se compilan como un todo, así como una serie de otras limitaciones. Así que, aunque el enfoque tradicional tal y como lo define Wikipedia podría funcionar, probablemente no sea el enfoque más productivo para garantizar la portabilidad.</p>
<p>¿Cómo lo hacemos en Rust? Entra <strong>embedded-hal</strong>...</p>
<h2 id="qué-es-embedded-hal"><a class="header" href="#qué-es-embedded-hal">¿Qué es embedded-hal?</a></h2>
<p>En pocas palabras es un conjunto de <em>traits</em> que definen contratos de implementación entre <strong>implementaciones de HAL</strong>, <strong>controladores</strong> y <strong>aplicaciones (o firmwares)</strong>. Estos contratos incluyen tanto capacidades (es decir, si un <em>trait</em> se implementa para un determinado tipo, la <strong>implementación de HAL</strong> proporciona una determinada capacidad) como métodos (es decir, si puedes construir un tipo implementando un <em>trait</em>, está garantizado que dispones de los métodos especificados en el <em>trait</em>).</p>
<p>Una estratificación típica podría ser la siguiente</p>
<p><img src="portability/../assets/rust_layers.svg" alt="" /></p>
<p>Algunos de los traits definidos en <strong>embedded-hal</strong> son:</p>
<ul>
<li>GPIO (pines de entrada y salida)</li>
<li>Comunicación serie</li>
<li>I2C</li>
<li>SPI</li>
<li>Temporizadores/Cuentas atrás</li>
<li>Conversión analógico-digital</li>
</ul>
<p>La razón principal para tener los <em>traits</em> <strong>embedded-hal</strong> y las crates que los implementan y utilizan es mantener la complejidad bajo control. Si se tiene en cuenta que una aplicación puede tener que implementar el uso del periférico en el hardware, así como la aplicación y, potencialmente, los controladores para los componentes de hardware adicionales, entonces debería ser fácil ver que la reutilización es muy limitada. Expresado matemáticamente, si <strong>M</strong> es el número de implementaciones de periféricos HAL y <strong>N</strong> el número de drivers, entonces si tuviéramos que reinventar la rueda para cada aplicación acabaríamos con <strong>M*N</strong> implementaciones, mientras que usando la <em>API</em> proporcionada por los <em>traits</em> <strong>embedded-hal</strong> la complejidad de la implementación se acercará a <strong>M+N</strong>. Por supuesto hay beneficios adicionales que se pueden obtener, tales como menos ensayo-y-error debido a una API bien definida y lista para usar.</p>
<h2 id="usuarios-de-embedded-hal"><a class="header" href="#usuarios-de-embedded-hal">Usuarios de embedded-hal</a></h2>
<p>Como se ha dicho anteriormente hay tres usuarios principales de la HAL:</p>
<h3 id="implementación-hal"><a class="header" href="#implementación-hal">Implementación HAL</a></h3>
<p>Una implementación HAL proporciona la interfaz entre el hardware y los usuarios de los <em>traits</em> HAL. Las implementaciones típicas constan de tres partes:</p>
<ul>
<li>Uno o más tipos específicos de hardware</li>
<li>Funciones para crear e inicializar dicho tipo, a menudo proporcionando varias opciones de configuración (velocidad, modo de funcionamiento, pines de uso, etc.)</li>
<li>Uno o más <code>trait</code> <code>impl</code> de <em>traits</em> <strong>embedded-hal</strong> para ese tipo.</li>
</ul>
<p>La implementación de <strong>HAL</strong> puede ser de varios tipos:</p>
<ul>
<li>Mediante acceso a hardware de bajo nivel, p.e. a través de registros.</li>
<li>A través del sistema operativo, p.e. mediante el uso de <code>sysfs</code> en Linux</li>
<li>A través de un adaptador, p.e. un simulador de tipos para pruebas unitarias.</li>
<li>A través de controladores para adaptadores de hardware, p.e. multiplexores I2C o expansores GPIO.</li>
</ul>
<h3 id="controlador"><a class="header" href="#controlador">Controlador</a></h3>
<p>Un driver implementa un conjunto de funcionalidades personalizadas para un componente interno o externo, conectado a un periférico que implementa los <em>traits</em> embedded-hal. Ejemplos típicos para tales controladores incluyen varios sensores (temperatura, magnetómetro, acelerómetro, luz), dispositivos de visualización (matrices de LED, pantallas LCD) y actuadores (motores, transmisores).</p>
<p>Un controlador tiene que ser inicializado con una instancia de tipo que implemente un determinado <code>trait</code> del embedded-hal que se asegura a través de <em>trait bound</em> y proporciona su propia instancia de tipo con un conjunto personalizado de métodos que permiten interactuar con el dispositivo controlado.</p>
<h3 id="aplicación"><a class="header" href="#aplicación">Aplicación</a></h3>
<p>La aplicación une las distintas partes y asegura que se consigue la funcionalidad deseada. Al portar entre diferentes sistemas, esta es la parte que requiere más esfuerzos de adaptación, ya que la aplicación necesita inicializar correctamente el hardware real a través de la implementación HAL y la inicialización de diferentes hardware difiere, a veces drásticamente. También la elección del usuario juega a menudo un papel importante, ya que los componentes pueden conectarse físicamente a diferentes terminales, los buses de hardware a veces necesitan hardware externo para ajustarse a la configuración o hay que hacer diferentes compensaciones en el uso de los periféricos internos (p.e. se dispone de múltiples temporizadores con diferentes capacidades o los periféricos entran en conflicto con otros).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="concurrencia"><a class="header" href="#concurrencia">Concurrencia</a></h1>
<p>La concurrencia se produce cuando diferentes partes del programa se ejecutan en momentos diferentes o fuera de orden. En un contexto embebido, esto incluye:</p>
<ul>
<li>Manejadores de interrupción, que se ejecutan cada vez que se produce la interrupción asociada,</li>
<li>varias formas de multihilo, en las que el microprocesador intercambia regularmente partes del programa,</li>
<li>y, en algunos sistemas, microprocesadores multinúcleo, en los que cada núcleo puede ejecutar de forma independiente una parte diferente del programa al mismo tiempo.</li>
</ul>
<p>Dado que muchos programas embebidos necesitan lidiar con interrupciones, la concurrencia aparecerá tarde o temprano, y es también donde muchos errores sutiles y difíciles pueden ocurrir. Afortunadamente, Rust proporciona una serie de abstracciones y garantías de seguridad para ayudarnos a escribir código correcto.</p>
<h2 id="sin-concurrencia"><a class="header" href="#sin-concurrencia">Sin concurrencia</a></h2>
<p>La concurrencia más simple para un programa embebido es la no concurrencia: tu software consiste en un único bucle principal que sigue corriendo, y no hay interrupciones en absoluto. A veces esto es perfectamente adecuado para el problema en cuestión. Normalmente, el bucle leerá algunas entradas, realizará algún procesamiento y escribirá algunas salidas.</p>
<pre><code class="language-rust ignore">#[entry]
fn main() {
    let peripherals = setup_peripherals();
    loop {
        let inputs = read_inputs(&amp;peripherals);
        let outputs = process(inputs);
        write_outputs(&amp;peripherals, outputs);
    }
}</code></pre>
<p>Como no hay concurrencia, no hay necesidad de preocuparse por compartir datos entre partes de tu programa o sincronizar el acceso a los periféricos. Si puedes salirte con la tuya con un enfoque tan simple esta puede ser una gran solución.</p>
<h2 id="datos-mutables-globales"><a class="header" href="#datos-mutables-globales">Datos Mutables Globales</a></h2>
<p>A diferencia del Rust no embebido, normalmente no tendremos el lujo de crear asignaciones de heap y pasar referencias a esos datos a un hilo recién creado. En su lugar, nuestros manejadores de interrupciones pueden ser llamados en cualquier momento y deben saber cómo acceder a cualquier memoria compartida que estemos utilizando. En el nivel más bajo, esto significa que debemos tener memoria mutable <em>asignada estáticamente</em>, a la que tanto el manejador de interrupciones como el código principal puedan referirse.</p>
<p>En Rust, tales variables <a href="https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html#accessing-or-modifying-a-mutable-static-variable"><code>static mut</code></a> son siempre inseguras para leer o escribir, porque sin tener especial cuidado, podrías provocar una condición de carrera, donde tu acceso a la variable es interrumpido a mitad de camino por una interrupción que también accede a esa variable.</p>
<p>Para un ejemplo de cómo este comportamiento puede causar errores sutiles en tu código, considera un programa embebido que cuenta los flancos ascendentes de alguna señal de entrada en cada periodo de un segundo (un contador de frecuencia):</p>
<pre><code class="language-rust ignore">static mut COUNTER: u32 = 0;

#[entry]
fn main() -&gt; ! {
    set_timer_1hz();
    let mut last_state = false;
    loop {
        let state = read_signal_level();
        if state &amp;&amp; !last_state {
            // DANGER - Not actually safe! Could cause data races.
            unsafe { COUNTER += 1 };
        }
        last_state = state;
    }
}

#[interrupt]
fn timer() {
    unsafe { COUNTER = 0; }
}</code></pre>
<p>Cada segundo, la interrupción del temporizador vuelve a poner el contador a 0. Mientras tanto, el bucle principal mide continuamente la señal, e incrementa el contador cuando ve un cambio de bajo a alto. Hemos tenido que usar <code>unsafe</code> para acceder a <code>COUNTER</code>, ya que es <code>static mut</code>, y eso significa que estamos prometiendo al compilador que no causaremos ningún comportamiento indefinido. ¿Puedes detectar la condición de carrera? El incremento en <code>COUNTER</code> <em>no</em> está garantizado que sea atómico - de hecho, en la mayoría de las plataformas embebidas, se dividirá en una carga, luego el incremento, y luego un almacenamiento. Si la interrupción se disparara después de la carga pero antes del almacenamiento, el reset a 0 sería ignorado después de que la interrupción volviera - y contaríamos el doble de transiciones para ese periodo.</p>
<h2 id="secciones-críticas"><a class="header" href="#secciones-críticas">Secciones críticas</a></h2>
<p>Entonces, ¿qué podemos hacer con las carreras de datos? Un enfoque sencillo es utilizar <em>secciones críticas</em>, un contexto en el que las interrupciones están deshabilitadas. Envolviendo el acceso a <code>COUNTER</code> en <code>main</code> en una sección crítica, podemos estar seguros de que la interrupción del temporizador no se disparará hasta que hayamos terminado de incrementar <code>COUNTER</code>:</p>
<pre><code class="language-rust ignore">static mut COUNTER: u32 = 0;

#[entry]
fn main() -&gt; ! {
    set_timer_1hz();
    let mut last_state = false;
    loop {
        let state = read_signal_level();
        if state &amp;&amp; !last_state {
            // New critical section ensures synchronised access to COUNTER
            cortex_m::interrupt::free(|_| {
                unsafe { COUNTER += 1 };
            });
        }
        last_state = state;
    }
}

#[interrupt]
fn timer() {
    unsafe { COUNTER = 0; }
}</code></pre>
<p>En este ejemplo, usamos <code>cortex_m::interrupt::free</code>, pero otras plataformas tendrán mecanismos similares para ejecutar código en una sección crítica. Esto también es lo mismo que desactivar las interrupciones, ejecutar algo de código, y luego volver a activar las interrupciones.</p>
<p>Observa que no necesitamos poner una sección crítica dentro de la interrupción del temporizador, por dos razones:</p>
<ul>
<li>Escribir 0 en <code>COUNTER</code> no puede verse afectado por una carrera ya que no lo leemos.</li>
<li>De todas formas nunca será interrumpido por el hilo `main</li>
</ul>
<p>Si <code>COUNTER</code> estuviera siendo compartido por múltiples manejadores de interrupción que pudieran <em>prevenir</em> a cada uno, entonces cada uno podría requerir una sección crítica también.</p>
<p>Esto resuelve nuestro problema inmediato, pero seguimos escribiendo mucho código inseguro sobre el que tenemos que razonar cuidadosamente, y podríamos estar usando secciones críticas innecesariamente. Dado que cada sección crítica pausa temporalmente el procesamiento de interrupciones, hay un costo asociado de algún tamaño de código extra y mayor latencia de interrupción y jitter (las interrupciones pueden tardar más en ser procesadas, y el tiempo hasta que son procesadas será más variable). Que esto sea un problema depende de tu sistema, pero en general, nos gustaría evitarlo.</p>
<p>Vale la pena señalar que, si bien una sección crítica garantiza que no se produzcan interrupciones, ¡no proporciona una garantía de exclusividad en sistemas multinúcleo!  El otro núcleo podría estar accediendo felizmente a la misma memoria que tu núcleo, incluso sin interrupciones. Necesitarás primitivas de sincronización más fuertes si estás usando múltiples núcleos.</p>
<h2 id="acceso-atómico"><a class="header" href="#acceso-atómico">Acceso atómico</a></h2>
<p>En algunas plataformas existen instrucciones atómicas especiales que garantizan las operaciones de lectura-modificación-escritura. Específicamente para Cortex-M: <code>thumbv6</code> (Cortex-M0, Cortex-M0+) sólo proporciona instrucciones atómicas de carga y almacenamiento, mientras que <code>thumbv7</code> (Cortex-M3 y superiores) proporciona instrucciones completas de Comparación e Intercambio (CAS). Estas instrucciones CAS ofrecen una alternativa a la pesada deshabilitación de todas las interrupciones: podemos intentar el incremento, que tendrá éxito la mayoría de las veces, pero si se interrumpe se reintentará automáticamente toda la operación de incremento. Estas operaciones atómicas son seguras incluso en múltiples núcleos.</p>
<pre><code class="language-rust ignore">use core::sync::atomic::{AtomicUsize, Ordering};

static COUNTER: AtomicUsize = AtomicUsize::new(0);

#[entry]
fn main() -&gt; ! {
    set_timer_1hz();
    let mut last_state = false;
    loop {
        let state = read_signal_level();
        if state &amp;&amp; !last_state {
            // Use `fetch_add` to atomically add 1 to COUNTER
            COUNTER.fetch_add(1, Ordering::Relaxed);
        }
        last_state = state;
    }
}

#[interrupt]
fn timer() {
    // Use `store` to write 0 directly to COUNTER
    COUNTER.store(0, Ordering::Relaxed)
}</code></pre>
<p>Esta vez <code>COUNTER</code> es una variable <code>static</code> segura. Gracias al tipo <code>AtomicUsize</code> <code>COUNTER</code> puede modificarse de forma segura tanto desde el manejador de interrupciones como desde el hilo principal sin desactivar las interrupciones. Cuando sea posible, esta es la mejor solución - pero puede que no esté soportada en tu plataforma.</p>
<p>Una nota sobre <a href="https://doc.rust-lang.org/core/sync/atomic/enum.Ordering.html"><code>Ordering</code></a>: esto afecta a cómo el compilador y el hardware pueden reordenar las instrucciones, y también tiene consecuencias sobre la visibilidad de la caché. Asumiendo que el objetivo es una plataforma mononúcleo, <code>Relaxed</code> es suficiente y la opción más eficiente en este caso particular. Un ordenamiento más estricto hará que el compilador emita barreras de memoria alrededor de las operaciones atómicas; ¡dependiendo de para qué uses las atómicas puedes necesitarlo o no! Los detalles precisos del modelo atómico son complicados y es mejor describirlos en otro lugar.</p>
<p>Para más detalles sobre atómicos y ordenación, vea el <a href="https://doc.rust-lang.org/nomicon/atomics.html">nomicon</a>.</p>
<h2 id="abstracciones-envío-y-sincronización"><a class="header" href="#abstracciones-envío-y-sincronización">Abstracciones, envío y sincronización</a></h2>
<p>Ninguna de las soluciones anteriores es especialmente satisfactoria. Requieren bloques &quot;inseguros&quot; que deben ser comprobados cuidadosamente y no son ergonómicos. ¡Seguramente podemos hacerlo mejor en Rust!</p>
<p>Podemos abstraer nuestro contador en una interfaz segura que pueda ser utilizada con seguridad en cualquier otra parte de nuestro código. Para este ejemplo, usaremos el contador de sección crítica, pero podrías hacer algo muy similar con atomics.</p>
<pre><code class="language-rust ignore">use core::cell::UnsafeCell;
use cortex_m::interrupt;

// Our counter is just a wrapper around UnsafeCell&lt;u32&gt;, which is the heart
// of interior mutability in Rust. By using interior mutability, we can have
// COUNTER be `static` instead of `static mut`, but still able to mutate
// its counter value.
struct CSCounter(UnsafeCell&lt;u32&gt;);

const CS_COUNTER_INIT: CSCounter = CSCounter(UnsafeCell::new(0));

impl CSCounter {
    pub fn reset(&amp;self, _cs: &amp;interrupt::CriticalSection) {
        // By requiring a CriticalSection be passed in, we know we must
        // be operating inside a CriticalSection, and so can confidently
        // use this unsafe block (required to call UnsafeCell::get).
        unsafe { *self.0.get() = 0 };
    }

    pub fn increment(&amp;self, _cs: &amp;interrupt::CriticalSection) {
        unsafe { *self.0.get() += 1 };
    }
}

// Required to allow static CSCounter. See explanation below.
unsafe impl Sync for CSCounter {}

// COUNTER is no longer `mut` as it uses interior mutability;
// therefore it also no longer requires unsafe blocks to access.
static COUNTER: CSCounter = CS_COUNTER_INIT;

#[entry]
fn main() -&gt; ! {
    set_timer_1hz();
    let mut last_state = false;
    loop {
        let state = read_signal_level();
        if state &amp;&amp; !last_state {
            // No unsafe here!
            interrupt::free(|cs| COUNTER.increment(cs));
        }
        last_state = state;
    }
}

#[interrupt]
fn timer() {
    // We do need to enter a critical section here just to obtain a valid
    // cs token, even though we know no other interrupt could pre-empt
    // this one.
    interrupt::free(|cs| COUNTER.reset(cs));

    // We could use unsafe code to generate a fake CriticalSection if we
    // really wanted to, avoiding the overhead:
    // let cs = unsafe { interrupt::CriticalSection::new() };
}</code></pre>
<p>Hemos movido nuestro código inseguro (<code>unsafe</code>) al interior de nuestra abstracción cuidadosamente planificada, y ahora el código de nuestra aplicación no contiene ningún bloque inseguro (<code>unsafe</code>).</p>
<p>Este diseño requiere que la aplicación pase un token <code>CriticalSection</code>: estos tokens sólo son generados de forma segura por <code>interrupt::free</code>, así que al requerir que se pase uno, nos aseguramos de que estamos operando dentro de una sección crítica, sin tener que hacer el bloqueo nosotros mismos. Esta garantía la proporciona estáticamente el compilador: no habrá ninguna sobrecarga en tiempo de ejecución asociada a <code>cs</code>. Si tuviéramos múltiples contadores, a todos se les podría dar el mismo <code>cs</code>, sin necesidad de múltiples secciones críticas anidadas.</p>
<p>Esto también trae a colación un tema importante para la concurrencia en Rust: los <em>traits</em> <a href="https://doc.rust-lang.org/nomicon/send-and-sync.html"><code>Send</code> y <code>Sync</code></a>. Para resumir el libro de Rust, un tipo es Send cuando puede ser movido con seguridad a otro hilo, mientras que es Sync cuando puede ser compartido con seguridad entre múltiples hilos. En un contexto embebido, consideramos que las interrupciones se ejecutan en un hilo separado del código de la aplicación, por lo que las variables accedidas tanto por una interrupción como por el código principal deben ser Sync.</p>
<p>Para la mayoría de los tipos en Rust, ambos <em>traits</em> se derivan automáticamente por el compilador. Sin embargo, debido a que <code>CSCounter</code> contiene una <a href="https://doc.rust-lang.org/core/cell/struct.UnsafeCell.html"><code>UnsafeCell</code></a>, no es Sync, y por lo tanto no podríamos hacer un <code>static CSCounter</code>: las variables <code>static</code> <em>deben</em> ser Sync, ya que pueden ser accedidas por múltiples hilos.</p>
<p>Para indicar al compilador que nos hemos asegurado de que el <code>CSCounter</code> es seguro para compartir entre hilos, implementamos el rasgo Sync explícitamente. Al igual que con el uso anterior de secciones críticas, esto sólo es seguro en plataformas mononúcleo: con múltiples núcleos, tendrías que ir más lejos para garantizar la seguridad.</p>
<h2 id="mutexes"><a class="header" href="#mutexes">Mutexes</a></h2>
<p>Hemos creado una abstracción útil específica para nuestro problema de contadores, pero hay muchas abstracciones comunes utilizadas para la concurrencia.</p>
<p>Una de estas <em>primitivas de sincronización</em> es un mutex, abreviatura de exclusión mutua. Estas construcciones aseguran el acceso exclusivo a una variable, como nuestro contador. Un hilo puede intentar <em>bloquear</em> (o <em>adquirir</em>) el mutex, y o bien lo consigue inmediatamente, o se bloquea esperando a que se adquiera el bloqueo, o devuelve un error de que el mutex no se ha podido bloquear. Mientras ese hilo mantiene el bloqueo, se le concede acceso a los datos protegidos. Cuando el hilo termina, <em>desbloquea</em> (o <em>libera</em>) el mutex, permitiendo que otro hilo lo bloquee. En Rust, normalmente implementaríamos el desbloqueo usando el rasgo <a href="https://doc.rust-lang.org/core/ops/trait.Drop.html"><code>Drop</code></a> para asegurarnos de que siempre se libera cuando el mutex sale del ámbito.</p>
<p>Usar un mutex con manejadores de interrupciones puede ser complicado: normalmente no es aceptable que el manejador de interrupciones se bloquee, y sería especialmente desastroso que se bloqueara esperando a que el hilo principal liberara un bloqueo, ya que entonces nos <em>deadlock</em> (el hilo principal nunca liberará el bloqueo porque la ejecución permanece en el manejador de interrupciones). El deadlock no se considera inseguro: es posible incluso en Rust seguro.</p>
<p>Para evitar completamente este comportamiento, podríamos implementar un mutex que requiera una sección crítica para bloquearse, como en nuestro ejemplo del contador. Mientras la sección crítica dure lo mismo que el bloqueo, podemos estar seguros de que tenemos acceso exclusivo a la variable envuelta sin necesidad de seguir el estado de bloqueo/desbloqueo del mutex.</p>
<p>De hecho, ¡esto lo hace por nosotros la <em>crate</em> <code>cortex_m</code>! Podríamos haber escrito nuestro contador usándolo:</p>
<pre><code class="language-rust ignore">use core::cell::Cell;
use cortex_m::interrupt::Mutex;

static COUNTER: Mutex&lt;Cell&lt;u32&gt;&gt; = Mutex::new(Cell::new(0));

#[entry]
fn main() -&gt; ! {
    set_timer_1hz();
    let mut last_state = false;
    loop {
        let state = read_signal_level();
        if state &amp;&amp; !last_state {
            interrupt::free(|cs|
                COUNTER.borrow(cs).set(COUNTER.borrow(cs).get() + 1));
        }
        last_state = state;
    }
}

#[interrupt]
fn timer() {
    // We still need to enter a critical section here to satisfy the Mutex.
    interrupt::free(|cs| COUNTER.borrow(cs).set(0));
}</code></pre>
<p>Ahora estamos utilizando <a href="https://doc.rust-lang.org/core/cell/struct.Cell.html"><code>Cell</code></a>, que junto con su hermano <code>RefCell</code> se utiliza para proporcionar mutabilidad interior segura. Ya hemos visto <code>UnsafeCell</code> que es la capa inferior de mutabilidad interior en Rust: te permite obtener múltiples referencias mutables a su valor, pero sólo con código inseguro. Una <code>Cell</code> es como una <code>UnsafeCell</code> pero proporciona una interfaz segura: sólo permite tomar una copia del valor actual o reemplazarlo, no tomar una referencia, y como no es Sync, no puede ser compartida entre hilos. Estas restricciones hacen que su uso sea seguro, pero no podríamos usarlo directamente en una variable <code>static</code> ya que una <code>static</code> debe ser Sync.</p>
<p>¿Por qué funciona el ejemplo anterior? El <code>Mutex&lt;T&gt;</code> implementa Sync para cualquier <code>T</code> que sea Send - como una <code>Cell</code>. Puede hacer esto de forma segura porque sólo da acceso a su contenido durante una sección crítica. Por lo tanto, podemos obtener un contador seguro sin código inseguro.</p>
<p>Esto es genial para tipos simples como el <code>u32</code> de nuestro contador, pero ¿qué pasa con tipos más complejos que no son Copy? Un ejemplo extremadamente común en un contexto embebido es una estructura periférica, que generalmente no es Copy. Para eso, podemos recurrir a <code>RefCell</code>.</p>
<h2 id="compartiendo-periféricos"><a class="header" href="#compartiendo-periféricos">Compartiendo Periféricos</a></h2>
<p>Las <em>crates</em> de dispositivos generadas usando <code>svd2rust</code> y abstracciones similares proporcionan un acceso seguro a los periféricos al imponer que sólo una instancia de la estructura periférica puede existir a la vez. Esto garantiza la seguridad, pero dificulta el acceso a un periférico tanto desde el hilo principal como desde un manejador de interrupciones.</p>
<p>Para compartir de forma segura el acceso a los periféricos, podemos utilizar el <code>Mutex</code> que vimos antes. También necesitaremos usar <a href="https://doc.rust-lang.org/core/cell/struct.RefCell.html"><code>RefCell</code></a>, que utiliza una comprobación en tiempo de ejecución para asegurar que sólo se da una referencia a un periférico cada vez. Esto tiene más sobrecarga que el simple <code>Cell</code>, pero ya que estamos dando referencias en lugar de copias, debemos estar seguros de que sólo existe una a la vez.</p>
<p>Por último, también tendremos que tener en cuenta la forma de mover el periférico a la variable compartida después de que se haya inicializado en el código principal. Para ello podemos utilizar el tipo <code>Option</code>, inicializado a <code>None</code> y posteriormente establecido a la instancia del periférico.</p>
<pre><code class="language-rust ignore">use core::cell::RefCell;
use cortex_m::interrupt::{self, Mutex};
use stm32f4::stm32f405;

static MY_GPIO: Mutex&lt;RefCell&lt;Option&lt;stm32f405::GPIOA&gt;&gt;&gt; =
    Mutex::new(RefCell::new(None));

#[entry]
fn main() -&gt; ! {
    // Obtain the peripheral singletons and configure it.
    // This example is from an svd2rust-generated crate, but
    // most embedded device crates will be similar.
    let dp = stm32f405::Peripherals::take().unwrap();
    let gpioa = &amp;dp.GPIOA;

    // Some sort of configuration function.
    // Assume it sets PA0 to an input and PA1 to an output.
    configure_gpio(gpioa);

    // Store the GPIOA in the mutex, moving it.
    interrupt::free(|cs| MY_GPIO.borrow(cs).replace(Some(dp.GPIOA)));
    // We can no longer use `gpioa` or `dp.GPIOA`, and instead have to
    // access it via the mutex.

    // Be careful to enable the interrupt only after setting MY_GPIO:
    // otherwise the interrupt might fire while it still contains None,
    // and as-written (with `unwrap()`), it would panic.
    set_timer_1hz();
    let mut last_state = false;
    loop {
        // We'll now read state as a digital input, via the mutex
        let state = interrupt::free(|cs| {
            let gpioa = MY_GPIO.borrow(cs).borrow();
            gpioa.as_ref().unwrap().idr.read().idr0().bit_is_set()
        });

        if state &amp;&amp; !last_state {
            // Set PA1 high if we've seen a rising edge on PA0.
            interrupt::free(|cs| {
                let gpioa = MY_GPIO.borrow(cs).borrow();
                gpioa.as_ref().unwrap().odr.modify(|_, w| w.odr1().set_bit());
            });
        }
        last_state = state;
    }
}

#[interrupt]
fn timer() {
    // This time in the interrupt we'll just clear PA0.
    interrupt::free(|cs| {
        // We can use `unwrap()` because we know the interrupt wasn't enabled
        // until after MY_GPIO was set; otherwise we should handle the potential
        // for a None value.
        let gpioa = MY_GPIO.borrow(cs).borrow();
        gpioa.as_ref().unwrap().odr.modify(|_, w| w.odr1().clear_bit());
    });
}</code></pre>
<p>Es mucho para asimilar, así que vamos a desglosar las líneas importantes.</p>
<pre><code class="language-rust ignore">static MY_GPIO: Mutex&lt;RefCell&lt;Option&lt;stm32f405::GPIOA&gt;&gt;&gt; =
    Mutex::new(RefCell::new(None));</code></pre>
<p>Nuestra variable compartida es ahora un <code>Mutex</code> alrededor de una <code>RefCell</code> que contiene una <code>Option</code>. El <code>Mutex</code> asegura que sólo tenemos acceso durante una sección crítica, y por lo tanto hace que la variable sea Sync, a pesar de que una <code>RefCell</code> normal no sería Sync. La <code>RefCell</code> nos da mutabilidad interior con referencias, que necesitaremos para usar nuestro <code>GPIOA</code>. La <code>Option</code> nos permite inicializar esta variable a algo vacío, y sólo después realmente mover la variable. No podemos acceder al singleton periférico estáticamente, sólo en tiempo de ejecución, así que esto es necesario.</p>
<pre><code class="language-rust ignore">interrupt::free(|cs| MY_GPIO.borrow(cs).replace(Some(dp.GPIOA)));</code></pre>
<p>Dentro de una sección crítica podemos llamar a <code>borrow()</code> en el mutex, que nos da una referencia a la <code>RefCell</code>. Luego llamamos a <code>replace()</code> para mover nuestro nuevo valor a la <code>RefCell</code>.</p>
<pre><code class="language-rust ignore">interrupt::free(|cs| {
    let gpioa = MY_GPIO.borrow(cs).borrow();
    gpioa.as_ref().unwrap().odr.modify(|_, w| w.odr1().set_bit());
});</code></pre>
<p>Por último, utilizamos <code>MY_GPIO</code> de forma segura y concurrente. La sección crítica evita que la interrupción se dispare como de costumbre, y nos permite tomar prestado el mutex. La <code>RefCell</code> nos da una <code>&amp;Option&lt;GPIOA&gt;</code>, y controla cuánto tiempo permanece prestada - una vez que la referencia sale del ámbito, la <code>RefCell</code> se actualiza para indicar que ya no está prestada.</p>
<p>Como no podemos mover el <code>GPIOA</code> fuera de <code>&amp;Option</code>, tenemos que convertirlo en un <code>&amp;Option&lt;&amp;GPIOA&gt;</code> con <code>as_ref()</code>, que finalmente podemos <code>unwrap()</code> para obtener el <code>&amp;GPIOA</code> que nos permite modificar el periférico.</p>
<p>Si necesitamos una referencia mutable a un recurso compartido, entonces debemos usar <code>borrow_mut</code> y <code>deref_mut</code> en su lugar. El siguiente código muestra un ejemplo utilizando el temporizador TIM2.</p>
<pre><code class="language-rust ignore">use core::cell::RefCell;
use core::ops::DerefMut;
use cortex_m::interrupt::{self, Mutex};
use cortex_m::asm::wfi;
use stm32f4::stm32f405;

static G_TIM: Mutex&lt;RefCell&lt;Option&lt;Timer&lt;stm32::TIM2&gt;&gt;&gt;&gt; =
	Mutex::new(RefCell::new(None));

#[entry]
fn main() -&gt; ! {
    let mut cp = cm::Peripherals::take().unwrap();
    let dp = stm32f405::Peripherals::take().unwrap();

    // Some sort of timer configuration function.
    // Assume it configures the TIM2 timer, its NVIC interrupt,
    // and finally starts the timer.
    let tim = configure_timer_interrupt(&amp;mut cp, dp);

    interrupt::free(|cs| {
        G_TIM.borrow(cs).replace(Some(tim));
    });

    loop {
        wfi();
    }
}

#[interrupt]
fn timer() {
    interrupt::free(|cs| {
        if let Some(ref mut tim)) =  G_TIM.borrow(cs).borrow_mut().deref_mut() {
            tim.start(1.hz());
        }
    });
}
</code></pre>
<p>¡Uf! Esto es seguro, pero también es un poco difícil de manejar. ¿Hay algo más que podamos hacer?</p>
<h2 id="rtic"><a class="header" href="#rtic">RTIC</a></h2>
<p>Una alternativa es el <a href="https://github.com/rtic-rs/cortex-m-rtic">RTIC framework</a>, abreviatura de Real Time Interrupt-driven Concurrency. Refuerza las prioridades estáticas y rastrea los accesos a variables <code>static mut</code> (&quot;recursos&quot;) para asegurar estáticamente que siempre se accede a los recursos compartidos de forma segura, sin requerir la sobrecarga de entrar siempre en secciones críticas y usar el conteo de referencias (como en <code>RefCell</code>). Esto tiene una serie de ventajas, como garantizar que no se produzcan bloqueos y ofrecer una sobrecarga de tiempo y memoria extremadamente baja.</p>
<p>El marco también incluye otras características como el paso de mensajes, que reduce la necesidad de un estado compartido explícito, y la capacidad de programar tareas para que se ejecuten en un momento dado, lo que puede utilizarse para implementar tareas periódicas. Consulta <a href="https://rtic.rs">la documentación</a> para obtener más información.</p>
<h2 id="sistemas-operativos-en-tiempo-real"><a class="header" href="#sistemas-operativos-en-tiempo-real">Sistemas operativos en tiempo real</a></h2>
<p>Otro modelo común para la concurrencia embebida es el sistema operativo en tiempo real (RTOS). Aunque actualmente están menos explorados en Rust, son ampliamente utilizados en el desarrollo embebido tradicional. Ejemplos de código abierto incluyen <a href="https://freertos.org/">FreeRTOS</a> y <a href="http://chibios.org/">ChibiOS</a>. Estos RTOSs proporcionan soporte para ejecutar múltiples hilos de aplicación que la CPU intercambia, ya sea cuando los hilos ceden el control (llamado multitarea cooperativa) o basado en un temporizador regular o interrupciones (multitarea preventiva). Los RTOS suelen proporcionar mutexes y otras primitivas de sincronización, y a menudo interoperan con funciones de hardware como los motores DMA.</p>
<p>En el momento de escribir esto, no hay muchos ejemplos de Rust RTOS a los que apuntar, pero es un área interesante así que ¡mira este espacio!</p>
<h2 id="múltiples-núcleos"><a class="header" href="#múltiples-núcleos">Múltiples núcleos</a></h2>
<p>Cada vez es más común tener dos o más núcleos en procesadores embebidos, lo que añade una capa extra de complejidad a la concurrencia. Todos los ejemplos que utilizan una sección crítica (incluyendo el <code>cortex_m::interrupt::Mutex</code>) asumen que el único otro hilo de ejecución es el hilo de interrupción, pero en un sistema multinúcleo eso ya no es cierto. En su lugar, necesitaremos primitivas de sincronización diseñadas para múltiples núcleos (también llamadas SMP, por multiprocesamiento simétrico).</p>
<p>Éstas suelen utilizar las instrucciones atómicas que hemos visto antes, ya que el sistema de procesamiento garantizará que la atomicidad se mantenga en todos los núcleos.</p>
<p>Cubrir estos temas en detalle está actualmente fuera del alcance de este libro, pero los patrones generales son los mismos que para el caso de un solo núcleo.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="colecciones"><a class="header" href="#colecciones">Colecciones</a></h1>
<p>Eventualmente querrás usar estructuras de datos dinámicas (también conocidas como colecciones) en tu programa. <code>std</code> proporciona un conjunto de colecciones comunes: <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html"><code>Vec</code></a>, <a href="https://doc.rust-lang.org/std/string/struct.String.html"><code>String</code></a>, <a href="https://doc.rust-lang.org/std/collections/struct.HashMap.html"><code>HashMap</code></a>, etc. Todas las colecciones implementadas en <code>std</code> utilizan un asignador global de memoria dinámica (también conocido como heap).</p>
<p>Como <code>core</code> está, por definición, libre de asignaciones de memoria, estas implementaciones no están disponibles allí, pero se pueden encontrar en la <em>crate</em> <code>alloc</code> que viene con el compilador.</p>
<p>Si necesitas colecciones, una implementación asignada a heap no es tu única opción. También puedes usar colecciones de <em>capacidad fija</em>; una de estas implementaciones se encuentra en la <em>crate</em> <a href="https://crates.io/crates/heapless"><code>heapless</code></a>.</p>
<p>En esta sección, exploraremos y compararemos estas dos implementaciones.</p>
<h2 id="usando-alloc"><a class="header" href="#usando-alloc">Usando <code>alloc</code></a></h2>
<p>La <em>crate</em> <code>alloc</code> viene con la distribución estándar de Rust. Para importar la <em>crate</em> puedes <code>usarla</code> directamente <em>sin</em> declararla como dependencia en tu archivo <code>Cargo.toml</code>.</p>
<pre><code class="language-rust ignore">#![feature(alloc)]

extern crate alloc;

use alloc::vec::Vec;</code></pre>
<p>Para poder utilizar cualquier colección primero tendrás que utilizar el atributo <code>global_allocator</code> para declarar el asignador global que utilizará tu programa. Es necesario que el asignador que selecciones implemente el <em>trait</em> <a href="https://doc.rust-lang.org/core/alloc/trait.GlobalAlloc.html"><code>GlobalAlloc</code></a>.</p>
<p>Para completar y mantener esta sección lo más autocontenida posible, implementaremos un simple asignador de punteros y lo usaremos como asignador global. Sin embargo, te sugerimos encarecidamente que utilices un asignador probado en batalla que esté en crates.io en tu programa en lugar de este asignador.</p>
<pre><code class="language-rust ignore">// Bump pointer allocator implementation

use core::alloc::{GlobalAlloc, Layout};
use core::cell::UnsafeCell;
use core::ptr;

use cortex_m::interrupt;

// Bump pointer allocator for *single* core systems
struct BumpPointerAlloc {
    head: UnsafeCell&lt;usize&gt;,
    end: usize,
}

unsafe impl Sync for BumpPointerAlloc {}

unsafe impl GlobalAlloc for BumpPointerAlloc {
    unsafe fn alloc(&amp;self, layout: Layout) -&gt; *mut u8 {
        // `interrupt::free` is a critical section that makes our allocator safe
        // to use from within interrupts
        interrupt::free(|_| {
            let head = self.head.get();
            let size = layout.size();
            let align = layout.align();
            let align_mask = !(align - 1);

            // move start up to the next alignment boundary
            let start = (*head + align - 1) &amp; align_mask;

            if start + size &gt; self.end {
                // a null pointer signal an Out Of Memory condition
                ptr::null_mut()
            } else {
                *head = start + size;
                start as *mut u8
            }
        })
    }

    unsafe fn dealloc(&amp;self, _: *mut u8, _: Layout) {
        // this allocator never deallocates memory
    }
}

// Declaration of the global memory allocator
// NOTE the user must ensure that the memory region `[0x2000_0100, 0x2000_0200]`
// is not used by other parts of the program
#[global_allocator]
static HEAP: BumpPointerAlloc = BumpPointerAlloc {
    head: UnsafeCell::new(0x2000_0100),
    end: 0x2000_0200,
};</code></pre>
<p>Además de seleccionar un asignador global, el usuario también tendrá que definir cómo se gestionan los errores de falta de memoria (OOM) usando el atributo <em>unstable</em> <code>alloc_error_handler</code>.</p>
<pre><code class="language-rust ignore">#![feature(alloc_error_handler)]

use cortex_m::asm;

#[alloc_error_handler]
fn on_oom(_layout: Layout) -&gt; ! {
    asm::bkpt();

    loop {}
}</code></pre>
<p>Una vez que todo esto está en su lugar, el usuario puede finalmente utilizar las colecciones en <code>alloc</code>.</p>
<pre><code class="language-rust ignore">#[entry]
fn main() -&gt; ! {
    let mut xs = Vec::new();

    xs.push(42);
    assert!(xs.pop(), Some(42));

    loop {
        // ..
    }
}</code></pre>
<p>Si has usado las colecciones en la <em>crate</em> <code>std</code> entonces estas te serán familiares ya que son exactamente la misma implementación.</p>
<h2 id="usando-heapless"><a class="header" href="#usando-heapless">Usando <code>heapless</code></a></h2>
<p><code>heapless</code> no requiere configuración ya que sus colecciones no dependen de un asignador de memoria global. Simplemente <code>use</code> sus colecciones y procede a instanciarlas:</p>
<pre><code class="language-rust ignore">// heapless version: v0.4.x
use heapless::Vec;
use heapless::consts::*;

#[entry]
fn main() -&gt; ! {
    let mut xs: Vec&lt;_, U8&gt; = Vec::new();

    xs.push(42).unwrap();
    assert_eq!(xs.pop(), Some(42));
    loop {}
}</code></pre>
<p>Notarás dos diferencias entre estas colecciones y las de <code>alloc</code>.</p>
<p>Primero, tienes que declarar por adelantado la capacidad de la colección. Las colecciones <code>heapless</code> nunca se reasignan y tienen capacidades fijas; esta capacidad forma parte de la firma de tipo de la colección. En este caso hemos declarado que <code>xs</code> tiene una capacidad de 8 elementos, es decir, que el vector puede contener, como máximo, 8 elementos. Esto se indica mediante la <code>U8</code> (véase <a href="https://crates.io/crates/typenum"><code>typenum</code></a>) en la firma de tipo.</p>
<p>En segundo lugar, el método <code>push</code>, y muchos otros métodos, devuelven un <code>Result</code>. Dado que las colecciones <code>heapless</code> tienen una capacidad fija, todas las operaciones que insertan elementos en la colección pueden fallar potencialmente. La API refleja este problema devolviendo un <code>Result</code> que indica si la operación ha tenido éxito o no. Por el contrario, las colecciones <code>alloc</code> se reasignan a sí mismas en el heap para aumentar su capacidad.</p>
<p>A partir de la versión v0.4.x todas las colecciones <code>heapless</code> almacenan todos sus elementos en línea. Esto significa que una operación como <code>let x = heapless::Vec::new();</code> asignará la colección en la pila, pero también es posible asignar la colección en una variable <code>static</code>, o incluso en el montón (<code>Box&lt;Vec&lt;_, _&gt;&gt;</code>).</p>
<h2 id="ventajas-y-desventajas"><a class="header" href="#ventajas-y-desventajas">Ventajas y desventajas</a></h2>
<p>Ten en cuenta lo siguiente a la hora de elegir entre colecciones reubicables asignadas al heap y colecciones de capacidad fija.</p>
<h3 id="out-of-memory-y-gestión-de-errores"><a class="header" href="#out-of-memory-y-gestión-de-errores">Out Of Memory y gestión de errores</a></h3>
<p>Con las asignaciones de heap, el Out Of Memory es siempre una posibilidad y puede ocurrir en cualquier lugar donde una colección pueda necesitar crecer: por ejemplo, todas las invocaciones <code>alloc::Vec.push</code> pueden potencialmente generar una condición OOM. Por tanto, algunas operaciones pueden fallar <em>implícitamente</em>. Algunas colecciones <code>alloc</code> exponen métodos <code>try_reserve</code> que te permiten comprobar posibles condiciones OOM al hacer crecer la colección, pero debes ser proactivo a la hora de utilizarlos.</p>
<p>Si usas exclusivamente colecciones <code>heapless</code> y no usas un asignador de memoria para nada más, entonces una condición OOM es imposible. En su lugar, tendrás que lidiar con las colecciones que se queden sin capacidad caso por caso. Es decir, tendrás que lidiar con <em>todos</em> los <code>Result</code> devueltos por métodos como <code>Vec.push</code>.</p>
<p>Los fallos OOM pueden ser más difíciles de depurar que, por ejemplo, <code>unwrap</code> todos los <code>Result</code> devueltos por <code>heapless::Vec.push</code> porque la localización observada del fallo puede <em>no</em> coincidir con la localización de la causa del problema. Por ejemplo, incluso <code>vec.reserve(1)</code> puede desencadenar un OOM si el asignador está casi agotado porque alguna otra colección estaba perdiendo memoria (las fugas de memoria son posibles en Rust seguro).</p>
<h3 id="uso-de-memoria"><a class="header" href="#uso-de-memoria">Uso de memoria</a></h3>
<p>Razonar sobre el uso de memoria de las colecciones asignadas al heap es difícil porque la capacidad de las colecciones de larga duración puede cambiar en tiempo de ejecución. Algunas operaciones pueden implícitamente reasignar la colección incrementando su uso de memoria, y algunas colecciones exponen métodos como <code>shrink_to_fit</code> que pueden potencialmente reducir la memoria usada por la colección -- en última instancia, depende del asignador decidir si realmente reduce la asignación de memoria o no. Además, el asignador puede tener que lidiar con la fragmentación de la memoria, lo que puede aumentar el uso de memoria <em>aparente</em>.</p>
<p>Por otro lado, si utilizas exclusivamente colecciones de capacidad fija, almacenas la mayoría de ellas en variables <code>static</code> y estableces un tamaño máximo para la pila de llamadas, el enlazador detectará si intentas utilizar más memoria de la que está físicamente disponible.</p>
<p>Además, las colecciones de capacidad fija asignadas en la pila serán reportadas por la bandera <a href="https://doc.rust-lang.org/beta/unstable-book/compiler-flags/emit-stack-sizes.html"><code>-Z emit-stack-sizes</code></a> lo que significa que las herramientas que analizan el uso de la pila (como <a href="https://crates.io/crates/stack-sizes"><code>stack-sizes</code></a>) las incluirán en su análisis.</p>
<p>Sin embargo, las colecciones de capacidad fija <em>no</em> pueden reducirse, lo que puede dar lugar a factores de carga (la relación entre el tamaño de la colección y su capacidad) inferiores a los que pueden conseguir las colecciones reubicables.</p>
<h3 id="tiempo-de-ejecución-en-el-peor-de-los-casos-wcet"><a class="header" href="#tiempo-de-ejecución-en-el-peor-de-los-casos-wcet">Tiempo de ejecución en el peor de los casos (WCET)</a></h3>
<p>Si estás construyendo aplicaciones sensibles al tiempo o aplicaciones de tiempo real duro, entonces te preocupas, quizás mucho, por el tiempo de ejecución en el peor de los casos de las diferentes partes de tu programa. Las colecciones <code>alloc</code> pueden reasignarse, por lo que el WCET de las operaciones que pueden hacer crecer la colección también incluirá el tiempo que se tarda en reasignar la colección, que a su vez depende de la capacidad <em>runtime</em> de la colección. Esto dificulta la determinación del WCET de, por ejemplo, la operación <code>alloc::Vec.push</code>, ya que depende tanto del asignador utilizado como de su capacidad en tiempo de ejecución.</p>
<p>Por otro lado, las colecciones de capacidad fija nunca se reasignan, por lo que todas las operaciones tienen un tiempo de ejecución predecible. Por ejemplo, <code>heapless::Vec.push</code> se ejecuta en tiempo constante.</p>
<h3 id="facilidad-de-uso"><a class="header" href="#facilidad-de-uso">Facilidad de uso</a></h3>
<p><code>alloc</code> requiere configurar un asignador global mientras que <code>heapless</code> no. Sin embargo, <code>heapless</code> requiere que elijas la capacidad de cada colección que instales.</p>
<p>La API <code>alloc</code> será familiar para prácticamente todos los desarrolladores de Rust. La API <code>heapless</code> intenta imitar de cerca la API <code>alloc</code> pero nunca será exactamente igual debido a su gestión explícita de errores -- algunos desarrolladores pueden sentir que la gestión explícita de errores es excesiva o demasiado engorrosa.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="patrones-de-diseño"><a class="header" href="#patrones-de-diseño">Patrones de Diseño</a></h1>
<p>Este capítulo tiene como objetivo recopilar varios patrones de diseño útiles para Rust embebido.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="patrones-de-diseño-hal"><a class="header" href="#patrones-de-diseño-hal">Patrones de Diseño HAL</a></h1>
<p>Este es un conjunto de patrones comunes y recomendados para escribir capas de abstracción de hardware (HALs) para microcontroladores en Rust. Estos patrones están pensados para ser usados además de las <a href="https://rust-lang.github.io/api-guidelines/">Orientaciones Rust API</a> existentes cuando se escriben HALs para microcontroladores.</p>
<p><a href="design-patterns/hal/checklist.html">Lista de comprobación</a></p>
<ul>
<li><a href="design-patterns/hal/naming.html">Nomenclatura</a></li>
<li><a href="design-patterns/hal/interoperability.html">Interoperabilidad</a></li>
<li><a href="design-patterns/hal/predictability.html">Previsibilidad</a></li>
<li><a href="design-patterns/hal/gpio.html">GPIO</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lista-de-chequeo-de-patrones-de-diseño-hal"><a class="header" href="#lista-de-chequeo-de-patrones-de-diseño-hal">Lista de chequeo de Patrones de Diseño HAL</a></h1>
<ul>
<li><strong>Nomenclatura</strong> <em>(la <strong>crate</strong> se alinea con las convenciones de nomenclatura de Rust)</em>
<ul>
<li><input disabled="" type="checkbox"/>
La <em>crate</em> tiene el nombre apropiado (<a href="design-patterns/hal/naming.html#c-crate-name">C-CRATE-NAME</a>)</li>
</ul>
</li>
<li><strong>Interoperabilidad</strong> <em>( la <strong>crate</strong> interactúa bien con otras funcionalidades de la librería)</em>
<ul>
<li><input disabled="" type="checkbox"/>
Los tipos Wrapper proporcionan un método destructor (<a href="design-patterns/hal/interoperability.html#c-free">C-FREE</a>)</li>
<li><input disabled="" type="checkbox"/>
Las HAL reexportan su <em>crate</em> de acceso a registros (<a href="design-patterns/hal/interoperabilidad.html#c-reexport-pac">C-REEXPORT-PAC</a>)</li>
<li><input disabled="" type="checkbox"/>
Los tipos implementan los <em>traits</em> <code>embedded-hal</code> (<a href="design-patterns/hal/interoperabilidad.html#c-hal-traits">C-HAL-TRAITS</a>)</li>
</ul>
</li>
<li><strong>Predictibilidad</strong> <em>(<strong>crate</strong> permite código legible que actúa como parece)</em>
<ul>
<li><input disabled="" type="checkbox"/>
Se utilizan constructores en lugar de <em>traits</em> de extensión (<a href="design-patterns/hal/predictability.html#c-ctor">C-CTOR</a>)</li>
</ul>
</li>
<li><strong>Interfaces GPIO</strong> <em>(Las Interfaces GPIO siguen un patrón común)</em>
<ul>
<li><input disabled="" type="checkbox"/>
Los tipos de pin son de tamaño cero por defecto (<a href="design-patterns/hal/gpio.html#c-zst-pin">C-ZST-PIN</a>)</li>
<li><input disabled="" type="checkbox"/>
Los tipos de pin proporcionan métodos para borrar el pin y el puerto (<a href="design-patterns/hal/gpio.html#c-erased-pin">C-ERASED-PIN</a>)</li>
<li><input disabled="" type="checkbox"/>
El estado de las pines debe codificarse como parámetros de tipo (<a href="design-patterns/hal/gpio.html#c-pin-state">C-PIN-STATE</a>)</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="nomenclatura"><a class="header" href="#nomenclatura">Nomenclatura</a></h1>
<p><a id="c-crate-name"></a></p>
<h2 id="la-crate-recibe-el-nombre-apropiado-c-crate-name"><a class="header" href="#la-crate-recibe-el-nombre-apropiado-c-crate-name">La <em>crate</em> recibe el nombre apropiado (C-CRATE-NAME)</a></h2>
<p>Las <em>crates</em> HAL deberían llamarse como el chip o familia de chips que desean soportar. Su nombre debe terminar con <code>-hal</code> para distinguirlos de las <em>crates</em> de acceso a registros. El nombre no debe contener guiones bajos (utilice guiones en su lugar).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="interoperabilidad"><a class="header" href="#interoperabilidad">Interoperabilidad</a></h1>
<p><a id="c-free"></a></p>
<h2 id="los-tipos-wrapper-proporcionan-un-método-destructor-c-free"><a class="header" href="#los-tipos-wrapper-proporcionan-un-método-destructor-c-free">Los tipos Wrapper proporcionan un método destructor (C-FREE)</a></h2>
<p>Cualquier tipo de wrapper que no sea <code>Copy</code> proporcionado por la HAL debería proporcionar un método <code>free</code> que consuma el wrapper y devuelva el periférico en bruto (y posiblemente otros objetos) a partir del cual fue creado.</p>
<p>El método debe apagar y reiniciar el periférico si es necesario. Llamar a <code>new</code> con el periférico devuelto por <code>free</code> no debería fallar debido a un estado inesperado del periférico.</p>
<p>Si el tipo de HAL requiere que se construyan otros objetos que no sean <code>Copy</code> (por ejemplo pines de E/S), cualquier objeto de este tipo debería ser liberado y devuelto por <code>free</code> también. En ese caso, <code>free</code> debería devolver una tupla.</p>
<p>Por ejemplo:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">pub struct TIMER0;
</span>pub struct Timer(TIMER0);

impl Timer {
    pub fn new(periph: TIMER0) -&gt; Self {
        Self(periph)
    }

    pub fn free(self) -&gt; TIMER0 {
        self.0
    }
}
<span class="boring">}</span></code></pre></pre>
<p><a id="c-reexport-pac"></a></p>
<h2 id="hals-reexportan-su-crate-de-acceso-a-registros-c-reexport-pac"><a class="header" href="#hals-reexportan-su-crate-de-acceso-a-registros-c-reexport-pac">HALs reexportan su <em>crate</em> de acceso a registros (C-REEXPORT-PAC)</a></h2>
<p>Las HALs pueden ser escritas sobre PACs generados por <a href="https://github.com/rust-embedded/svd2rust">svd2rust</a>, o sobre otras <em>crates</em> que proveen acceso a registros sin procesar. Las HALs siempre deben reexportar la <em>crate</em> de acceso a registros en el que se basan en su <em>crate</em> raíz.</p>
<p>Un PAC debe ser reexportado bajo el nombre <code>pac</code>, independientemente del nombre real de la <em>crate</em>, como el nombre de la HAL ya debe dejar claro qué PAC se está accediendo.</p>
<p><a id="c-hal-traits"></a></p>
<h2 id="los-tipos-implementan-los-rasgos-embedded-hal-c-hal-traits"><a class="header" href="#los-tipos-implementan-los-rasgos-embedded-hal-c-hal-traits">Los tipos implementan los rasgos <code>embedded-hal</code> (C-HAL-TRAITS)</a></h2>
<p>Los tipos proporcionados por la HAL deben implementar todos los rasgos aplicables proporcionados por la <em>crate</em> <a href="https://github.com/rust-embedded/embedded-hal"><code>embedded-hal</code></a>.</p>
<p>Pueden implementarse múltiples rasgos para el mismo tipo.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="predictibilidad"><a class="header" href="#predictibilidad">Predictibilidad</a></h1>
<p><a id="c-ctor"></a></p>
<h2 id="se-utilizan-constructores-en-lugar-de-traits-de-extensión-c-ctor"><a class="header" href="#se-utilizan-constructores-en-lugar-de-traits-de-extensión-c-ctor">Se utilizan constructores en lugar de <em>traits</em> de extensión (C-CTOR)</a></h2>
<p>Todos los periféricos a los que la HAL añade funcionalidad deben envolverse en un nuevo tipo, incluso si no se requieren campos adicionales para esa funcionalidad.</p>
<p>Deben evitarse los <em>traits</em> de extensión implementados para el periférico directamente.</p>
<p><a id="c-inline"></a></p>
<h2 id="los-métodos-están-decorados-con-inline-cuando-es-apropiado-c-inline"><a class="header" href="#los-métodos-están-decorados-con-inline-cuando-es-apropiado-c-inline">Los métodos están decorados con <code>#[inline]</code> cuando es apropiado (C-INLINE)</a></h2>
<p>El compilador de Rust no realiza por defecto inlining completo a través de los límites de las <em>crates</em>. Como las aplicaciones embebidas son sensibles a aumentos inesperados del tamaño del código, <code>#[inline]</code> debería ser usado para guiar al compilador de la siguiente manera:</p>
<ul>
<li>Todas las funciones &quot;pequeñas&quot; deben marcarse como <code>#[inline]</code>. Lo que se califica como &quot;pequeño&quot; es subjetivo, pero generalmente todas las funciones que se espera que compilen en secuencias de instrucciones de un solo dígito se califican como pequeñas.</li>
<li>Las funciones que es muy probable que tomen valores constantes como parámetros deben marcarse como <code>#[inline]</code>. Esto permite al compilador calcular incluso la complicada lógica de inicialización en tiempo de compilación, siempre que se conozcan las entradas de la función.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="recomendaciones-para-interfaces-gpio"><a class="header" href="#recomendaciones-para-interfaces-gpio">Recomendaciones para interfaces GPIO</a></h1>
<p><a id="c-zst-pin"></a></p>
<h2 id="los-tipos-de-pin-son-de-tamaño-cero-por-defecto-c-zst-pin"><a class="header" href="#los-tipos-de-pin-son-de-tamaño-cero-por-defecto-c-zst-pin">Los tipos de pin son de tamaño cero por defecto (C-ZST-PIN)</a></h2>
<p>Las Interfaces GPIO expuestas por la HAL deberían proporcionar tipos dedicados de tamaño cero para cada pin en cada interfaz o puerto, resultando en una abstracción GPIO de costo cero cuando todas las asignaciones de pines son conocidas estáticamente.</p>
<p>Cada interfaz o puerto GPIO debe implementar un método <code>split</code> que devuelva una estructura con cada pin.</p>
<p>Ejemplo:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct PA0;
pub struct PA1;
// ...

pub struct PortA;

impl PortA {
    pub fn split(self) -&gt; PortAPins {
        PortAPins {
            pa0: PA0,
            pa1: PA1,
            // ...
        }
    }
}

pub struct PortAPins {
    pub pa0: PA0,
    pub pa1: PA1,
    // ...
}
<span class="boring">}</span></code></pre></pre>
<p><a id="c-erased-pin"></a></p>
<h2 id="los-tipos-de-pines-proporcionan-métodos-para-borrar-pines-y-puertos-c-erased-pin"><a class="header" href="#los-tipos-de-pines-proporcionan-métodos-para-borrar-pines-y-puertos-c-erased-pin">Los tipos de pines proporcionan métodos para borrar pines y puertos (C-ERASED-PIN)</a></h2>
<p>Los pines deben proporcionar métodos de borrado de tipos que trasladen sus propiedades de tiempo de compilación a tiempo de ejecución, y permitan una mayor flexibilidad en las aplicaciones.</p>
<p>Ejemplo:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Port A, pin 0.
pub struct PA0;

impl PA0 {
    pub fn erase_pin(self) -&gt; PA {
        PA { pin: 0 }
    }
}

/// A pin on port A.
pub struct PA {
    /// The pin number.
    pin: u8,
}

impl PA {
    pub fn erase_port(self) -&gt; Pin {
        Pin {
            port: Port::A,
            pin: self.pin,
        }
    }
}

pub struct Pin {
    port: Port,
    pin: u8,
    // (these fields can be packed to reduce the memory footprint)
}

enum Port {
    A,
    B,
    C,
    D,
}
<span class="boring">}</span></code></pre></pre>
<p><a id="c-pin-state"></a></p>
<h2 id="el-estado-de-los-pines-debería-codificarse-como-parámetros-de-tipo-c-pin-state"><a class="header" href="#el-estado-de-los-pines-debería-codificarse-como-parámetros-de-tipo-c-pin-state">El estado de los pines debería codificarse como parámetros de tipo (C-PIN-STATE)</a></h2>
<p>Los pines pueden configurarse como entrada o salida con diferentes características dependiendo del chip o familia. Este estado debe codificarse en el sistema de tipos para evitar el uso de pines en estados incorrectos.</p>
<p>Los estados adicionales específicos de cada chip (por ejemplo, la intensidad de accionamiento) también pueden codificarse de este modo, utilizando parámetros de tipo adicionales.</p>
<p>Los métodos para cambiar el estado del pin deben proporcionarse como métodos <code>into_input</code> y <code>into_output</code>.</p>
<p>Además, se deben proporcionar métodos <code>with_{input,output}_state</code> que reconfiguren temporalmente un pin en un estado diferente sin moverlo.</p>
<p>Se deben proporcionar los siguientes métodos para cada tipo de pin (es decir, tanto los tipos de pin borrados como los no borrados deben proporcionar la misma API):</p>
<ul>
<li><code>pub fn into_input&lt;N: InputState&gt;(self, input: N) -&gt; Pin&lt;N&gt;</code></li>
<li><code>pub fn into_output&lt;N: OutputState&gt;(self, output: N) -&gt; Pin&lt;N&gt;</code></li>
<li>
<pre><code class="language-ignore">pub fn with_input_state&lt;N: InputState, R&gt;(
    &amp;mut self,
    input: N,
    f: impl FnOnce(&amp;mut PA1&lt;N&gt;) -&gt; R,
) -&gt; R
</code></pre>
</li>
<li>
<pre><code class="language-ignore">pub fn with_output_state&lt;N: OutputState, R&gt;(
    &amp;mut self,
    output: N,
    f: impl FnOnce(&amp;mut PA1&lt;N&gt;) -&gt; R,
) -&gt; R
</code></pre>
</li>
</ul>
<p>El estado de los pines debe estar limitado por <em>traits</em> sellados. Los usuarios de la HAL no deberían tener necesidad de añadir su propio estado. Los <em>traits</em> pueden proporcionar métodos específicos de la HAL necesarios para implementar la API de estado de los pines.</p>
<p>Ejemplo:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span><span class="boring">use std::marker::PhantomData;
</span>mod sealed {
    pub trait Sealed {}
}

pub trait PinState: sealed::Sealed {}
pub trait OutputState: sealed::Sealed {}
pub trait InputState: sealed::Sealed {
    // ...
}

pub struct Output&lt;S: OutputState&gt; {
    _p: PhantomData&lt;S&gt;,
}

impl&lt;S: OutputState&gt; PinState for Output&lt;S&gt; {}
impl&lt;S: OutputState&gt; sealed::Sealed for Output&lt;S&gt; {}

pub struct PushPull;
pub struct OpenDrain;

impl OutputState for PushPull {}
impl OutputState for OpenDrain {}
impl sealed::Sealed for PushPull {}
impl sealed::Sealed for OpenDrain {}

pub struct Input&lt;S: InputState&gt; {
    _p: PhantomData&lt;S&gt;,
}

impl&lt;S: InputState&gt; PinState for Input&lt;S&gt; {}
impl&lt;S: InputState&gt; sealed::Sealed for Input&lt;S&gt; {}

pub struct Floating;
pub struct PullUp;
pub struct PullDown;

impl InputState for Floating {}
impl InputState for PullUp {}
impl InputState for PullDown {}
impl sealed::Sealed for Floating {}
impl sealed::Sealed for PullUp {}
impl sealed::Sealed for PullDown {}

pub struct PA1&lt;S: PinState&gt; {
    _p: PhantomData&lt;S&gt;,
}

impl&lt;S: PinState&gt; PA1&lt;S&gt; {
    pub fn into_input&lt;N: InputState&gt;(self, input: N) -&gt; PA1&lt;Input&lt;N&gt;&gt; {
        todo!()
    }

    pub fn into_output&lt;N: OutputState&gt;(self, output: N) -&gt; PA1&lt;Output&lt;N&gt;&gt; {
        todo!()
    }

    pub fn with_input_state&lt;N: InputState, R&gt;(
        &amp;mut self,
        input: N,
        f: impl FnOnce(&amp;mut PA1&lt;N&gt;) -&gt; R,
    ) -&gt; R {
        todo!()
    }

    pub fn with_output_state&lt;N: OutputState, R&gt;(
        &amp;mut self,
        output: N,
        f: impl FnOnce(&amp;mut PA1&lt;N&gt;) -&gt; R,
    ) -&gt; R {
        todo!()
    }
}

// Same for `PA` and `Pin`, and other pin types.
<span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="consejos-para-desarrolladores-de-c-embebido"><a class="header" href="#consejos-para-desarrolladores-de-c-embebido">Consejos para desarrolladores de C embebido</a></h1>
<p>Este capítulo recoge una serie de consejos que pueden ser útiles para desarrolladores experimentados en C embebido que quieran empezar a escribir Rust. Destacará especialmente cómo las cosas a las que ya podrías estar acostumbrado en C son diferentes en Rust.</p>
<h2 id="preprocesador"><a class="header" href="#preprocesador">Preprocesador</a></h2>
<p>En C embebido es muy común usar el preprocesador para una variedad de propósitos, tales como:</p>
<ul>
<li>Selección en tiempo de compilación de bloques de código con <code>#ifdef</code>.</li>
<li>Cálculos y tamaños de matrices en tiempo de compilación</li>
<li>Macros para simplificar patrones comunes (para evitar el costo de las llamadas a funciones)</li>
</ul>
<p>En Rust no hay preprocesador, por lo que muchos de estos casos de uso se abordan de manera diferente. En el resto de esta sección cubrimos varias alternativas al uso del preprocesador.</p>
<h3 id="selección-de-código-en-tiempo-de-compilación"><a class="header" href="#selección-de-código-en-tiempo-de-compilación">Selección de Código en Tiempo de Compilación</a></h3>
<p>Lo más parecido a <code>#ifdef ... #endif</code> en Rust son las <a href="https://doc.rust-lang.org/cargo/reference/manifest.html#the-features-section">prestaciones de Cargo</a>. Éstas son un poco más formales que el preprocesador de C: todas las prestaciones posibles se listan explícitamente por <em>crate</em>, y sólo pueden estar activadas o desactivadas. Las prestaciones se activan cuando listas una <em>crate</em> como dependencia, y son aditivas: si cualquier <em>crate</em> en tu árbol de dependencias activa una prestación para otra <em>crate</em>, esa prestación se activará para todos los usuarios de esa <em>crate</em>.</p>
<p>Por ejemplo, puedes tener una <em>crate</em> que proporcione una biblioteca de primitivas de procesamiento de señales. Cada una de ellas puede requerir un tiempo extra de compilación o declarar una gran tabla de constantes que te gustaría evitar. Podrías declarar una función de Cargo para cada componente en tu <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[features]
FIR = []
IIR = []
</code></pre>
<p>A continuación, en tu código, utiliza <code>#[cfg(feature=&quot;FIR&quot;)]</code> para controlar lo que se incluye.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// In your top-level lib.rs

#[cfg(feature=&quot;FIR&quot;)]
pub mod fir;

#[cfg(feature=&quot;IIR&quot;)]
pub mod iir;
<span class="boring">}</span></code></pre></pre>
<p>De forma similar, puede incluir bloques de código sólo si una prestación <em>no</em> está habilitada, o si cualquier combinación de prestaciones está o no está habilitada.</p>
<p>Además, Rust proporciona una serie de condiciones de configuración automática que puedes utilizar, como <code>target_arch</code> para seleccionar código diferente basado en la arquitectura. Para más detalles sobre el soporte de compilación condicional, consulta el capítulo <a href="https://doc.rust-lang.org/reference/conditional-compilation.html">compilación condicional</a> de la referencia de Rust.</p>
<p>La compilación condicional sólo se aplicará a la siguiente sentencia o bloque. Si un bloque no puede ser utilizado en el ámbito actual, entonces el atributo <code>cfg</code> tendrá que ser utilizado varias veces. Vale la pena señalar que la mayoría de las veces es mejor simplemente incluir todo el código y permitir que el compilador elimine el código muerto al optimizar: es más simple para ti y tus usuarios, y en general el compilador hará un buen trabajo eliminando el código no utilizado.</p>
<h3 id="computación-y-tamaños-en-tiempo-de-compilación"><a class="header" href="#computación-y-tamaños-en-tiempo-de-compilación">Computación y Tamaños en Tiempo de Compilación</a></h3>
<p>Rust soporta <code>const fn</code>, funciones que se garantiza que son evaluables en tiempo de compilación y por lo tanto se pueden utilizar cuando se requieren constantes, como en el tamaño de las matrices. Esto puede utilizarse junto con las funciones mencionadas anteriormente, por ejemplo:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>const fn array_size() -&gt; usize {
    #[cfg(feature=&quot;use_more_ram&quot;)]
    { 1024 }
    #[cfg(not(feature=&quot;use_more_ram&quot;))]
    { 128 }
}

static BUF: [u32; array_size()] = [0u32; array_size()];
<span class="boring">}</span></code></pre></pre>
<p>Estos son nuevos para Rust estable a partir de 1.31, por lo que la documentación es todavía escasa. La funcionalidad disponible para <code>const fn</code> también es muy limitada en el momento de escribir esto; en futuras versiones de Rust se espera ampliar lo que se permite en un <code>const fn</code>.</p>
<h3 id="macros"><a class="header" href="#macros">Macros</a></h3>
<p>Rust proporciona un <a href="https://doc.rust-lang.org/book/ch19-06-macros.html">sistema de macros</a> extremadamente potente. Mientras que el preprocesador de C opera casi directamente sobre el texto de tu código fuente, el sistema de macros de Rust opera a un nivel superior. Hay dos variedades de macros en Rust: <em>macros a través de ejemplo</em> y <em>macros procedimentales</em>. Las primeras son más simples y comunes; se parecen a las llamadas a funciones y pueden expandirse a una expresión, declaración, elemento o patrón completo. Las macros procedimentales son más complejas pero permiten adiciones extremadamente potentes al lenguaje Rust: pueden transformar sintaxis arbitraria de Rust en nueva sintaxis de Rust.</p>
<p>En general, donde podría haber utilizado una macro del preprocesador de C, probablemente quiera ver si una macro por ejemplo puede hacer el trabajo en su lugar. Pueden ser definidas en su <em>crate</em> y fácilmente usadas por su propio <em>crate</em> o exportadas para otros usuarios. Tenga en cuenta que, dado que deben expandirse a expresiones, sentencias, elementos o patrones completos, algunos casos de uso de macros del preprocesador de C no funcionarán, por ejemplo, una macro que se expanda a parte del nombre de una variable o a un conjunto incompleto de elementos de una lista.</p>
<p>Al igual que ocurre con las funciones de Cargo, conviene plantearse si se necesita la macro. En muchos casos, una función regular es más fácil de entender y será <em>inline</em> en el mismo código que una macro. Los <a href="https://doc.rust-lang.org/reference/attributes.html#inline-attribute">atributos</a> <code>#[inline]</code> e <code>#[inline(always)]</code> ofrecen un mayor control sobre este proceso, aunque también en este caso hay que tener cuidado: el compilador alineará automáticamente funciones de la misma <em>crate</em> cuando sea necesario, por lo que forzarlo a hacerlo de forma inadecuada podría reducir el rendimiento.</p>
<p>Explicar todo el sistema de macros de Rust está fuera del alcance de esta página de consejos, así que te animamos a consultar la documentación de Rust para más detalles.</p>
<h2 id="sistema-de-construcción"><a class="header" href="#sistema-de-construcción">Sistema de construcción</a></h2>
<p>La mayoría de los <em>crates</em> de Rust se construyen usando Cargo (aunque no es obligatorio). Esto resuelve muchos problemas difíciles con los sistemas de construcción tradicionales. Sin embargo, es posible que desee personalizar el proceso de construcción. Cargo proporciona los <a href="https://doc.rust-lang.org/cargo/reference/build-scripts.html">scripts <code>build.rs</code></a> para este propósito. Se trata de scripts de Rust que pueden interactuar con el sistema de compilación de Cargo según sea necesario.</p>
<p>Los casos de uso comunes para los scripts de compilación incluyen:</p>
<ul>
<li>proporcionar información en tiempo de compilación, por ejemplo incrustando estáticamente la fecha de compilación o el hash de commit de Git en el ejecutable</li>
<li>generar secuencias de comandos del enlazador en tiempo de compilación en función de las prestaciones seleccionadas u otra lógica</li>
<li>modificar la configuración de compilación de Cargo</li>
<li>añadir bibliotecas estáticas adicionales con las que enlazar</li>
</ul>
<p>Actualmente no hay soporte para scripts posteriores a la compilación, que tradicionalmente se han utilizado para tareas como la generación automática de binarios a partir de los objetos de compilación o la impresión de información de compilación.</p>
<h3 id="compilación-cruzada-1"><a class="header" href="#compilación-cruzada-1">Compilación cruzada</a></h3>
<p>El uso de Cargo como sistema de compilación también simplifica la compilación cruzada. En la mayoría de los casos basta con decirle a Cargo <code>--target thumbv6m-none-eabi</code> y encontrar un ejecutable adecuado en <code>target/thumbv6m-none-eabi/debug/myapp</code>.</p>
<p>Para plataformas no soportadas nativamente por Rust, necesitarás compilar <code>libcore</code> para ese objetivo por ti mismo. En tales plataformas, <a href="https://github.com/japaric/xargo">Xargo</a> puede ser utilizado como un sustituto de Cargo que automáticamente construye <code>libcore</code> para ti.</p>
<h2 id="iteradores-vs-acceso-a-matrices"><a class="header" href="#iteradores-vs-acceso-a-matrices">Iteradores vs Acceso a Matrices</a></h2>
<p>En C probablemente estés acostumbrado a acceder a arrays directamente por su índice:</p>
<pre><code class="language-c">int16_t arr[16];
int i;
for(i=0; i&lt;sizeof(arr)/sizeof(arr[0]); i++) {
    process(arr[i]);
}
</code></pre>
<p>En Rust esto es un anti-patrón: el acceso indexado puede ser más lento (ya que necesita ser comprobado) y puede impedir varias optimizaciones del compilador. Esta es una distinción importante y vale la pena repetirla: Rust comprobará los accesos fuera de los límites en la indexación manual de arrays para garantizar la seguridad de la memoria, mientras que C indexará alegremente fuera del array.</p>
<p>En su lugar, usa iteradores:</p>
<pre><code class="language-rust ignore">let arr = [0u16; 16];
for element in arr.iter() {
    process(*element);
}</code></pre>
<p>Los iteradores proporcionan una potente gama de funcionalidades que tendrías que implementar manualmente en C, como encadenar, comprimir, enumerar, encontrar el mínimo o el máximo, sumar, y más. Los métodos de los iteradores también pueden encadenarse, lo que proporciona un código de procesamiento de datos muy legible.</p>
<p>Consulte <a href="https://doc.rust-lang.org/book/ch13-02-iterators.html">Iteradores en el libro</a> y <a href="https://doc.rust-lang.org/core/iter/trait.Iterator.html">Documentación de los Iteradores</a> para obtener más información.</p>
<h2 id="referencias-vs-punteros"><a class="header" href="#referencias-vs-punteros">Referencias vs Punteros</a></h2>
<p>En Rust, los punteros (llamados punteros crudos (<a href="https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html#dereferencing-a-raw-pointer"><em>raw pointers</em></a>)) existen pero sólo se usan en circunstancias específicas, ya que desreferenciarlos siempre se considera inseguro (<code>unsafe</code>) -- Rust no puede proporcionar sus garantías habituales sobre lo que puede haber detrás del puntero.</p>
<p>En la mayoría de los casos, utilizamos <em>references</em>, indicadas por el símbolo <code>&amp;</code>, o <em>mutable references</em>, indicadas por <code>&amp;mut</code>. Las referencias se comportan de manera similar a los punteros, en el sentido de que pueden ser desreferenciadas para acceder a los valores subyacentes, pero son una parte clave del sistema de propiedad de Rust: Rust hará cumplir estrictamente que sólo se puede tener una referencia mutable <em>o</em> múltiples referencias no mutables al mismo valor en un momento dado.</p>
<p>En la práctica, esto significa que tienes que ser más cuidadoso sobre si necesitas acceso mutable a los datos: mientras que en C el valor por defecto es mutable y debes ser explícito sobre <code>const</code>, en Rust ocurre lo contrario.</p>
<p>Una situación en la que todavía se pueden utilizar <em>punteros crudos</em> es interactuando directamente con el hardware (por ejemplo, escribiendo un puntero a un buffer en un registro periférico DMA), y también se utilizan <em>tras bastidores</em> en todas las <em>crates</em> de acceso periférico para permitir la lectura y escritura de registros mapeados en memoria.</p>
<h2 id="acceso-volátil"><a class="header" href="#acceso-volátil">Acceso Volátil</a></h2>
<p>En C, las variables individuales pueden ser marcadas como <code>volatile</code>, indicando al compilador que el valor de la variable puede cambiar entre accesos. Las variables volátiles se usan comúnmente en un contexto embebido para registros mapeados en memoria.</p>
<p>En Rust, en lugar de marcar una variable como <code>volatile</code>, usamos métodos específicos para realizar accesos volátiles: <a href="https://doc.rust-lang.org/core/ptr/fn.read_volatile.html"><code>core::ptr::read_volatile</code></a> y <a href="https://doc.rust-lang.org/core/ptr/fn.write_volatile.html"><code>core::ptr::write_volatile</code></a>. Estos métodos toman un <code>*const T</code> o un <code>*mut T</code> (<em>raw pointers</em>, como se ha comentado anteriormente) y realizan una lectura o escritura volátil.</p>
<p>Por ejemplo, en C podrías escribir</p>
<pre><code class="language-c">volatile bool signalled = false;

void ISR() {
    // Señal de que se ha producido la interrupción
    signalled = true;
}

void driver() {
    while(true) {
        // Dormir hasta la señal
        while(!signalled) { WFI(); }
        // Resetear la bandera de la señal
        signalled = false;
        // Realizar alguna tarea que estaba a la espera de la interrupción
        run_task();
    }
}
</code></pre>
<p>El equivalente en Rust usaría métodos volátiles en cada acceso:</p>
<pre><code class="language-rust ignore">static mut SIGNALLED: bool = false;

#[interrupt]
fn ISR() {
    // Señal de que se ha producido la interrupción
    // (En condiciones reales, debes considerar una primitiva de alto nivel,
    //  tal como un tipo atómico (atomic type)).
    unsafe { core::ptr::write_volatile(&amp;mut SIGNALLED, true) };
}

fn driver() {
    loop {
        // Dormir hasta la señal
        while unsafe { !core::ptr::read_volatile(&amp;SIGNALLED) } {}
        // Resetear la bandera de la señal
        unsafe { core::ptr::write_volatile(&amp;mut SIGNALLED, false) };
        // Realizar alguna tarea que estaba a la espera de la interrupción
        run_task();
    }
}</code></pre>
<p>Vale la pena notar algunas cosas en el ejemplo de código:</p>
<ul>
<li>Podemos pasar <code>&amp;mut SIGNALLED</code> a la función que requiere <code>*mut T</code>, ya que <code>&amp;mut T</code> se convierte automáticamente en <code>*mut T</code> (y lo mismo para <code>*const T</code>)</li>
<li>Necesitamos bloques <code>unsafe</code> para los métodos <code>read_volatile</code>/<code>write_volatile</code>, ya que son funciones <code>unsafe</code>. Es responsabilidad del programador garantizar un uso seguro: consulte la documentación de los métodos para más detalles.</li>
</ul>
<p>Es raro que necesites estas funciones directamente en tu código, ya que normalmente se encargarán de ellas las bibliotecas de alto nivel. Para los periféricos mapeados en memoria, las <em>crates</em> de acceso a periféricos implementarán el acceso volátil automáticamente, mientras que para las primitivas de concurrencia hay mejores abstracciones disponibles (ver el <a href="c-tips/../concurrency/index.html">capítulo de concurrencia</a>).</p>
<h2 id="tipos-empaquetados-y-alineados"><a class="header" href="#tipos-empaquetados-y-alineados">Tipos empaquetados y alineados</a></h2>
<p>En C embebido es común decirle al compilador que una variable debe tener una cierta alineación o que una estructura debe estar empaquetada en lugar de alineada, normalmente para cumplir requisitos específicos de hardware o protocolo.</p>
<p>En Rust esto se controla mediante el atributo <code>repr</code> de una estructura o unión. La representación por defecto no ofrece garantías de disposición, por lo que no debe utilizarse para código que interopera con hardware o C. El compilador puede reordenar los miembros de la estructura o insertar relleno y el comportamiento puede cambiar con futuras versiones de Rust.</p>
<pre><pre class="playground"><code class="language-rust">struct Foo {
    x: u16,
    y: u8,
    z: u16,
}

fn main() {
    let v = Foo { x: 0, y: 0, z: 0 };
    println!(&quot;{:p} {:p} {:p}&quot;, &amp;v.x, &amp;v.y, &amp;v.z);
}

// 0x7ffecb3511d0 0x7ffecb3511d4 0x7ffecb3511d2
// Nota que el orden se cambió a x, z, y para mejorar el empaquetado.</code></pre></pre>
<p>Para asegurar diseños interoperables con C, use <code>repr(C)</code>:</p>
<pre><pre class="playground"><code class="language-rust">#[repr(C)]
struct Foo {
    x: u16,
    y: u8,
    z: u16,
}

fn main() {
    let v = Foo { x: 0, y: 0, z: 0 };
    println!(&quot;{:p} {:p} {:p}&quot;, &amp;v.x, &amp;v.y, &amp;v.z);
}

// 0x7fffd0d84c60 0x7fffd0d84c62 0x7fffd0d84c64
// El orden se preserva y la disposición no cambiará en el tiempo.
// `z` es alineado a dos bytes por lo que un byte de relleno existe entre `y` y `z`.</code></pre></pre>
<p>Para asegurar una representación empaquetada, use <code>repr(packed)</code>:</p>
<pre><pre class="playground"><code class="language-rust">#[repr(packed)]
struct Foo {
    x: u16,
    y: u8,
    z: u16,
}

fn main() {
    let v = Foo { x: 0, y: 0, z: 0 };
    // La referencias siempre deben estar alineadas, por lo tanto para revisar
    // las direcciones de los campos de las estructuras, usamos `std::ptr::addr_of!()`
    // para obtener un puntero crudo en lugar de sólo imprimir `&amp;v.x`.
    let px = std::ptr::addr_of!(v.x);
    let py = std::ptr::addr_of!(v.y);
    let pz = std::ptr::addr_of!(v.z);
    println!(&quot;{:p} {:p} {:p}&quot;, px, py, pz);
}

// 0x7ffd33598490 0x7ffd33598492 0x7ffd33598493
// No se ha insertado relleno entre `y` y `z`, por lo tanto, ahora `z` está desalineado.</code></pre></pre>
<p>Tenga en cuenta que el uso de <code>repr(packed)</code> también establece la alineación del tipo a <code>1</code>.</p>
<p>Finalmente, para especificar una alineación concreta, usa <code>repr(align(n))</code>, donde <code>n</code> es el número de bytes a alinear (y debe ser una potencia de dos):</p>
<pre><pre class="playground"><code class="language-rust">#[repr(C)]
#[repr(align(4096))]
struct Foo {
    x: u16,
    y: u8,
    z: u16,
}

fn main() {
    let v = Foo { x: 0, y: 0, z: 0 };
    let u = Foo { x: 0, y: 0, z: 0 };
    println!(&quot;{:p} {:p} {:p}&quot;, &amp;v.x, &amp;v.y, &amp;v.z);
    println!(&quot;{:p} {:p} {:p}&quot;, &amp;u.x, &amp;u.y, &amp;u.z);
}

// 0x7ffec909a000 0x7ffec909a002 0x7ffec909a004
// 0x7ffec909b000 0x7ffec909b002 0x7ffec909b004
// Las dos instancias `u` y `v` han sido colocadas en alineamientos de 4096 bytes,
// evidenciado por el `000` al final de sus direcciones.</code></pre></pre>
<p>Observe que podemos combinar <code>repr(C)</code> con <code>repr(align(n))</code> para obtener una disposición alineada y compatible con C. No es permisible combinar <code>repr(align(n))</code> con <code>repr(packed)</code>, ya que <code>repr(packed)</code> establece la alineación a <code>1</code>. Tampoco está permitido que un tipo <code>repr(packed)</code> contenga un tipo <code>repr(align(n))</code>.</p>
<p>Para más detalles sobre la disposición de tipos, consulta el capítulo <a href="https://doc.rust-lang.org/reference/type-layout.html">disposición de tipos</a> de la Referencia de Rust.</p>
<h2 id="otros-recursos-1"><a class="header" href="#otros-recursos-1">Otros Recursos</a></h2>
<ul>
<li>En este libro:
<ul>
<li><a href="c-tips/../interoperability/c-with-rust.html">Un poco de C con tu Rust</a></li>
<li><a href="c-tips/../interoperability/rust-with-c.html">Un poco de Rust con tu C</a></li>
</ul>
</li>
<li><a href="https://docs.rust-embedded.org/faq.html">Preguntas frecuentes sobre Rust embebido</a></li>
<li><a href="http://blahg.josefsipek.net/?p=580">Punteros Rust para programadores C</a></li>
<li><a href="https://github.com/diwic/reffers-rs/blob/master/docs/Pointers.md">Usé punteros, ¿y ahora qué?</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="interoperabilidad-1"><a class="header" href="#interoperabilidad-1">Interoperabilidad</a></h1>
<p>La interoperabilidad entre el código Rust y C depende siempre de la transformación de datos entre los dos lenguajes. Para ello hay dos módulos dedicados en <code>stdlib</code> llamados <a href="https://doc.rust-lang.org/std/ffi/index.html"><code>std::ffi</code></a> y <a href="https://doc.rust-lang.org/std/os/raw/index.html"><code>std::os::raw</code></a>.</p>
<p><code>std::os::raw</code> trata con tipos primitivos de bajo nivel que pueden ser convertidos implícitamente por el compilador porque la disposición de memoria entre Rust y C es lo suficientemente similar o la misma.</p>
<p><code>std::ffi</code> proporciona alguna utilidad para convertir tipos más complejos como Strings, mapeando tanto <code>&amp;str</code> como <code>String</code> a tipos C que son más fáciles y seguros de manejar.</p>
<p>Ninguno de estos módulos está disponible en <code>core</code>, pero puedes encontrar una versión compatible con <code>#![no_std]</code> de <code>std::ffi::{CStr,CString}</code> en la <em>crate</em> <a href="https://crates.io/crates/cstr_core"><code>cstr_core</code></a>, y la mayoría de los tipos <code>std::os::raw</code> en la <em>crate</em> <a href="https://crates.io/crates/cty"><code>cty</code></a>.</p>
<div class="table-wrapper"><table><thead><tr><th>Tipo Rust</th><th>Intermedio</th><th>Tipo C</th></tr></thead><tbody>
<tr><td>String</td><td>CString</td><td>*char</td></tr>
<tr><td>&amp;str</td><td>CStr</td><td>*const char</td></tr>
<tr><td>()</td><td>c_void</td><td>void</td></tr>
<tr><td>u32 o u64</td><td>c_uint</td><td>unsigned int</td></tr>
<tr><td>etc.</td><td>...</td><td>...</td></tr>
</tbody></table>
</div>
<p>Como se mencionó anteriormente, los tipos primitivos pueden ser convertidos por el compilador implícitamente.</p>
<pre><code class="language-rust ignore">unsafe fn foo(num: u32) {
    let c_num: c_uint = num;
    let r_num: u32 = c_num;
}</code></pre>
<h2 id="interoperabilidad-con-otros-sistemas-de-compilación"><a class="header" href="#interoperabilidad-con-otros-sistemas-de-compilación">Interoperabilidad con otros sistemas de compilación</a></h2>
<p>Un requisito común para incluir Rust en tu proyecto embebido es combinar Cargo con tu sistema de compilación existente, como make o cmake.</p>
<p>Estamos recopilando ejemplos y casos de uso para esto en nuestro issue tracker en <a href="https://github.com/rust-embedded/book/issues/61">issue #61</a>.</p>
<h2 id="interoperabilidad-con-sistemas-operativos-en-tiempo-real-rtoss"><a class="header" href="#interoperabilidad-con-sistemas-operativos-en-tiempo-real-rtoss">Interoperabilidad con Sistemas Operativos en Tiempo Real (RTOSs)</a></h2>
<p>Integrar Rust con un RTOS como FreeRTOS o ChibiOS es todavía un trabajo en progreso; en particular llamar a funciones RTOS desde Rust puede ser complicado.</p>
<p>Estamos recopilando ejemplos y casos de uso para esto en nuestro issue tracker en <a href="https://github.com/rust-embedded/book/issues/62">issue #62</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="un-poco-de-c-con-tu-rust"><a class="header" href="#un-poco-de-c-con-tu-rust">Un poco de C con tu Rust</a></h1>
<p>Usar C o C++ dentro de un proyecto Rust consta de dos partes principales:</p>
<ul>
<li>Envolver la API C expuesta para usarla con Rust</li>
<li>Construir tu código C o C++ para integrarlo con el código Rust</li>
</ul>
<p>Como C++ no tiene una ABI estable para el compilador de Rust, se recomienda usar la ABI <code>C</code> cuando se combina Rust con C o C++.</p>
<h2 id="definir-la-interfaz"><a class="header" href="#definir-la-interfaz">Definir la interfaz</a></h2>
<p>Antes de consumir código C o C++ desde Rust, es necesario definir (en Rust) qué tipos de datos y firmas de función existen en el código enlazado. En C o C++, se incluiría un fichero de cabecera (<code>.h</code> o <code>.hpp</code>) que defina estos datos. En Rust, es necesario traducir manualmente estas definiciones a Rust, o utilizar una herramienta para generar estas definiciones.</p>
<p>Primero, cubriremos la traducción manual de estas definiciones de C/C++ a Rust.</p>
<h3 id="envolviendo-funciones-c-y-datatypes"><a class="header" href="#envolviendo-funciones-c-y-datatypes">Envolviendo funciones C y Datatypes</a></h3>
<p>Típicamente, las bibliotecas escritas en C o C++ proporcionan un fichero de cabecera que define todos los tipos y funciones utilizados en las interfaces públicas. Un archivo de ejemplo puede tener este aspecto:</p>
<pre><code class="language-C">/* File: cool.h */
typedef struct CoolStruct {
    int x;
    int y;
} CoolStruct;

void cool_function(int i, char c, CoolStruct* cs);
</code></pre>
<p>Traducida a Rust, esta interfaz quedaría así:</p>
<pre><code class="language-rust ignore">/* File: cool_bindings.rs */
#[repr(C)]
pub struct CoolStruct {
    pub x: cty::c_int,
    pub y: cty::c_int,
}

extern &quot;C&quot; {
    pub fn cool_function(
        i: cty::c_int,
        c: cty::c_char,
        cs: *mut CoolStruct
    );
}</code></pre>
<p>Echemos un vistazo a esta definición pieza por pieza, para explicar cada una de las partes.</p>
<pre><code class="language-rust ignore">#[repr(C)]
pub struct CoolStruct { ... }</code></pre>
<p>Por defecto, Rust no garantiza el orden, el relleno o el tamaño de los datos incluidos en una <code>struct</code>. Para garantizar la compatibilidad con el código C, incluimos el atributo <code>#[repr(C)]</code>, que indica al compilador de Rust que utilice siempre las mismas reglas que C para organizar los datos dentro de una estructura.</p>
<pre><code class="language-rust ignore">pub x: cty::c_int,
pub y: cty::c_int,</code></pre>
<p>Debido a la flexibilidad de cómo C o C++ definen un <code>int</code> o un <code>char</code>, se recomienda usar tipos de datos primitivos definidos en <code>cty</code>, que mapeará tipos de C a tipos en Rust.</p>
<pre><code class="language-rust ignore">extern &quot;C&quot; { pub fn cool_function( ... ); }</code></pre>
<p>Esta sentencia define la firma de una función que usa la ABI de C, llamada <code>cool_function</code>. Al definir la firma sin definir el cuerpo de la función, la definición de esta función necesitará ser proporcionada en otro lugar, o enlazada en la librería final o binaria desde una librería estática.</p>
<pre><code class="language-rust ignore">    i: cty::c_int,
    c: cty::c_char,
    cs: *mut CoolStruct</code></pre>
<p>Al igual que en el caso anterior, definimos los tipos de datos de los argumentos de las funciones utilizando definiciones compatibles con C. También mantenemos los mismos nombres de argumentos para mayor claridad.</p>
<p>Aquí tenemos un nuevo tipo, <code>*mut CoolStruct</code>. Como C no tiene el concepto de referencias de Rust, que se vería así: <code>&amp;mut CoolStruct</code>, en su lugar tenemos un puntero crudo. Como hacer referencia a este puntero es <code>unsafe</code>, y el puntero puede ser de hecho un puntero <code>null</code>, hay que tener cuidado para asegurar las garantías típicas de Rust cuando se interactúa con código C o C++.</p>
<h3 id="generación-automática-de-la-interfaz"><a class="header" href="#generación-automática-de-la-interfaz">Generación automática de la interfaz</a></h3>
<p>En lugar de generar manualmente estas interfaces, lo que puede ser tedioso y propenso a errores, existe una herramienta llamada <a href="https://github.com/rust-lang/rust-bindgen">bindgen</a> que realizará estas conversiones automáticamente. Para instrucciones de uso de <a href="https://github.com/rust-lang/rust-bindgen">bindgen</a>, consulte el <a href="https://rust-lang.github.io/rust-bindgen/">manual de usuario de bindgen</a>, sin embargo el proceso típico consiste en lo siguiente:</p>
<ol>
<li>Reúne todas las cabeceras C o C++ que definan interfaces o tipos de datos que quieras usar con Rust.</li>
<li>Escribe un archivo <code>bindings.h</code>, que <code>#include &quot;...&quot;</code> cada uno de los archivos que reuniste en el paso uno.</li>
<li>Introduce este fichero <code>bindings.h</code>, junto con cualquier bandera de compilación utilizada para compilar tu código en <code>bindgen</code>. Consejo: utilice <code>Builder.ctypes_prefix(&quot;cty&quot;)</code> / <code>--ctypes-prefix=cty</code> y <code>Builder.use_core()</code> / <code>--use-core</code> para hacer compatible el código generado <code>#![no_std]</code>.</li>
<li><code>bindgen</code> producirá el código Rust generado a la salida de la ventana de terminal. Este archivo puede ser canalizado a un archivo de tu proyecto, como <code>bindings.rs</code>. Puedes usar este archivo en tu proyecto Rust para interactuar con código C/C++ compilado y enlazado como una librería externa. Consejo: no te olvides de usar la <em>crate</em> <a href="https://crates.io/crates/cty"><code>cty</code></a> si tus tipos en los bindings generados están prefijados con <code>cty</code>.</li>
</ol>
<h2 id="construyendo-tu-código-cc"><a class="header" href="#construyendo-tu-código-cc">Construyendo tu código C/C++</a></h2>
<p>Como el compilador Rust no sabe directamente cómo compilar código C o C++ (o código de cualquier otro lenguaje, que presente una interfaz C), es necesario compilar tu código no Rust con antelación.</p>
<p>Para proyectos embebidos, esto significa normalmente compilar el código C/C++ en un archivo estático (como <code>cool-library.a</code>), que puede combinarse con tu código Rust en el paso final de enlazado.</p>
<p>Si la biblioteca que deseas utilizar ya se distribuye como un archivo estático, no es necesario reconstruir su código. Sólo tienes que convertir el fichero de cabecera de interfaz proporcionado como se ha descrito anteriormente, e incluir el archivo estático en el momento de compilar/enlazar.</p>
<p>Si tu código existe como un proyecto fuente, será necesario compilar tu código C/C++ a una biblioteca estática, ya sea activando tu sistema de compilación existente (como <code>make</code>, <code>CMake</code>, etc.), o portando los pasos de compilación necesarios para utilizar una herramienta llamada <code>cc</code> <em>crate</em>. Para ambos pasos, es necesario utilizar un script <code>build.rs</code>.</p>
<h3 id="scripts-de-compilación-buildrs-de-rust"><a class="header" href="#scripts-de-compilación-buildrs-de-rust">Scripts de compilación <code>build.rs</code> de Rust</a></h3>
<p>Un script <code>build.rs</code> es un archivo escrito en sintaxis Rust, que se ejecuta en tu máquina de compilación, DESPUÉS de que las dependencias de tu proyecto hayan sido construidas, pero ANTES de que tu proyecto sea construido.</p>
<p>La referencia completa se puede encontrar <a href="https://doc.rust-lang.org/cargo/reference/build-scripts.html">aquí</a>. Los scripts <code>build.rs</code> son útiles para generar código (como a través de <a href="https://github.com/rust-lang/rust-bindgen">bindgen</a>), llamando a sistemas de compilación externos como <code>Make</code>, o compilando directamente C/C++ a través del uso de la <em>crate</em> <code>cc</code>.</p>
<h3 id="activación-de-sistemas-de-compilación-externos"><a class="header" href="#activación-de-sistemas-de-compilación-externos">Activación de sistemas de compilación externos</a></h3>
<p>Para proyectos con complejos proyectos externos o sistemas de compilación, puede ser más fácil usar <a href="https://doc.rust-lang.org/std/process/struct.Command.html"><code>std::process::Command</code></a> para &quot;enviar&quot; a tus otros sistemas de compilación atravesando rutas relativas, llamando a un comando fijo (como <code>make library</code>), y luego copiando la biblioteca estática resultante a la ubicación adecuada en el directorio de compilación <code>target</code>.</p>
<p>Mientras que tu <em>crate</em> puede estar dirigida a una plataforma embebida <code>no_std</code>, tu <code>build.rs</code> se ejecuta sólo en las máquinas que compilan tu <em>crate</em>. Esto significa que puedes usar cualquier <em>crate</em> de Rust que se ejecute en tu anfitrión de compilación.</p>
<h3 id="construyendo-código-cc-con-la-crate-cc"><a class="header" href="#construyendo-código-cc-con-la-crate-cc">Construyendo código C/C++ con la <em>crate</em> <code>cc</code></a></h3>
<p>Para proyectos con dependencias o complejidad limitadas, o para proyectos donde es difícil modificar el sistema de compilación para producir una librería estática (en lugar de un binario final o ejecutable), puede ser más fácil utilizar la <a href="https://github.com/alexcrichton/cc-rs"><em>crate</em> <code>cc</code></a>, que proporciona una interfaz idiomática de Rust al compilador proporcionado por el anfitrión.</p>
<p>En el caso más sencillo de compilar un único archivo C como dependencia de una biblioteca estática, un script <code>build.rs</code> de ejemplo utilizando la <a href="https://github.com/alexcrichton/cc-rs"><em>crate</em> <code>cc</code></a> tendría el siguiente aspecto:</p>
<pre><code class="language-rust ignore">fn main() {
    cc::Build::new()
        .file(&quot;foo.c&quot;)
        .compile(&quot;libfoo.a&quot;);
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="un-poco-de-rust-con-tu-c"><a class="header" href="#un-poco-de-rust-con-tu-c">Un poco de Rust con tu C</a></h1>
<p>Usar código Rust dentro de un proyecto C o C++ consiste principalmente en dos partes.</p>
<ul>
<li>Crear una API amigable con C en Rust</li>
<li>Incrustar tu proyecto Rust en un sistema de compilación externo</li>
</ul>
<p>Aparte de <code>cargo</code> y <code>meson</code>, la mayoría de los sistemas de compilación no tienen soporte nativo para Rust. Así que lo mejor es que utilices <code>cargo</code> para compilar tu <em>crate</em> y cualquier dependencia.</p>
<h2 id="creando-un-proyecto"><a class="header" href="#creando-un-proyecto">Creando un proyecto</a></h2>
<p>Crea un nuevo proyecto <code>cargo</code> como de costumbre.</p>
<p>Hay banderas para decirle a <code>cargo</code> que emita una biblioteca de sistemas, en lugar de su objetivo rust normal. Esto también te permite establecer un nombre de salida diferente para tu biblioteca, si quieres que difiera del resto de tu <em>crate</em>.</p>
<pre><code class="language-toml">[lib]
name = &quot;your_crate&quot;
crate-type = [&quot;cdylib&quot;]      # Creates dynamic lib
# crate-type = [&quot;staticlib&quot;] # Creates static lib
</code></pre>
<h2 id="creación-de-una-api-c"><a class="header" href="#creación-de-una-api-c">Creación de una API <code>C</code></a></h2>
<p>Debido a que C++ no tiene una ABI estable para el compilador de Rust, usamos <code>C</code> para cualquier interoperabilidad entre diferentes lenguajes. Esto no es una excepción cuando usamos Rust dentro de código C y C++.</p>
<h3 id="no_mangle"><a class="header" href="#no_mangle"><code>#[no_mangle]</code></a></h3>
<p>El compilador de Rust manipula los nombres de los símbolos de forma diferente a lo que esperan los enlazadores de código nativo. Como tal, cualquier función que Rust exporte para ser usada fuera de Rust necesita que se le diga que no sea manipulada por el compilador.</p>
<h3 id="extern-c"><a class="header" href="#extern-c"><code>extern &quot;C&quot;</code></a></h3>
<p>Por defecto, cualquier función que escribas en Rust usará la ABI de Rust (que tampoco está estabilizada). En cambio, cuando se construyen APIs FFI orientadas al exterior, necesitamos decirle al compilador que use la ABI del sistema.</p>
<p>Dependiendo de tu plataforma, puede que quieras apuntar a una versión ABI específica, que están documentadas <a href="https://doc.rust-lang.org/reference/items/external-blocks.html">aquí</a>.</p>
<hr />
<p>Juntando estas partes, se obtiene una función que se parece más o menos a esto.</p>
<pre><code class="language-rust ignore">#[no_mangle]
pub extern &quot;C&quot; fn rust_function() {

}</code></pre>
<p>Igual que cuando usas código <code>C</code> en tu proyecto Rust ahora necesitas transformar los datos desde y hacia una forma que el resto de la aplicación entienda.</p>
<h2 id="enlazado-y-mayor-contexto-del-proyecto"><a class="header" href="#enlazado-y-mayor-contexto-del-proyecto">Enlazado y mayor contexto del proyecto.</a></h2>
<p>Así que, esa es una mitad del problema resuelto. ¿Cómo usas esto ahora?</p>
<p><strong>Esto depende mucho de tu proyecto y/o sistema de compilación</strong></p>
<p><code>cargo</code> creará un archivo <code>my_lib.so</code>/<code>my_lib.dll</code> o <code>my_lib.a</code>, dependiendo de tu plataforma y configuración. Esta biblioteca puede ser simplemente enlazada por tu sistema de compilación.</p>
<p>Sin embargo, llamar a una función Rust desde C requiere un archivo de cabecera para declarar las firmas de la función.</p>
<p>Cada función en tu API Rust-ffi necesita tener una función de cabecera correspondiente.</p>
<pre><code class="language-rust ignore">#[no_mangle]
pub extern &quot;C&quot; fn rust_function() {}</code></pre>
<p>se convertiría en</p>
<pre><code class="language-C">void rust_function();
</code></pre>
<p>etc.</p>
<p>Existe una herramienta para automatizar este proceso, llamada <a href="https://github.com/eqrion/cbindgen">cbindgen</a>, que analiza tu código Rust y genera a partir de él cabeceras para tus proyectos C y C++.</p>
<p>Llegados a este punto, ¡utilizar las funciones Rust desde C es tan sencillo como incluir la cabecera y llamarlas!</p>
<pre><code class="language-C">#include &quot;my-rust-project.h&quot;
rust_function();
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="temas-sin-clasificar"><a class="header" href="#temas-sin-clasificar">Temas sin clasificar</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="optimizaciones-el-compromiso-entre-velocidad-y-tamaño"><a class="header" href="#optimizaciones-el-compromiso-entre-velocidad-y-tamaño">Optimizaciones: el compromiso entre velocidad y tamaño</a></h1>
<p>Todo el mundo quiere que su programa sea superrápido y superpequeño, pero normalmente no es posible tener ambas características. Esta sección discute los diferentes niveles de optimización que <code>rustc</code> proporciona y cómo afectan al tiempo de ejecución y al tamaño binario de un programa.</p>
<h2 id="sin-optimizaciones"><a class="header" href="#sin-optimizaciones">Sin optimizaciones</a></h2>
<p>Esta es la opción por defecto. Cuando se llama a <code>cargo build</code> se utiliza el perfil de desarrollo (AKA <code>dev</code>). Este perfil está optimizado para la depuración, por lo que habilita la información de depuración y <em>no</em> habilita ninguna optimización, es decir, utiliza <code>-C opt-level = 0</code>.</p>
<p>Al menos para el desarrollo bare metal, debuginfo es costo cero en el sentido de que no ocupará espacio en Flash / ROM por lo que en realidad recomendamos que active debuginfo en el perfil de liberación -- está desactivado por defecto. Esto le permitirá utilizar puntos de interrupción al depurar las versiones.</p>
<pre><code class="language-toml">[profile.release]
# symbols are nice and they don't increase the size on Flash
debug = true
</code></pre>
<p>Sin optimizaciones es genial para la depuración, porque el paso a través del código se siente como si estuviera ejecutando el programa declaración por declaración, además de que puede <code>print</code> variables de la pila y los argumentos de función en GDB. Cuando el código está optimizado, al intentar imprimir variables se imprime <code>$0 = &lt;valor optimizado&gt;</code>.</p>
<p>El mayor inconveniente del perfil <code>dev</code> es que el binario resultante será enorme y lento. El tamaño es normalmente el mayor problema porque los binarios no optimizados pueden ocupar docenas de KiB de Flash, que tu dispositivo de destino puede no tener -- el resultado: ¡tu binario no optimizado no cabe en tu dispositivo!</p>
<p>¿Podemos tener binarios más pequeños y fáciles de depurar? Sí, hay un truco.</p>
<h3 id="optimizar-las-dependencias"><a class="header" href="#optimizar-las-dependencias">Optimizar las dependencias</a></h3>
<p>Existe una función de Cargo llamada <a href="https://doc.rust-lang.org/cargo/reference/profiles.html#overrides"><code>profile-overrides</code></a> que te permite anular el nivel de optimización de las dependencias. Puedes usar esta característica para optimizar todas las dependencias por tamaño mientras mantienes la <em>crate</em> superior sin optimizar y amigable para el depurador.</p>
<p>Aquí tienes un ejemplo:</p>
<pre><code class="language-toml"># Cargo.toml
[package]
name = &quot;app&quot;
# ..

[profile.dev.package.&quot;*&quot;] # +
opt-level = &quot;z&quot; # +
</code></pre>
<p>Sin la anulación:</p>
<pre><code class="language-text">$ cargo size --bin app -- -A
app  :
section               size        addr
.vector_table         1024   0x8000000
.text                 9060   0x8000400
.rodata               1708   0x8002780
.data                    0  0x20000000
.bss                     4  0x20000000
</code></pre>
<p>Con la anulación:</p>
<pre><code class="language-text">$ cargo size --bin app -- -A
app  :
section               size        addr
.vector_table         1024   0x8000000
.text                 3490   0x8000400
.rodata               1100   0x80011c0
.data                    0  0x20000000
.bss                     4  0x20000000
</code></pre>
<p>Eso es una reducción de 6 KiB en el uso de Flash sin ninguna pérdida en la depurabilidad de la <em>crate</em> superior. Si entras en una dependencia entonces empezarás a ver esos mensajes de <code>&lt;value optimized out&gt;</code> de nuevo, pero normalmente lo que quieres es depurar la <em>crate</em> superior y no las dependencias. Y si <em>necesitas</em> depurar una dependencia entonces puedes usar la característica <code>profile-overrides</code> para excluir una dependencia en particular de ser optimizada. Véase el ejemplo siguiente:</p>
<pre><code class="language-toml"># ..

# don't optimize the `cortex-m-rt` crate
[profile.dev.package.cortex-m-rt] # +
opt-level = 0 # +

# but do optimize all the other dependencies
[profile.dev.package.&quot;*&quot;]
codegen-units = 1 # better optimizations
opt-level = &quot;z&quot;
</code></pre>
<p>¡Ahora la <em>crate</em> superior y <code>cortex-m-rt</code> son amigables con el depurador!</p>
<h2 id="optimizar-para-velocidad"><a class="header" href="#optimizar-para-velocidad">Optimizar para velocidad</a></h2>
<p>A partir de 2018-09-18 <code>rustc</code> soporta tres niveles de &quot;optimización para velocidad&quot;: <code>opt-level = 1</code>, <code>2</code> y <code>3</code>. Cuando ejecutas <code>cargo build --release</code> estás usando el perfil release que por defecto es <code>opt-level = 3</code>.</p>
<p>Tanto <code>opt-level = 2</code> como <code>3</code> optimizan la velocidad a expensas del tamaño del binario, pero el nivel <code>3</code> hace más vectorización e inlining que el nivel <code>2</code>. En particular, verás que en <code>opt-level</code> igual o mayor que <code>2</code> LLVM desenrollará bucles. El desenrollado de bucles tiene un costo bastante alto en términos de Flash / ROM (por ejemplo, de 26 bytes a 194 para un bucle de matriz cero), pero también puede reducir a la mitad el tiempo de ejecución dadas las condiciones adecuadas (por ejemplo, el número de iteraciones es lo suficientemente grande).</p>
<p>Actualmente no hay forma de deshabilitar el desenrollado de bucles en <code>opt-level = 2</code> y <code>3</code> así que si no puedes permitirte su costo, deberías optimizar tu programa por tamaño.</p>
<h2 id="optimizar-por-tamaño"><a class="header" href="#optimizar-por-tamaño">Optimizar por tamaño</a></h2>
<p>A partir de 2018-09-18 <code>rustc</code> soporta dos niveles de &quot;optimización por tamaño&quot;: <code>opt-level = &quot;s&quot;</code> y <code>&quot;z&quot;</code>. Estos nombres fueron heredados de clang / LLVM y no son demasiado descriptivos, pero <code>&quot;z&quot;</code> pretende dar la idea de que produce binarios más pequeños que <code>&quot;s&quot;</code>.</p>
<p>Si quieres que tus binarios de lanzamiento estén optimizados para el tamaño, entonces cambia el ajuste <code>profile.release.opt-level</code> en <code>Cargo.toml</code> como se muestra a continuación.</p>
<pre><code class="language-toml">[profile.release]
# or &quot;z&quot;
opt-level = &quot;s&quot;
</code></pre>
<p>Estos dos niveles de optimización reducen en gran medida el umbral inline de LLVM, una métrica utilizada para decidir si hacer una función <code>inline</code> o no. Uno de los principios de Rust son las abstracciones de costo cero; estas abstracciones tienden a usar muchos newtypes y pequeñas funciones para mantener invariantes (por ejemplo, funciones que toman prestado un valor interno como <code>deref</code>, <code>as_ref</code>) por lo que un umbral inline bajo puede hacer que LLVM pierda oportunidades de optimización (por ejemplo, eliminar ramas muertas, llamadas inline a cierres).</p>
<p>Cuando se optimiza por tamaño se puede intentar aumentar el umbral inline para ver si tiene algún efecto en el tamaño del binario. La forma recomendada de cambiar el umbral en línea es añadir la bandera <code>-C inline-threshold</code> a las otras rustflags en <code>.cargo/config.toml</code>.</p>
<pre><code class="language-toml"># .cargo/config.toml
# this assumes that you are using the cortex-m-quickstart template
[target.'cfg(all(target_arch = &quot;arm&quot;, target_os = &quot;none&quot;))']
rustflags = [
  # ..
  &quot;-C&quot;, &quot;inline-threshold=123&quot;, # +
]
</code></pre>
<p>¿Qué valor usar? <a href="https://github.com/rust-lang/rust/blob/1.29.0/src/librustc_codegen_llvm/back/write.rs#L2105-L2122">A partir de 1.29.0 estos son los umbrales en línea que utilizan los distintos niveles de optimización</a>:</p>
<ul>
<li><code>opt-level = 3</code> usa 275</li>
<li><code>opt-level = 2</code> usa 225</li>
<li><code>opt-level = &quot;s&quot;</code> usa 75</li>
<li><code>opt-level = &quot;z&quot;</code> usa 25</li>
</ul>
<p>Deberías probar con <code>225</code> y <code>275</code> para optimizar el tamaño.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="realizar-funciones-matemáticas-con-no_std"><a class="header" href="#realizar-funciones-matemáticas-con-no_std">Realizar funciones matemáticas con <code>#[no_std]</code></a></h1>
<p>Si quieres realizar funciones matemáticas como calcular la raíz cuadrada o la exponencial de un número y tienes disponible toda la biblioteca estándar, tu código podría ser como el siguiente:</p>
<pre><code class="language-rs">//! Some mathematical functions with standard support available

fn main() {
    let float: f32 = 4.82832;
    let floored_float = float.floor();

    let sqrt_of_four = floored_float.sqrt();

    let sinus_of_four = floored_float.sin();

    let exponential_of_four = floored_float.exp();
    println!(&quot;Floored test float {} to {}&quot;, float, floored_float);
    println!(&quot;The square root of {} is {}&quot;, floored_float, sqrt_of_four);
    println!(&quot;The sinus of four is {}&quot;, sinus_of_four);
    println!(
        &quot;The exponential of four to the base e is {}&quot;,
        exponential_of_four
    )
}
</code></pre>
<p>Sin el soporte de la biblioteca estándar, estas funciones no están disponibles. En su lugar se puede utilizar una <em>crate</em> externa como <a href="https://crates.io/crates/libm"><code>libm</code></a>. El código de ejemplo sería el siguiente</p>
<pre><code class="language-rs">#![no_main]
#![no_std]

use panic_halt as _;

use cortex_m_rt::entry;
use cortex_m_semihosting::{debug, hprintln};
use libm::{exp, floorf, sin, sqrtf};

#[entry]
fn main() -&gt; ! {
    let float = 4.82832;
    let floored_float = floorf(float);

    let sqrt_of_four = sqrtf(floored_float);

    let sinus_of_four = sin(floored_float.into());

    let exponential_of_four = exp(floored_float.into());
    hprintln!(&quot;Floored test float {} to {}&quot;, float, floored_float).unwrap();
    hprintln!(&quot;The square root of {} is {}&quot;, floored_float, sqrt_of_four).unwrap();
    hprintln!(&quot;The sinus of four is {}&quot;, sinus_of_four).unwrap();
    hprintln!(
        &quot;The exponential of four to the base e is {}&quot;,
        exponential_of_four
    )
    .unwrap();
    // exit QEMU
    // NOTE do not run this on hardware; it can corrupt OpenOCD state
    // debug::exit(debug::EXIT_SUCCESS);

    loop {}
}
</code></pre>
<p>Si necesitas realizar operaciones más complejas como procesamiento de señales DSP o álgebra lineal avanzada en tu MCU, los siguientes crates pueden ayudarte</p>
<ul>
<li><a href="https://github.com/jacobrosenthal/cmsis-dsp-sys">CMSIS DSP library binding</a></li>
<li><a href="https://github.com/tarcieri/micromath"><code>micromath</code></a></li>
<li><a href="https://crates.io/crates/microfft"><code>microfft</code></a></li>
<li><a href="https://github.com/dimforge/nalgebra"><code>nalgebra</code></a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="apéndice-a-glosario"><a class="header" href="#apéndice-a-glosario">Apéndice A: Glosario</a></h1>
<p>El ecosistema embebido está lleno de diferentes protocolos, componentes de hardware y específicos de cada proveedor que utilizan sus propios términos y abreviaturas. Este glosario intenta enumerarlos con indicaciones para entenderlos mejor.</p>
<h3 id="bsp"><a class="header" href="#bsp">BSP</a></h3>
<p>Una <em>Crate</em> de Soporte de Tarjeta (Board Support <em>Crate</em>) proporciona una interfaz de alto nivel configurada para una tarjeta específica. Normalmente depende de una <em>crate</em> <a href="appendix/glossary.html#hal">HAL</a>.
Hay una descripción más detallada en la <a href="appendix/../start/registers.html">página de registros de memoria mapeada</a> o para una visión más amplia ver <a href="https://youtu.be/vLYit_HHPaY">este video</a>.</p>
<h3 id="fpu"><a class="header" href="#fpu">FPU</a></h3>
<p>Unidad de punto flotante. Un 'procesador matemático' que ejecuta sólo operaciones con números de punto flotante.</p>
<h3 id="hal"><a class="header" href="#hal">HAL</a></h3>
<p>Una Capa de Abstracción de Hardware proporciona una interfaz amigable para el desarrollador a las características y periféricos de un microcontrolador. Normalmente se implementa sobre una <a href="appendix/glossary.html#pac"><em>Crate</em> de Acceso Periférico (PAC)</a>.
También se puede implementar <em>traits</em> de la <em>crate</em> <a href="https://crates.io/crates/embedded-hal"><code>embedded-hal</code></a>.
Hay una descripción más detallada en la <a href="appendix/../start/registers.html">página de registros de memoria mapeada</a> o para una visión más amplia ver <a href="https://youtu.be/vLYit_HHPaY">este video</a>.</p>
<h3 id="i2c"><a class="header" href="#i2c">I2C</a></h3>
<p>También llamado <code>I²C</code> o Inter-IC. Es un protocolo destinado a la comunicación de hardware dentro de un único circuito integrado. Ver <a href="https://en.wikipedia.org/wiki/I2c">aquí</a> para más detalles</p>
<h3 id="pac"><a class="header" href="#pac">PAC</a></h3>
<p>Una <em>Crate</em> de Acceso Periférico proporciona acceso a los periféricos de un microcontrolador. Es uno de nivel inferior y normalmente se genera directamente a partir del <a href="appendix/glossary.html#svd">SVD</a> proporcionado, a menudo utilizando [svd2rust] (#svd). utilizando <a href="https://github.com/rust-embedded/svd2rust/">svd2rust</a>. La <a href="appendix/glossary.html#hal">Capa de Abstracción de Hardware</a> dependerá normalmente de este <em>crate</em>.
Hay una descripción más detallada en la <a href="appendix/../start/registers.html">página de registros de memoria mapeada</a> o para una visión más amplia ver <a href="https://youtu.be/vLYit_HHPaY">este video</a>.</p>
<h3 id="spi"><a class="header" href="#spi">SPI</a></h3>
<p>Interfaz Periférica Serial. Ver <a href="https://en.wikipedia.org/wiki/Serial_peripheral_interface">aquí</a> para más información.</p>
<h3 id="svd"><a class="header" href="#svd">SVD</a></h3>
<p>Descripción de la Vista del Sistema es un formato de archivo XML utilizado para describir la vista de los programadores de un dispositivo microcontrolador. Puede leer más sobre él en <a href="https://www.keil.com/pack/doc/CMSIS/SVD/html/index.html">el sitio de documentación ARM CMSIS</a>.</p>
<h3 id="uart"><a class="header" href="#uart">UART</a></h3>
<p>Receptor-Transmisor Asíncrono Universal. Ver <a href="https://en.wikipedia.org/wiki/Universal_asynchronous_receiver-transmitter">aquí</a> para más información.</p>
<h3 id="usart"><a class="header" href="#usart">USART</a></h3>
<p>Receptor-Transmisor Síncrono y Asíncrono Universal. Ver <a href="https://en.wikipedia.org/wiki/Universal_synchronous_and_asynchronous_receiver-transmitter">aquí</a> para más información.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
